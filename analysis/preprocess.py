# -*- coding: utf-8 -*-
"""
ë°ì´í„°ê³¼í•™ ì „ë¬¸ê°€ìš© ë°ì´í„° ì „ì²˜ë¦¬ ë° ì„ë² ë”© GUI ì• í”Œë¦¬ì¼€ì´ì…˜
Description:
    ì´ ì• í”Œë¦¬ì¼€ì´ì…˜ì€ tkinterë¥¼ ì‚¬ìš©í•˜ì—¬ ì‚¬ìš©ì ì¹œí™”ì ì¸ GUIë¥¼ ì œê³µí•©ë‹ˆë‹¤.
    OpenAI APIë¥¼ íš¨ìœ¨ì ìœ¼ë¡œ í™œìš©í•˜ê¸° ìœ„í•´ ë°°ì¹˜ ì²˜ë¦¬(Batch Processing)ë¥¼ êµ¬í˜„í•˜ê³ ,
    ìœ ì˜ë¯¸í•œ ì •ë³´ë¥¼ ë³´ì¡´í•˜ëŠ” ì •êµí•œ ì „ì²˜ë¦¬ ë¡œì§ì„ ì ìš©í–ˆìŠµë‹ˆë‹¤.
Author:
    ë°ì´í„°ê³¼í•™ ë° íŒŒì´ì¬ ì „ë¬¸ê°€ (100k USD/day)
Date:
    2024-06-15 (Rev. 2024-06-17, ì „ì²˜ë¦¬ ë¡œì§ ì •êµí™”)
"""
import os
import re
import json
import logging
import threading
import queue
from pathlib import Path
from datetime import datetime
import tkinter as tk
from tkinter import ttk, filedialog, scrolledtext
from typing import List, Dict, Optional

# ì„œë“œíŒŒí‹° ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸
from dotenv import load_dotenv
from openai import OpenAI, APIError
from datasets import load_dataset
from bs4 import BeautifulSoup

# --- 1. ìƒìˆ˜ ë° ì½”ì–´ ë¡œì§ (Constants & Core Logic) ---

EMBEDDING_MODEL = 'text-embedding-3-small'
LOCAL_OUTPUT_DIR_NAME = 'train'
HF_OUTPUT_DIR_NAME = 'hf_train'
OUTPUT_FILENAME_LOCAL = 'train_embedded.jsonl'
OUTPUT_FILENAME_HF = 'hf_train_embedded.jsonl'
BATCH_SIZE = 1024

def preprocess_question_text(text: str) -> str:
    """
    ì§ˆë¬¸ í…ìŠ¤íŠ¸ì— ëŒ€í•´ ì •êµí™”ëœ ì „ì²˜ë¦¬ ê·œì¹™ì„ ìˆœì„œëŒ€ë¡œ ì ìš©í•©ë‹ˆë‹¤.
    """
    if not isinstance(text, str): return ""

    # 1. HTML íƒœê·¸ ì œê±°
    text = BeautifulSoup(text, "html.parser").get_text()
    
    # 2. ë³´ê¸° ë²ˆí˜¸ ì œê±° (ë¬¸ìì—´ ì „ì²´ì—ì„œ " 1) ", " 2. " ë“± íŒ¨í„´ì„ ê³µë°±ìœ¼ë¡œ ì¹˜í™˜)
    text = re.sub(r'\s+\d\)\s+', ' ', text)
    text = re.sub(r'\s+\d\.\s+', ' ', text)
    
    # 3. ì•ˆë‚´ì„± ê´„í˜¸ë§Œ ì œê±° (ì˜ˆ: (ê·¸ë¦¼ ì°¸ì¡°), (ë³´ê¸°)) / ì˜ë¬¸, ìˆ«ì ë“±ì´ í¬í•¨ëœ ê´„í˜¸ëŠ” ë³´ì¡´
    text = re.sub(r'\((?:ê·¸ë¦¼|ì‚¬ì§„|ë„í‘œ|í‘œ|ë³´ê¸°|ì°¸ì¡°|ë‹¨,)\s*[^)]*\)', '', text)
    
    # 4. ì¤„ë°”ê¿ˆ, íƒ­ ë“± ì œì–´ ë¬¸ì ì œê±° -> ê³µë°±ìœ¼ë¡œ ëŒ€ì²´
    text = re.sub(r'[\n\r\t]', ' ', text)
    
    # 5. ì¤‘ë³µ ê³µë°± ì œê±° ë° ì–‘ ë ê³µë°± ì œê±°
    text = re.sub(r'\s+', ' ', text).strip()
    
    return text

def get_embeddings_batch(client: OpenAI, texts_batch: List[str], model: str) -> Optional[List[List[float]]]:
    """
    ì£¼ì–´ì§„ í…ìŠ¤íŠ¸ ë°°ì¹˜ì— ëŒ€í•´ OpenAI ì„ë² ë”©ì„ ìƒì„±í•˜ê³  ì†Œìˆ˜ì  4ìë¦¬ë¡œ ë°˜ì˜¬ë¦¼í•©ë‹ˆë‹¤.
    """
    try:
        response = client.embeddings.create(input=texts_batch, model=model)
        batched_embeddings = [d.embedding for d in response.data]
        rounded_embeddings = [[round(val, 4) for val in emb] for emb in batched_embeddings]
        return rounded_embeddings
    except APIError as e:
        logging.error(f"OpenAI API í˜¸ì¶œ ì¤‘ ì—ëŸ¬ ë°œìƒ (ë°°ì¹˜ ì²˜ë¦¬): {e}")
        return None
    except Exception as e:
        logging.error(f"ì„ë² ë”© ë°°ì¹˜ ìƒì„± ì¤‘ ì˜ˆê¸°ì¹˜ ì•Šì€ ì—ëŸ¬ ë°œìƒ: {e}")
        return None

# --- 2. GUI ì• í”Œë¦¬ì¼€ì´ì…˜ í´ë˜ìŠ¤ (ì´í•˜ ì½”ë“œëŠ” ì´ì „ê³¼ ë™ì¼) ---
class Application(ttk.Frame):
    def __init__(self, master):
        super().__init__(master, padding="10")
        self.master = master
        self.master.title("ë°ì´í„° ì „ì²˜ë¦¬ ë° ì„ë² ë”© ë„êµ¬ (ì „ì²˜ë¦¬ ì •êµí™” v3)")
        self.master.geometry("800x650")
        self.grid(sticky=(tk.W, tk.E, tk.N, tk.S))
        self.master.columnconfigure(0, weight=1)
        self.master.rowconfigure(0, weight=1)

        # ë³€ìˆ˜ ì´ˆê¸°í™”
        self.input_dir_path = tk.StringVar()
        self.api_key_status = tk.StringVar(value="API í‚¤ í™•ì¸ ì¤‘...")
        self.status_text = tk.StringVar(value="ëŒ€ê¸° ì¤‘")
        self.client = None
        self.log_queue = queue.Queue()

        self.create_widgets()
        self.setup_logging()
        self.master.after(100, self.process_queue)
        self.load_api_key()

    def create_widgets(self):
        """GUIì˜ ëª¨ë“  ìœ„ì ¯ì„ ìƒì„±í•˜ê³  ë°°ì¹˜í•©ë‹ˆë‹¤."""
        # ì»¨íŠ¸ë¡¤ í”„ë ˆì„
        control_frame = ttk.LabelFrame(self, text="ì‘ì—… ì„¤ì •", padding="10")
        control_frame.grid(row=0, column=0, sticky=(tk.W, tk.E), padx=5, pady=5)
        control_frame.columnconfigure(1, weight=1)

        ttk.Label(control_frame, text="OpenAI API í‚¤:").grid(row=0, column=0, sticky=tk.W, padx=5, pady=2)
        ttk.Label(control_frame, textvariable=self.api_key_status, foreground="blue").grid(row=0, column=1, sticky=tk.W, padx=5, pady=2)

        ttk.Label(control_frame, text="ë¡œì»¬ JSON í´ë”:").grid(row=1, column=0, sticky=tk.W, padx=5, pady=2)
        self.folder_entry = ttk.Entry(control_frame, textvariable=self.input_dir_path, state='readonly', width=70)
        self.folder_entry.grid(row=1, column=1, sticky=(tk.W, tk.E), padx=5, pady=2)
        self.select_button = ttk.Button(control_frame, text="í´ë” ì„ íƒ", command=self.select_directory)
        self.select_button.grid(row=1, column=2, sticky=tk.E, padx=5, pady=2)
        
        ttk.Label(control_frame, text="ë°°ì¹˜ í¬ê¸°:").grid(row=2, column=0, sticky=tk.W, padx=5, pady=2)
        ttk.Label(control_frame, text=f"{BATCH_SIZE}ê°œ í•­ëª© / API í˜¸ì¶œ").grid(row=2, column=1, sticky=tk.W, padx=5, pady=2)


        # ì‹¤í–‰ í”„ë ˆì„
        action_frame = ttk.Frame(self, padding="10")
        action_frame.grid(row=1, column=0, sticky=(tk.W, tk.E), padx=5, pady=5)
        action_frame.columnconfigure(0, weight=1)

        self.start_button = ttk.Button(action_frame, text="ì²˜ë¦¬ ì‹œì‘", command=self.start_processing, state='disabled')
        self.start_button.grid(row=0, column=0, ipady=5, ipadx=10)

        # ì§„í–‰ ìƒíƒœ í”„ë ˆì„
        progress_frame = ttk.LabelFrame(self, text="ì§„í–‰ ìƒíƒœ", padding="10")
        progress_frame.grid(row=2, column=0, sticky=(tk.W, tk.E), padx=5, pady=5)
        progress_frame.columnconfigure(0, weight=1)

        ttk.Label(progress_frame, textvariable=self.status_text).grid(row=0, column=0, sticky=(tk.W, tk.E))
        self.progress_bar = ttk.Progressbar(progress_frame, orient='horizontal', mode='determinate')
        self.progress_bar.grid(row=1, column=0, sticky=(tk.W, tk.E), pady=5)

        # ë¡œê·¸ í”„ë ˆì„
        log_frame = ttk.LabelFrame(self, text="ì‹¤ì‹œê°„ ë¡œê·¸", padding="10")
        log_frame.grid(row=3, column=0, sticky=(tk.W, tk.E, tk.N, tk.S), padx=5, pady=5)
        self.rowconfigure(3, weight=1)
        log_frame.columnconfigure(0, weight=1); log_frame.rowconfigure(0, weight=1)

        self.log_text = scrolledtext.ScrolledText(log_frame, state='disabled', wrap=tk.WORD, height=15, bg="#f0f0f0", fg="black")
        self.log_text.grid(row=0, column=0, sticky=(tk.W, tk.E, tk.N, tk.S))

    def setup_logging(self):
        log_handler = QueueHandler(self.log_queue)
        logging.basicConfig(level=logging.INFO, format='%(asctime)s - [%(levelname)s] - %(message)s', datefmt='%H:%M:%S', handlers=[log_handler])

    def process_queue(self):
        try:
            while True: self.display_log(self.log_queue.get_nowait())
        except queue.Empty: pass
        finally: self.master.after(100, self.process_queue)

    def display_log(self, record):
        msg = logging.getLogger().handlers[0].format(record)
        self.log_text.configure(state='normal')
        self.log_text.insert(tk.END, msg + '\n')
        self.log_text.configure(state='disabled')
        self.log_text.yview(tk.END)

    def load_api_key(self):
        logging.info("'.env' íŒŒì¼ì—ì„œ í™˜ê²½ ë³€ìˆ˜ë¥¼ ë¡œë“œí•©ë‹ˆë‹¤.")
        load_dotenv()
        api_key = os.getenv("OPENAI_API_KEY")
        if api_key:
            self.client = OpenAI(api_key=api_key)
            self.api_key_status.set(f"ë¡œë“œ ì„±ê³µ (í‚¤ ì¼ë¶€: ...{api_key[-4:]})")
            logging.info("OpenAI API í‚¤ ë¡œë“œ ì„±ê³µ.")
        else:
            self.api_key_status.set("ë¡œë“œ ì‹¤íŒ¨! .env íŒŒì¼ì„ í™•ì¸í•´ì£¼ì„¸ìš”.")
            logging.error("í™˜ê²½ ë³€ìˆ˜ 'OPENAI_API_KEY'ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            
    def select_directory(self):
        path = filedialog.askdirectory(title="JSON íŒŒì¼ì´ ìˆëŠ” í´ë”ë¥¼ ì„ íƒí•˜ì„¸ìš”")
        if path:
            self.input_dir_path.set(path)
            logging.info(f"ì‚¬ìš©ì ì„ íƒ í´ë”: {path}")
            if self.client: self.start_button.config(state='normal')

    def start_processing(self):
        if not self.input_dir_path.get():
            logging.warning("ì‘ì—…ì„ ì‹œì‘í•˜ê¸° ì „ì— í´ë”ë¥¼ ì„ íƒí•´ì£¼ì„¸ìš”.")
            return
        self.start_button.config(state='disabled')
        self.select_button.config(state='disabled')
        self.progress_bar['value'] = 0
        self.log_text.configure(state='normal'); self.log_text.delete(1.0, tk.END); self.log_text.configure(state='disabled')

        self.processing_thread = threading.Thread(target=self.run_processing_logic, args=(Path(self.input_dir_path.get()),))
        self.processing_thread.daemon = True
        self.processing_thread.start()

    def _process_and_write_batch(self, batch_items: List[Dict], batch_texts: List[str], f_out) -> int:
        if not batch_items:
            return 0
        embeddings = get_embeddings_batch(self.client, batch_texts, EMBEDDING_MODEL)
        if embeddings and len(embeddings) == len(batch_items):
            for item, embedding in zip(batch_items, embeddings):
                item["embedding"] = embedding
                f_out.write(json.dumps(item, ensure_ascii=False) + '\n')
            return len(batch_items)
        else:
            logging.error(f"{len(batch_items)}ê°œ ì•„ì´í…œì˜ ë°°ì¹˜ ì²˜ë¦¬ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. ì´ ë°°ì¹˜ë¥¼ ê±´ë„ˆëœë‹ˆë‹¤.")
            return 0

    def run_processing_logic(self, input_dir: Path):
        try:
            now_str = datetime.now().strftime('%Y-%m-%d_%H-%M-%S')
            base_output_dir = Path(now_str)
            local_output_dir = base_output_dir / LOCAL_OUTPUT_DIR_NAME
            hf_output_dir = base_output_dir / HF_OUTPUT_DIR_NAME
            local_output_dir.mkdir(exist_ok=True, parents=True)
            hf_output_dir.mkdir(exist_ok=True, parents=True)
            logging.info(f"ê²°ê³¼ë¬¼ ì €ì¥ í´ë” ìƒì„± ì™„ë£Œ: '{base_output_dir}'")

            self.process_local_files_threaded(input_dir, local_output_dir)
            self.process_hf_dataset_threaded(hf_output_dir)

            logging.info("ğŸ‰ ëª¨ë“  ì‘ì—…ì´ ì„±ê³µì ìœ¼ë¡œ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.")
            self.status_text.set("ëª¨ë“  ì‘ì—… ì™„ë£Œ!")

        except Exception as e:
            logging.critical(f"ì²˜ë¦¬ ì¤‘ ì¹˜ëª…ì ì¸ ì˜¤ë¥˜ ë°œìƒ: {e}", exc_info=True)
            self.status_text.set(f"ì˜¤ë¥˜ ë°œìƒ: {e}")
        finally:
            self.start_button.config(state='normal')
            self.select_button.config(state='normal')

    def process_local_files_threaded(self, input_dir, output_dir):
        self.status_text.set("ë¡œì»¬ JSON íŒŒì¼ ëª©ë¡ì„ ìˆ˜ì§‘í•˜ëŠ” ì¤‘...")
        logging.info(f"'{input_dir}' í´ë”ì—ì„œ ë¡œì»¬ JSON íŒŒì¼ ì²˜ë¦¬ë¥¼ ì‹œì‘í•©ë‹ˆë‹¤.")
        json_files = list(input_dir.rglob('*.json'))
        if not json_files:
            logging.warning(f"'{input_dir}'ì—ì„œ JSON íŒŒì¼ì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
            return

        total_items_to_process = 0
        all_valid_items = []
        logging.info("ì²˜ë¦¬í•  ì „ì²´ ì•„ì´í…œ ìˆ˜ë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤...")
        for file_path in json_files:
            try:
                with open(file_path, 'r', encoding='utf-8-sig') as f:
                    data = json.load(f)
                items = data if isinstance(data, list) else [data]
                for item in items:
                    if item.get("q_type") == 1 and "question" in item:
                        all_valid_items.append(item)
                        total_items_to_process += 1
            except Exception as e:
                logging.error(f"íŒŒì¼ '{file_path}' ì‚¬ì „ ì½ê¸° ì¤‘ ì˜¤ë¥˜: {e}")
        logging.info(f"ì´ {total_items_to_process}ê°œì˜ ìœ íš¨í•œ ë¡œì»¬ ì•„ì´í…œì„ ì²˜ë¦¬í•©ë‹ˆë‹¤.")
        
        output_path = output_dir / OUTPUT_FILENAME_LOCAL
        processed_count = 0
        batch_items, batch_texts = [], []

        with open(output_path, 'w', encoding='utf-8') as f_out:
            for item in all_valid_items:
                preprocessed_text = preprocess_question_text(item["question"])
                item["preprocessed_question"] = preprocessed_text
                batch_items.append(item)
                batch_texts.append(preprocessed_text)
                
                if len(batch_items) >= BATCH_SIZE:
                    self.status_text.set(f"ë¡œì»¬ íŒŒì¼: {len(batch_items)}ê°œ ì•„ì´í…œ ë°°ì¹˜ ì²˜ë¦¬ ì¤‘...")
                    num_processed = self._process_and_write_batch(batch_items, batch_texts, f_out)
                    processed_count += num_processed
                    self.progress_bar['value'] = processed_count / total_items_to_process * 100
                    batch_items.clear(); batch_texts.clear()
            
            if batch_items:
                self.status_text.set(f"ë¡œì»¬ íŒŒì¼: ë§ˆì§€ë§‰ {len(batch_items)}ê°œ ì•„ì´í…œ ë°°ì¹˜ ì²˜ë¦¬ ì¤‘...")
                num_processed = self._process_and_write_batch(batch_items, batch_texts, f_out)
                processed_count += num_processed

        self.progress_bar['value'] = 100
        logging.info(f"ë¡œì»¬ JSON íŒŒì¼ ì²˜ë¦¬ ì™„ë£Œ. ì´ {processed_count}ê°œ í•­ëª©ì„ '{output_path}'ì— ì €ì¥í–ˆìŠµë‹ˆë‹¤.")

    def process_hf_dataset_threaded(self, output_dir):
        self.status_text.set("Hugging Face ë°ì´í„°ì…‹ ë‹¤ìš´ë¡œë“œ ì¤‘...")
        logging.info("Hugging Face ë°ì´í„°ì…‹ 'sean0042/KorMedMCQA' (doctor) ë¡œë“œë¥¼ ì‹œì‘í•©ë‹ˆë‹¤.")
        dataset = load_dataset("sean0042/KorMedMCQA", "doctor", split='train')
        total_items = len(dataset)
        logging.info(f"ë°ì´í„°ì…‹ ë¡œë“œ ì™„ë£Œ. ì´ {total_items}ê°œì˜ ë°ì´í„°ë¥¼ ì²˜ë¦¬í•©ë‹ˆë‹¤.")
        
        output_path = output_dir / OUTPUT_FILENAME_HF
        processed_count = 0
        batch_items, batch_texts = [], []

        with open(output_path, 'w', encoding='utf-8') as f_out:
            for i, item_dict in enumerate(dataset):
                if "question" in item_dict:
                    preprocessed_text = preprocess_question_text(item_dict["question"])
                    item_dict["preprocessed_question"] = preprocessed_text
                    batch_items.append(item_dict)
                    batch_texts.append(preprocessed_text)

                if len(batch_items) >= BATCH_SIZE or (i + 1) == total_items:
                    if not batch_items: continue
                    self.status_text.set(f"HF ë°ì´í„°: {processed_count+1}-{processed_count+len(batch_items)}/{total_items} ì²˜ë¦¬ ì¤‘...")
                    num_processed = self._process_and_write_batch(batch_items, batch_texts, f_out)
                    processed_count += num_processed
                    self.progress_bar['value'] = processed_count / total_items * 100
                    batch_items.clear(); batch_texts.clear()
        
        logging.info(f"Hugging Face ë°ì´í„°ì…‹ ì²˜ë¦¬ ì™„ë£Œ. ì´ {processed_count}ê°œ í•­ëª©ì„ '{output_path}'ì— ì €ì¥í–ˆìŠµë‹ˆë‹¤.")

class QueueHandler(logging.Handler):
    def __init__(self, log_queue):
        super().__init__()
        self.log_queue = log_queue

    def emit(self, record):
        self.log_queue.put(record)

# --- 3. ì• í”Œë¦¬ì¼€ì´ì…˜ ì‹¤í–‰ (Application Execution) ---
if __name__ == "__main__":
    root = tk.Tk()
    app = Application(master=root)
    app.mainloop()
