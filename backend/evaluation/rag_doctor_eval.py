#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
## KorMedMCQA ì˜ì‚¬ êµ­ê°€ê³ ì‹œ ë°ì´í„°ì…‹ RAG ê¸°ë°˜ í‰ê°€ ìŠ¤í¬ë¦½íŠ¸ (ìˆ˜ì • ì™„ë£Œ)

ì´ ìŠ¤í¬ë¦½íŠ¸ëŠ” 'doctor-test.csv' ë¬¸ì œ ë°ì´í„°ì…‹ì— ëŒ€í•´ 
'search_engine.py'ì˜ ë²¡í„° ê²€ìƒ‰ ê¸°ëŠ¥ì„ í™œìš©í•œ RAG(Retrieval-Augmented Generation) 
ì„±ëŠ¥ì„ í‰ê°€í•©ë‹ˆë‹¤.

**ì£¼ìš” ê¸°ëŠ¥:**
1.  **RAG íŒŒì´í”„ë¼ì¸**: ê° ë¬¸ì œì— ëŒ€í•´ ë¨¼ì € ë²¡í„° DBì—ì„œ ê´€ë ¨ ì •ë³´ë¥¼ ê²€ìƒ‰í•˜ê³ , 
    ê²€ìƒ‰ëœ ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ LLMì´ ë¬¸ì œë¥¼ í’€ë„ë¡ í•©ë‹ˆë‹¤.
2.  **ë™ì  í”„ë¡¬í”„íŠ¸ ìƒì„±**: ê²€ìƒ‰ëœ ì»¨í…ìŠ¤íŠ¸ì˜ ìœ ë¬´ì— ë”°ë¼ LLMì—ê²Œ ë‹¤ë¥¸ ì§€ì¹¨ì„ ì œê³µí•˜ëŠ”
    í”„ë¡¬í”„íŠ¸ë¥¼ ë™ì ìœ¼ë¡œ ìƒì„±í•©ë‹ˆë‹¤.
3.  **ì„±ëŠ¥ í‰ê°€ ë° ë¡œê¹…**: RAG íŒŒì´í”„ë¼ì¸ì˜ ì „ì²´ ì •í™•ë„ë¥¼ ì¸¡ì •í•˜ê³ , í‹€ë¦° ë¬¸ì œì— ëŒ€í•œ
    ìƒì„¸ ì •ë³´(ì‚¬ìš©í•œ ì»¨í…ìŠ¤íŠ¸, ëª¨ë¸ ë‹µë³€ ë“±)ë¥¼ JSONL íŒŒì¼ë¡œ ì €ì¥í•˜ì—¬ ë¶„ì„ì„ ë•ìŠµë‹ˆë‹¤.

**ì‹¤í–‰ ë°©ë²•:**
- í”„ë¡œì íŠ¸ ë£¨íŠ¸(medical-multimodal-rag) í´ë”ì—ì„œ ì‹¤í–‰:
  `python -m evaluation.rag_doctor_eval`
- ìƒìœ„ 5ê°œ ë¬¸ì œë§Œ í‰ê°€:
  `python -m evaluation.rag_doctor_eval --top_n 5`
"""
# --- ê¸°ë³¸ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸ ---
import os, re, argparse, json, time, pathlib, sys
from typing import Dict, Optional 

# --- ì™¸ë¶€ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸ ---
from tqdm import tqdm
import pandas as pd
import google.generativeai as genai
from dotenv import load_dotenv

### ê²½ë¡œ ì„¤ì • ì‹œì‘ ###
# í˜„ì¬ íŒŒì¼ì˜ ìœ„ì¹˜ë¥¼ ê¸°ì¤€ìœ¼ë¡œ í”„ë¡œì íŠ¸ ë£¨íŠ¸ ë””ë ‰í† ë¦¬ ê²½ë¡œë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤.
project_root = pathlib.Path(__file__).resolve().parents[1]

# sys.pathì— í”„ë¡œì íŠ¸ ë£¨íŠ¸ë¥¼ ì¶”ê°€í•˜ì—¬ ë‹¤ë¥¸ í´ë”ì˜ ëª¨ë“ˆì„ ì„í¬íŠ¸í•  ìˆ˜ ìˆë„ë¡ í•©ë‹ˆë‹¤.
if str(project_root) not in sys.path:
    sys.path.append(str(project_root))
### ê²½ë¡œ ì„¤ì • ë ###


### ì‚¬ìš©ì ì •ì˜ ëª¨ë“ˆ ì„í¬íŠ¸ ìˆ˜ì • ì‹œì‘ ###
# ëª¨ë“  ì„í¬íŠ¸ êµ¬ë¬¸ì„ ìŠ¤í¬ë¦½íŠ¸ ìƒë‹¨ìœ¼ë¡œ ì´ë™í•˜ê³ , ì „ì²´ ê²½ë¡œë¥¼ ëª…ì‹œí•©ë‹ˆë‹¤.
from search.search_engine import SearchEngine
from evaluation.doctor_choice_eval import extract_choice, gemini_completion, validate_data
### ì‚¬ìš©ì ì •ì˜ ëª¨ë“ˆ ì„í¬íŠ¸ ìˆ˜ì • ë ###


# --- í™˜ê²½ ì„¤ì • ---
load_dotenv(dotenv_path=project_root / '.env')
api_key = os.getenv("GEMINI_API_KEY")
if not api_key:
    raise ValueError("GEMINI_API_KEYê°€ .env íŒŒì¼ì— ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
genai.configure(api_key=api_key)    

def build_rag_prompt(question: str, choices: Dict[str, str], context: Optional[str]) -> str:
    """
    RAG íŒŒì´í”„ë¼ì¸ì„ ìœ„í•œ ë™ì  í”„ë¡¬í”„íŠ¸ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
    """
    choices_str = "\n".join([f"{k}. {v}" for k, v in choices.items()])

    if context and context != "ê´€ë ¨ í…ìŠ¤íŠ¸ ì •ë³´ ì—†ìŒ":
        instruction = """ë‹¹ì‹ ì€ ì˜í•™ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ì£¼ì–´ì§„ [ì°¸ê³  ì •ë³´]ë¥¼ ê²€í† í•˜ê³ , ë§Œì•½ ì´ ì •ë³´ê°€ [ë¬¸ì œ] í•´ê²°ì— ì§ì ‘ì ì´ê³  ì •í™•í•˜ê²Œ ê´€ë ¨ì´ ìˆë‹¤ë©´ ì´ë¥¼ ìµœìš°ì„ ìœ¼ë¡œ í™œìš©í•˜ì—¬ ë‹µì„ ì°¾ìœ¼ì„¸ìš”.
í•˜ì§€ë§Œ, [ì°¸ê³  ì •ë³´]ê°€ ë¬¸ì œì™€ ê´€ë ¨ì´ ì—†ê±°ë‚˜, ì‚¬ì‹¤ê³¼ ë‹¤ë¥´ê±°ë‚˜, ì˜¤í•´ì˜ ì†Œì§€ê°€ ìˆë‹¤ê³  íŒë‹¨ë˜ë©´, ì´ ì •ë³´ë¥¼ ë¬´ì‹œí•˜ê³  ë‹¹ì‹ ì˜ ì˜í•™ ì „ë¬¸ ì§€ì‹ì—ë§Œ ì˜ì¡´í•˜ì—¬ ê°€ì¥ ì ì ˆí•œ ë‹µì„ ê³ ë¥´ì„¸ìš”."""
        context_section = f"---\n[ì°¸ê³  ì •ë³´]\n{context}\n---"
    else:
        instruction = "ë‹¹ì‹ ì€ ì˜í•™ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ë‹¹ì‹ ì˜ ì˜í•™ ì§€ì‹ì„ ì´ë™ì›í•˜ì—¬ ì•„ë˜ [ë¬¸ì œ]ì— ê°€ì¥ ì ì ˆí•œ ë‹µì„ [ë³´ê¸°]ì—ì„œ í•˜ë‚˜ë§Œ ê³ ë¥´ì„¸ìš”."
        context_section = ""

    prompt = f"""[ì§€ì¹¨]
{instruction}
ë‹µë³€ì€ ë°˜ë“œì‹œ A, B, C, D, E ì¤‘ í•˜ë‚˜ì˜ ì•ŒíŒŒë²³ìœ¼ë¡œë§Œ ì¶œë ¥í•´ì•¼ í•˜ë©°, ë‹¤ë¥¸ ì–´ë–¤ ë¶€ê°€ ì„¤ëª…ë„ ì¶”ê°€í•˜ì§€ ë§ˆì„¸ìš”.

{context_section}

[ë¬¸ì œ]
{question}

[ë³´ê¸°]
{choices_str}

[ì •ë‹µ]:"""
    
    return prompt.strip()

def generate_search_query(question: str, model_name: str = "gemini-1.5-pro") -> str:
    """
    LLMì„ ì‚¬ìš©í•˜ì—¬ ë¬¸ì œì—ì„œ ê²€ìƒ‰ì— ê°€ì¥ ì í•©í•œ í•µì‹¬ í‚¤ì›Œë“œë‚˜ ì§ˆë¬¸ì„ ìƒì„±í•©ë‹ˆë‹¤.
    """
    prompt = f"""ë‹¤ìŒ ì˜í•™ ë¬¸ì œì—ì„œ ë²¡í„° ê²€ìƒ‰ì„ ìœ„í•œ ê°€ì¥ í•µì‹¬ì ì¸ í‚¤ì›Œë“œë‚˜ ì§§ì€ ì§ˆë¬¸ì„ 1~2ê°œ ìƒì„±í•´ì¤˜. ë²•ë¥ ì´ë‚˜ ê·œì •ê³¼ ê´€ë ¨ëœ ë¬¸ì œë¼ë©´ ê´€ë ¨ ë²•ë¥ ëª…ì„ í¬í•¨í•´ì¤˜. ë‹¤ë¥¸ ì„¤ëª… ì—†ì´ í‚¤ì›Œë“œë‚˜ ì§ˆë¬¸ë§Œ ì¶œë ¥í•´ì¤˜.

[ë¬¸ì œ]
{question}

[ê²€ìƒ‰ìš© ì¿¼ë¦¬]:"""
    
    try:
        # gemini_completion í•¨ìˆ˜ëŠ” ì´ë¯¸ doctor_choice_eval.pyì— ì¡´ì¬í•˜ë¯€ë¡œ ì¬ì‚¬ìš©í•©ë‹ˆë‹¤.
        search_query = gemini_completion(prompt, model_name)
        # LLMì´ ë¶ˆí•„ìš”í•œ ë¬¸êµ¬ë¥¼ ì¶”ê°€í•  ê²½ìš°ë¥¼ ëŒ€ë¹„í•´ ê°„ë‹¨íˆ ì²˜ë¦¬
        search_query = search_query.replace("*", "").replace("`", "").strip()
        print(f"    - ìƒì„±ëœ ê²€ìƒ‰ ì¿¼ë¦¬: {search_query}")
        return search_query
    except Exception as e:
        print(f"    - ì¿¼ë¦¬ ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return question # ì‹¤íŒ¨ ì‹œ ì›ë³¸ ì§ˆë¬¸ ì‚¬ìš©
    


# --- ì¿¼ë¦¬ í™•ì¥ì´ ì ìš©ëœ evaluate_with_rag í•¨ìˆ˜ (ì „ì²´ ìˆ˜ì • ë²„ì „) ---
def evaluate_with_rag(top_n: int = None, model_name: str = "gemini-1.5-pro"):
    print("--- RAG í‰ê°€ ì‹œìŠ¤í…œ ì‹œì‘ (ì¿¼ë¦¬ í™•ì¥ ì ìš©ë¨) ---")
    
    print("\n[1/5] ê²€ìƒ‰ ì—”ì§„ ì´ˆê¸°í™” ì¤‘...")
    try:
        search_engine = SearchEngine()
        print("âœ… ê²€ìƒ‰ ì—”ì§„ ì´ˆê¸°í™” ì™„ë£Œ")
    except Exception as e:
        print(f"âŒ ê²€ìƒ‰ ì—”ì§„ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
        return

    print("\n[2/5] í‰ê°€ ë°ì´í„° ë¡œë“œ ì¤‘...")
    try:
        data_path = pathlib.Path(__file__).parent
        csv_path = data_path / "doctor-test.csv"
        df = pd.read_csv(csv_path)
        df = validate_data(df)
        if len(df) == 0:
            print("âŒ í‰ê°€ë¥¼ ì§„í–‰í•  ìœ íš¨í•œ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return
        test_data = df.to_dict('records')
        print(f"âœ… ë°ì´í„° ë¡œë“œ ë° ê²€ì¦ ì™„ë£Œ: {len(test_data)}ê°œ ë¬¸ì œ")
    except FileNotFoundError:
        print(f"âŒ ì˜¤ë¥˜: í‰ê°€ íŒŒì¼ '{csv_path}'ì„(ë¥¼) ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return
    except Exception as e:
        print(f"âŒ ë°ì´í„° ë¡œë“œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return

    if top_n:
        test_data = test_data[:top_n]
        print(f"â„¹ï¸  --top_n={top_n} ì„¤ì •ì— ë”°ë¼ ìƒìœ„ {len(test_data)}ê°œ ë¬¸ì œë§Œ í‰ê°€í•©ë‹ˆë‹¤.")

    print(f"\n[3/5] RAG ê¸°ë°˜ í‰ê°€ ë£¨í”„ ì‹œì‘ (ëª¨ë¸: {model_name})")
    
    total, correct = 0, 0
    wrong_log = []

    for item in tqdm(test_data, desc="RAG í‰ê°€ ì§„í–‰ ì¤‘"):
        total += 1
        q_text = item["question"]
        choices_dict = {letter: str(item[letter]).strip() for letter in ['A', 'B', 'C', 'D', 'E']}
        gt = chr(65 + item["answer"] - 1)

        # --- KeyError ìˆ˜ì •ëœ ë¶€ë¶„ ---
        # item['id'] ëŒ€ì‹  ì¹´ìš´í„° ë³€ìˆ˜ totalì„ ì‚¬ìš©í•©ë‹ˆë‹¤.
        print(f"\n[ë¬¸ì œ {total}]")
        print("  - ì¿¼ë¦¬ í™•ì¥ ì¤‘...")
        search_query = generate_search_query(q_text, model_name)
        print(f"  - ìƒì„±ëœ ê²€ìƒ‰ ì¿¼ë¦¬: '{search_query}'")
        
        search_result = search_engine.search_text(query=search_query, top_k=3)
        retrieved_context = search_result.get("text_content")
        print(f"  - ê²€ìƒ‰ëœ ì •ë³´: {'ìˆìŒ' if retrieved_context else 'ì—†ìŒ'}")
        
        rag_prompt = build_rag_prompt(q_text, choices_dict, retrieved_context)
        gen_out = gemini_completion(rag_prompt, model_name)
        pred = extract_choice(gen_out)

        is_ok = (pred == gt)
        if is_ok:
            correct += 1
            print(f"  - ê²°ê³¼: ì •ë‹µ (ì˜ˆì¸¡: {pred}, ì •ë‹µ: {gt})")
        else:
            print(f"  - ê²°ê³¼: ì˜¤ë‹µ (ì˜ˆì¸¡: {pred}, ì •ë‹µ: {gt})")
            
            # --- KeyError ìˆ˜ì •ëœ ë¶€ë¶„ ---
            # ì˜¤ë‹µ ë¡œê·¸ ì €ì¥ ì‹œì—ë„ ë™ì ìœ¼ë¡œ ìƒì„±ëœ IDë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.
            wrong_log.append({
                "id": f"item_{total}", 
                "question": q_text,
                "choices": choices_dict,
                "generated_query": search_query,
                "retrieved_context": retrieved_context,
                "gt": gt,
                "pred": pred,
                "model_output": gen_out
            })

        time.sleep(1.0)
    
    print("\n[4/5] í‰ê°€ ì™„ë£Œ. ê²°ê³¼ ì§‘ê³„ ì¤‘...")

    if total > 0:
        acc = correct / total * 100
        print(f"\nğŸ¯ ìµœì¢… ì •í™•ë„: {acc:.2f}% (ì´ {total} ë¬¸ì œ ì¤‘ {correct} ë¬¸ì œ ì •ë‹µ)")
    
    if wrong_log:
        out_dir = pathlib.Path(__file__).parent / "evaluation_results"
        out_dir.mkdir(exist_ok=True)
        model_short_name = model_name.split('/')[-1]
        file_path = out_dir / f"rag_wrong_answers_query_expansion_{model_short_name}.jsonl"
        with open(file_path, "w", encoding="utf-8") as f:
            for row in wrong_log:
                f.write(json.dumps(row, ensure_ascii=False) + "\n")
        print(f"ğŸ’¾ ì˜¤ë‹µ ë…¸íŠ¸ ì €ì¥ ì™„ë£Œ: {file_path} ({len(wrong_log)}ê°œ)")

    print("\n[5/5] RAG í‰ê°€ ì‹œìŠ¤í…œ ì¢…ë£Œ")

if __name__ == "__main__":
    parser = argparse.ArgumentParser(description="RAG ê¸°ë°˜ìœ¼ë¡œ KorMedMCQA-doctor ë°ì´í„°ì…‹ì„ í‰ê°€í•©ë‹ˆë‹¤.")
    parser.add_argument("--model", type=str, default="gemini-1.5-pro", help="í‰ê°€ì— ì‚¬ìš©í•  ëª¨ë¸ ì´ë¦„ (ì˜ˆ: gemini-1.5-pro, gemini-1.5-flash)")
    parser.add_argument("--top_n", type=int, help="í‰ê°€í•  ë¬¸ì œì˜ ìˆ˜ë¥¼ ì œí•œí•©ë‹ˆë‹¤ (ì˜ˆ: --top_n 10).")
    args = parser.parse_args()
    
    current_dir = pathlib.Path(__file__).parent
    required_files = ["doctor-test.csv", "doctor_choice_eval.py"]
    missing_files = [f for f in required_files if not (current_dir / f).exists()]
    
    if missing_files:
        print("âŒ ì˜¤ë¥˜: í‰ê°€ì— í•„ìš”í•œ íŒŒì¼ì´ 'evaluation' í´ë”ì— ì—†ìŠµë‹ˆë‹¤.")
        for f in missing_files:
            print(f"  - {f} íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    else:
        evaluate_with_rag(top_n=args.top_n, model_name=args.model)