# generation/dynamic_question_generator.py
"""
ë²¡í„°DB ê¸°ë°˜ ë™ì  ì˜ë£Œ ë¬¸ì œ ìƒì„± ì‹œìŠ¤í…œ
ì‚¬ìš©ì ì¿¼ë¦¬ â†’ ë²¡í„° ê²€ìƒ‰ â†’ LLM ììœ¨ íŒë‹¨ â†’ ë¬¸ì œ ìƒì„±
"""
from pathlib import Path
import os
import json
from datetime import datetime
from typing import Dict, List, Any, Optional
from dataclasses import dataclass

# Phase IV ê²€ìƒ‰ ì—”ì§„
from search.search_engine import SearchEngine

# Gemini API
try:
    import google.generativeai as genai
    GEMINI_AVAILABLE = True
except ImportError:
    GEMINI_AVAILABLE = False

@dataclass
class SearchContext:
    query: str
    text_content: str
    image_info: str
    confidence: str
    has_images: bool
    estimated_topic: str
    primary_image_path: str = ""  # ì¶”ê°€
    
class DynamicQuestionGenerator:
    """ë²¡í„°DB ê¸°ë°˜ ë™ì  ë¬¸ì œ ìƒì„±ê¸°"""
    
    def __init__(self):
        print("ğŸ¤– ë™ì  ë¬¸ì œ ìƒì„± ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì¤‘...")
        
        # ê²€ìƒ‰ ì—”ì§„ ì—°ê²°
        try:
            self.search_engine = SearchEngine()
            print("âœ… ë²¡í„°DB ê²€ìƒ‰ ì—”ì§„ ì—°ê²° ì™„ë£Œ")
        except Exception as e:
            print(f"âŒ ê²€ìƒ‰ ì—”ì§„ ì—°ê²° ì‹¤íŒ¨: {e}")
            self.search_engine = None
        
        # Gemini í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
        self.gemini_client = self._init_gemini()
        
        print("âœ… ë™ì  ë¬¸ì œ ìƒì„± ì‹œìŠ¤í…œ ì¤€ë¹„ ì™„ë£Œ")
    
    def _init_gemini(self) -> Optional[object]:
        """Gemini API ì´ˆê¸°í™”"""
        api_key = os.getenv("GEMINI_API_KEY")
        if not api_key or not GEMINI_AVAILABLE:
            print("âš ï¸ Gemini API ì‚¬ìš© ë¶ˆê°€")
            return None
        
        try:
            genai.configure(api_key=api_key)
            model = genai.GenerativeModel('gemini-1.5-pro')
            print("âœ… Gemini 1.5 Pro ì—°ê²° ì™„ë£Œ")
            return model
        except Exception as e:
            print(f"âŒ Gemini ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            return None
    
    def generate_question_from_query(self, user_query: str, top_k: int = 8) -> Dict[str, Any]:
        """ì‚¬ìš©ì ì¿¼ë¦¬ë¡œë¶€í„° ë™ì  ë¬¸ì œ ìƒì„± + LLM ì´ë¯¸ì§€ ì„ íƒ"""
        
        print(f"\nğŸ” ë™ì  ë¬¸ì œ ìƒì„±: '{user_query}'")
        print("="*60)
        
        try:
            # 1. ë²¡í„°DBì—ì„œ ê´€ë ¨ ì •ë³´ ê²€ìƒ‰
            print("1ï¸âƒ£ ë²¡í„°DB ê²€ìƒ‰ ì¤‘...")
            search_result = self.search_engine.search_text(user_query, top_k=top_k)
            
            if "error" in search_result:
                return {"error": f"ë²¡í„° ê²€ìƒ‰ ì‹¤íŒ¨: {search_result['error']}"}
            
            # 2. ê²€ìƒ‰ ê²°ê³¼ë¥¼ êµ¬ì¡°í™”ëœ ì»¨í…ìŠ¤íŠ¸ë¡œ ë³€í™˜
            print("2ï¸âƒ£ ì»¨í…ìŠ¤íŠ¸ êµ¬ì¡°í™” ì¤‘...")
            context = self._create_search_context(search_result, user_query)
            
            # 3. LLMì—ê²Œ ë¬¸ì œ ìƒì„± ìš”ì²­ (ì´ë¯¸ì§€ ì„ íƒ ì—†ì´)
            print("3ï¸âƒ£ LLM ë¬¸ì œ ìƒì„± ì¤‘...")
            if not self.gemini_client:
                return {"error": "Gemini API ì‚¬ìš© ë¶ˆê°€"}
            
            generated_question = self._generate_question_only(context)
            
            if not generated_question or "error" in generated_question:
                return {"error": "LLM ë¬¸ì œ ìƒì„± ì‹¤íŒ¨"}
            
            # 4. í…ìŠ¤íŠ¸ ì „ìš© ëª¨ë“œ í™•ì¸ ë° ì¡°ê¸° ì²˜ë¦¬
            is_text_only_mode = search_result.get("is_text_only_mode", False)

            if is_text_only_mode:
                print("4ï¸âƒ£ í…ìŠ¤íŠ¸ ì „ìš© ëª¨ë“œ ê°ì§€ - ì´ë¯¸ì§€ ê²€ìƒ‰ ìƒëµ")
                # ì´ë¯¸ì§€ ì„ íƒ ë° ê²€ìƒ‰ ìƒëµ
                image_selection = {
                    "selected_image_type": "None",
                    "korean_name": "í…ìŠ¤íŠ¸ ì „ìš©",
                    "reason": "ì§ˆë³‘ ë§¤ì¹­ ì‹¤íŒ¨ë¡œ ì¸í•œ í…ìŠ¤íŠ¸ ì „ìš© ì²˜ë¦¬ (í‰ë¶€ ë¬´ê´€ ì£¼ì œ ì¶”ì •)",
                    "relevance_score": 1,
                    "is_chest_related": False,
                    "query_match": "low"
                }
                selected_images = []
            else:
                # ê¸°ì¡´ ì´ë¯¸ì§€ ì„ íƒ ë¡œì§
                print("4ï¸âƒ£ LLM ì´ë¯¸ì§€ íƒ€ì… ì„ íƒ ì¤‘...")
                image_selection = self._select_appropriate_image(generated_question, context)
                
                print("5ï¸âƒ£ ì„ íƒëœ íƒ€ì…ìœ¼ë¡œ ì´ë¯¸ì§€ ê²€ìƒ‰ ì¤‘...")
                selected_images = self._fetch_selected_images(image_selection, search_result)

            # 6. ê²°ê³¼ êµ¬ì„± (ê¸°ì¡´ê³¼ ë™ì¼í•˜ë˜ ë‹¨ê³„ ë²ˆí˜¸ë§Œ ì¡°ì •)
            result = {
                "generated_question": generated_question,
                "image_selection": image_selection,
                "selected_images": selected_images,
                "search_context": {
                    "original_query": user_query,
                    "estimated_topic": context.estimated_topic,
                    "has_images": len(selected_images) > 0,
                    "confidence": context.confidence,
                    "text_sources": search_result.get("text_count", 0),
                    "image_sources": len(selected_images),
                    "selected_image_type": image_selection.get("selected_image_type", "None"),
                    "is_text_only_mode": is_text_only_mode  # ìƒˆ í”Œë˜ê·¸ ì¶”ê°€
                },
                "generation_metadata": {
                    "method": "dynamic_vector_search_with_early_text_only_detection",
                    "search_quality": context.confidence,
                    "llm_model": "gemini-1.5-pro",
                    "vector_db_used": True,
                    "image_selection_method": "early_detection" if is_text_only_mode else "llm_analysis"
                },
                "created_at": datetime.now().isoformat()
            }
            
            selected_type = image_selection.get("selected_image_type", "None")
            reason = image_selection.get("reason", "ì„ íƒ ì´ìœ  ì—†ìŒ")
            print(f"âœ… ë™ì  ë¬¸ì œ ìƒì„± ì™„ë£Œ: ì´ë¯¸ì§€ íƒ€ì… '{selected_type}' ì„ íƒ")
            print(f"   ğŸ’¡ ì„ íƒ ì´ìœ : {reason}")
            
            return result
        
        except Exception as e:
            print(f"âŒ ë¬¸ì œ ìƒì„± ì‹¤íŒ¨: {e}")
            return {"error": f"ë™ì  ìƒì„± ì¤‘ ì˜¤ë¥˜: {str(e)}"}
    
    def _generate_question_only(self, context: SearchContext) -> Optional[Dict]:
        """ ì´ë¯¸ì§€ ì„ íƒ ì—†ì´ ë¬¸ì œë§Œ ìƒì„± """
        
        prompt = f"""ë‹¹ì‹ ì€ í•œêµ­ ì˜ì‚¬êµ­ê°€ê³ ì‹œ ë¬¸ì œ ì¶œì œ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.

    # ì‚¬ìš©ì ìš”ì²­
    ì‚¬ìš©ìê°€ "{context.query}"ì— ëŒ€í•œ ë¬¸ì œë¥¼ ìš”ì²­í–ˆìŠµë‹ˆë‹¤.

    # ë²¡í„°DB ê²€ìƒ‰ ê²°ê³¼
    ì¶”ì • ì˜ë£Œ ì£¼ì œ: {context.estimated_topic}
    ê²€ìƒ‰ ì‹ ë¢°ë„: {context.confidence}

    ## ê´€ë ¨ ì˜í•™ ì§€ì‹
    {context.text_content[:2000]}

    # ìƒì„± ì§€ì¹¨
    1. í•œêµ­ ì˜ì‚¬êµ­ê°€ê³ ì‹œ í˜•ì‹ì˜ 5ì§€ì„ ë‹¤ ê°ê´€ì‹ ë¬¸ì œ 1ê°œ ìƒì„±
    2. ì‹¤ì œ ì„ìƒ ìƒí™©ì„ ë°˜ì˜í•œ í™˜ì ì¦ë¡€ í¬í•¨
    3. ìœ„ì˜ ê²€ìƒ‰ëœ ì˜ë£Œ ì§€ì‹ì„ ìµœëŒ€í•œ í™œìš©
    4. í•œêµ­ ì˜ë£Œ í™˜ê²½ê³¼ ìš©ì–´ì— ë§ê²Œ ì‘ì„±

    # ì¶œë ¥ í˜•ì‹
    ë‹¤ìŒ JSON í˜•ì‹ìœ¼ë¡œë§Œ ì‘ë‹µí•˜ì„¸ìš”:

    {{
        "question": "ë¬¸ì œ ë³¸ë¬¸ (í™˜ì ì¦ë¡€ í¬í•¨)",
        "options": ["ë³´ê¸°1", "ë³´ê¸°2", "ë³´ê¸°3", "ë³´ê¸°4", "ë³´ê¸°5"],
        "answer": ì •ë‹µ_ì¸ë±ìŠ¤_ìˆ«ì(0-4),
        "explanation": "ì •ë‹µ ê·¼ê±° ë° í•´ì„¤",
        "topic_analysis": {{
            "estimated_topic": "LLMì´ íŒë‹¨í•œ ì •í™•í•œ ì˜ë£Œ ì£¼ì œ",
            "difficulty_level": "ì´ˆê¸‰/ì¤‘ê¸‰/ê³ ê¸‰",
            "clinical_relevance": "high/medium/low"
        }},
        "source_utilization": "ê²€ìƒ‰ëœ ì •ë³´ë¥¼ ì–´ë–»ê²Œ í™œìš©í–ˆëŠ”ì§€ ì„¤ëª…"
    }}

    ê²€ìƒ‰ëœ ì˜í•™ ì§€ì‹ì„ ì¶©ì‹¤íˆ ë°˜ì˜í•˜ì—¬ ì •í™•í•˜ê³  êµìœ¡ì  ê°€ì¹˜ê°€ ë†’ì€ ë¬¸ì œë¥¼ ìƒì„±í•˜ì„¸ìš”."""

        try:
            response = self.gemini_client.generate_content(prompt)
            
            # JSON ì¶”ì¶œ
            import re
            json_match = re.search(r'\{.*\}', response.text, re.DOTALL)
            
            if json_match:
                return json.loads(json_match.group())
            else:
                print("   âš ï¸ LLMì´ JSON í˜•ì‹ìœ¼ë¡œ ì‘ë‹µí•˜ì§€ ì•ŠìŒ")
                return {"error": "JSON íŒŒì‹± ì‹¤íŒ¨", "raw_response": response.text}
                
        except Exception as e:
            print(f"   âŒ ë¬¸ì œ ìƒì„± ì‹¤íŒ¨: {e}")
            return {"error": str(e)}

    def _select_appropriate_image(self, generated_question: Dict, context: SearchContext) -> Dict:
        """ìƒì„±ëœ ë¬¸ì œë¥¼ ë¶„ì„í•˜ì—¬ ì ì ˆí•œ ì´ë¯¸ì§€ íƒ€ì… ì„ íƒ"""
        
        question_text = generated_question.get("question", "")
        explanation = generated_question.get("explanation", "")
        topic_analysis = generated_question.get("topic_analysis", {})
    # ìˆ˜ì •ëœ ì´ë¯¸ì§€ ì„ íƒ í”„ë¡¬í”„íŠ¸
        selection_prompt = f"""ë‹¹ì‹ ì€ ì˜ë£Œ ì˜ìƒ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ë‹¤ìŒ ë¬¸ì œë¥¼ ë¶„ì„í•˜ì—¬ í‰ë¶€ X-rayê°€ í•„ìš”í•œì§€ íŒë‹¨í•˜ì„¸ìš”.

# ì›ë³¸ ì‚¬ìš©ì ì¿¼ë¦¬
"{context.query}"

# ìƒì„±ëœ ë¬¸ì œ ë‚´ìš©
ë¬¸ì œ: {question_text}
í•´ì„¤: {explanation}
ì¶”ì • ì£¼ì œ: {topic_analysis.get('estimated_topic', 'Unknown')}

# í•µì‹¬ íŒë‹¨ ê¸°ì¤€
**ë°˜ë“œì‹œ Noneì„ ì„ íƒí•´ì•¼ í•˜ëŠ” ê²½ìš°:**
- ì›ë³¸ ì¿¼ë¦¬ì™€ ìƒì„±ëœ ë¬¸ì œì˜ ì£¼ì œê°€ ì™„ì „íˆ ë‹¤ë¥¸ ê²½ìš°
- ì™¸ìƒì™¸ê³¼: ì—´ìƒ, ê³¨ì ˆ, í™”ìƒ, ì™¸ìƒ ë“±
- ì •í˜•ì™¸ê³¼: ê´€ì ˆ, ê·¼ê³¨ê²©ê³„ ì§ˆí™˜
- ë‚´ê³¼ ë¹„í‰ë¶€: ë‹¹ë‡¨ë³‘, ì‹ ì¥ì§ˆí™˜, ê°„ì§ˆí™˜, ë‚´ë¶„ë¹„ ë“±
- í”¼ë¶€ê³¼, ì•ˆê³¼, ì´ë¹„ì¸í›„ê³¼ ì§ˆí™˜
- ì‹¤í—˜ì‹¤ ê²€ì‚¬, í˜ˆì•¡ê²€ì‚¬, ì†Œë³€ê²€ì‚¬ ì¤‘ì‹¬ ë¬¸ì œ
- ì•½ë¬¼ ì¹˜ë£Œ, ìˆ˜ìˆ  ì ì‘ì¦ ë“± ë¹„ì˜ìƒ ë¬¸ì œ

**í‰ë¶€ X-rayê°€ í•„ìš”í•œ ê²½ìš°ë§Œ:**
- í, ê¸°ê´€ì§€, í‰ë§‰, ì‹¬ì¥ ì§ˆí™˜
- í˜¸í¡ê¸° ê°ì—¼, íë ´, ê²°í•µ
- í‰í†µ, í˜¸í¡ê³¤ë€ì˜ ì›ì¸ ì§„ë‹¨
- ëª…í™•í•œ í‰ë¶€ ì˜ìƒ ì†Œê²¬ì´ ì–¸ê¸‰ëœ ê²½ìš°

# ì„ íƒ ì˜µì…˜
1. Pneumonia (íë ´) - íê°ì—¼, ë°œì—´, ê¸°ì¹¨, ê°€ë˜
2. Effusion (í‰ìˆ˜) - ëŠ‘ë§‰ì‚¼ì¶œ, í˜¸í¡ê³¤ë€
3. Mass (ì¢…ê´´) - íì¢…ê´´, íì•”, ì¢…ì–‘
4. Nodule (ê²°ì ˆ) - íê²°ì ˆ, ì†Œê²°ì ˆ
5. Pneumothorax (ê¸°í‰) - ê¸°í‰, í‰í†µ, ì‘ê¸‰
6. Atelectasis (ë¬´ê¸°í) - íí—ˆíƒˆ, ìˆ˜ìˆ í›„
7. Infiltrate (ì¹¨ìœ¤/ê²½í™”) - íì¹¨ìœ¤, ê²½í™”
8. Cardiomegaly (ì‹¬ì¥ë¹„ëŒ€) - ì‹¬ë¶€ì „, ì‹¬ì¥í™•ëŒ€
9. **None (í…ìŠ¤íŠ¸ ì „ìš©)** - í‰ë¶€ X-ray ë¶ˆí•„ìš”

# ì¶œë ¥ í˜•ì‹
{{
    "selected_image_type": "ì„ íƒëœ_íƒ€ì…_ë˜ëŠ”_None",
    "korean_name": "í•œêµ­ì–´ëª…_ë˜ëŠ”_í…ìŠ¤íŠ¸ì „ìš©",
    "reason": "ì„ íƒ ê·¼ê±° (íŠ¹íˆ None ì„ íƒì‹œ ìƒì„¸ ì´ìœ )",
    "relevance_score": ì ìˆ˜(1-10),
    "is_chest_related": true/false,
    "query_match": "ì›ë³¸ ì¿¼ë¦¬ì™€ ë¬¸ì œ ì¼ì¹˜ë„ (high/medium/low)"
}}

**ì£¼ì˜: ì›ë³¸ ì¿¼ë¦¬ "{context.query}"ì™€ ìƒì„±ëœ ë¬¸ì œê°€ ë‹¤ë¥¸ ì˜ë£Œ ë¶„ì•¼ë¼ë©´ ë°˜ë“œì‹œ Noneì„ ì„ íƒí•˜ì„¸ìš”!**"""


        try:
            response = self.gemini_client.generate_content(selection_prompt)
            
            # JSON ì¶”ì¶œ
            import re
            json_match = re.search(r'\{.*\}', response.text, re.DOTALL)
            
            if json_match:
                selection_result = json.loads(json_match.group())
                
                # ìœ íš¨ì„± ê²€ì¦
                valid_types = [
                    "Pneumonia", "Effusion", "Mass", "Nodule", 
                    "Pneumothorax", "Atelectasis", "Infiltrate", "Cardiomegaly", "None"
                ]
                
                selected_type = selection_result.get("selected_image_type", "None")
                if selected_type not in valid_types:
                    print(f"   âš ï¸ ì˜ëª»ëœ ì´ë¯¸ì§€ íƒ€ì…: {selected_type}, Noneìœ¼ë¡œ ì„¤ì •")
                    selection_result["selected_image_type"] = "None"
                    selection_result["reason"] = "ìœ íš¨í•˜ì§€ ì•Šì€ ì„ íƒìœ¼ë¡œ ì¸í•œ í…ìŠ¤íŠ¸ ì „ìš© ì²˜ë¦¬"
                
                # í‰ë¶€ ë¬´ê´€ ì£¼ì œ ì²˜ë¦¬ ì¶”ê°€
                is_chest_related = selection_result.get("is_chest_related", True)
                if not is_chest_related:
                    print(f"   ğŸ“ í‰ë¶€ ë¬´ê´€ ì£¼ì œë¡œ íŒë‹¨: í…ìŠ¤íŠ¸ ì „ìš© ì²˜ë¦¬")
                    selection_result["selected_image_type"] = "None"
                
                return selection_result
            
            else:
                print("   âš ï¸ ì´ë¯¸ì§€ ì„ íƒ JSON íŒŒì‹± ì‹¤íŒ¨")
                return {
                    "selected_image_type": "None",
                    "korean_name": "ì´ë¯¸ì§€ ì—†ìŒ",
                    "reason": "LLM ì‘ë‹µ íŒŒì‹± ì‹¤íŒ¨",
                    "relevance_score": 1,
                    "alternative_types": []
                }
                
        except Exception as e:
            print(f"   âŒ ì´ë¯¸ì§€ ì„ íƒ ì‹¤íŒ¨: {e}")
            return {
                "selected_image_type": "None",
                "korean_name": "ì´ë¯¸ì§€ ì—†ìŒ", 
                "reason": f"ì„ íƒ ê³¼ì •ì—ì„œ ì˜¤ë¥˜ ë°œìƒ: {str(e)}",
                "relevance_score": 1,
                "alternative_types": []
            }

    def _fetch_selected_images(self, image_selection: Dict, search_result: Dict) -> List[Dict]:
        """ì„ íƒëœ ì´ë¯¸ì§€ íƒ€ì…ìœ¼ë¡œ ì‹¤ì œ ì´ë¯¸ì§€ ê²€ìƒ‰"""
        
        selected_type = image_selection.get("selected_image_type", "None")
        
        if selected_type == "None":
            print("   ğŸ“ ì´ë¯¸ì§€ ì—†ìŒ (LLM íŒë‹¨)")
            return []
        
        print(f"   ğŸ–¼ï¸ '{selected_type}' íƒ€ì… ì´ë¯¸ì§€ ê²€ìƒ‰ ì¤‘...")
        
        try:
            # ì„ íƒëœ ì§ˆë³‘ìœ¼ë¡œ ì´ë¯¸ì§€ ê²€ìƒ‰ (ê¸°ì¡´ search_engine í™œìš©)
            dummy_vector = [0.0] * 512
            filter_condition = {"primary_label": {"$eq": selected_type}}
            
            # í•´ë‹¹ ì§ˆë³‘ ì´ë¯¸ì§€ ìˆ˜ í™•ì¸
            disease_info = self.search_engine.config.DISEASE_INFO.get(selected_type, {})
            available_count = disease_info.get('count', 0)
            
            if available_count == 0:
                print(f"   âš ï¸ '{selected_type}' ì´ë¯¸ì§€ ì—†ìŒ")
                return []
            
            search_count = min(3, available_count)  # ìµœëŒ€ 3ê°œ
            
            results = self.search_engine.image_index.query(
                vector=dummy_vector,
                filter=filter_condition,
                top_k=search_count,
                include_metadata=True
            )
            
            selected_images = []
            for match in results['matches']:
                metadata = match['metadata']
                selected_images.append({
                    'image_id': match['id'],
                    'disease': selected_type,
                    'labels': metadata.get('labels', []),
                    'description': metadata.get('all_descriptions', ''),
                    'primary_label': metadata.get('primary_label', ''),
                    'image_path': metadata.get('image_path', ''),
                    'bbox_info': metadata.get('bboxes', []),
                    'relevance_score': 1.0,
                    'selection_method': 'llm_choice'
                })
            
            print(f"   âœ… {len(selected_images)}ê°œ '{selected_type}' ì´ë¯¸ì§€ ë°œê²¬")
            return selected_images
            
        except Exception as e:
            print(f"   âŒ '{selected_type}' ì´ë¯¸ì§€ ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
            return []
    
    def _create_search_context(self, search_result: Dict, user_query: str) -> SearchContext:
        """ê²€ìƒ‰ ê²°ê³¼ë¥¼ êµ¬ì¡°í™”ëœ ì»¨í…ìŠ¤íŠ¸ë¡œ ë³€í™˜ (ì´ë¯¸ì§€ ê²½ë¡œ í¬í•¨)"""
        
        # ê¸°ë³¸ ì •ë³´ ì¶”ì¶œ
        text_content = search_result.get("text_content", "")
        image_info = search_result.get("image_info", "")
        confidence = search_result.get("confidence", "low")
        
        # ì´ë¯¸ì§€ ê²°ê³¼ì—ì„œ ì‹¤ì œ ê²½ë¡œ ì¶”ì¶œ
        images = search_result.get("images", [])
        has_images = len(images) > 0
        
        # ì²« ë²ˆì§¸ ì´ë¯¸ì§€ì˜ ê²½ë¡œ ì¶”ì¶œ
        primary_image_path = ""
        if images and isinstance(images, list):
            first_image = images[0]
            if isinstance(first_image, dict):
                primary_image_path = first_image.get("image_path", "")
        
        estimated_topic = search_result.get("korean_diagnosis", "ë¯¸ìƒ") or search_result.get("diagnosis", "Unknown")
        
        context = SearchContext(
            query=user_query,
            text_content=text_content,
            image_info=image_info,
            confidence=confidence,
            has_images=has_images,
            estimated_topic=estimated_topic,
            primary_image_path=primary_image_path  # ì¶”ê°€
        )
        
        print(f"   ğŸ“Š ì»¨í…ìŠ¤íŠ¸ ìƒì„±: {context.estimated_topic} (ì‹ ë¢°ë„: {confidence})")
        print(f"   ğŸ–¼ï¸ ì´ë¯¸ì§€ í¬í•¨: {has_images}")
        if primary_image_path:
            print(f"   ğŸ“· ì´ë¯¸ì§€ ê²½ë¡œ: {Path(primary_image_path).name}")
        
        return context

    
    def _generate_with_llm_analysis(self, context: SearchContext) -> Optional[Dict]:
        """LLMì´ ì»¨í…ìŠ¤íŠ¸ë¥¼ ë¶„ì„í•˜ê³  ì ì ˆí•œ ë¬¸ì œ ìƒì„±"""
        
        # ë™ì  í”„ë¡¬í”„íŠ¸ ìƒì„±
        prompt = self._create_dynamic_prompt(context)
        
        try:
            response = self.gemini_client.generate_content(prompt)
            
            # JSON ì¶”ì¶œ
            import re
            json_match = re.search(r'\{.*\}', response.text, re.DOTALL)
            
            if json_match:
                return json.loads(json_match.group())
            else:
                print("   âš ï¸ LLMì´ JSON í˜•ì‹ìœ¼ë¡œ ì‘ë‹µí•˜ì§€ ì•ŠìŒ")
                return {"error": "JSON íŒŒì‹± ì‹¤íŒ¨", "raw_response": response.text}
                
        except Exception as e:
            print(f"   âŒ LLM í˜¸ì¶œ ì‹¤íŒ¨: {e}")
            return {"error": str(e)}
    
    def _create_dynamic_prompt(self, context: SearchContext) -> str:
        """ì»¨í…ìŠ¤íŠ¸ ê¸°ë°˜ ë™ì  í”„ë¡¬í”„íŠ¸ ìƒì„±"""
        
        # ì´ë¯¸ì§€ ìœ ë¬´ì— ë”°ë¥¸ ì¡°ê±´ë¶€ í”„ë¡¬í”„íŠ¸
        image_instruction = ""
        if context.has_images:
            image_instruction = """
ì´ ë¬¸ì œëŠ” í‰ë¶€ X-ray ì´ë¯¸ì§€ì™€ í•¨ê»˜ ì œì‹œë  ì˜ˆì •ì…ë‹ˆë‹¤. 
ë¬¸ì œëŠ” ë°˜ë“œì‹œ ì´ë¯¸ì§€ í•´ì„ì´ í•„ìš”í•˜ë„ë¡ êµ¬ì„±í•˜ì„¸ìš”.
"""
        else:
            image_instruction = """
ì´ ë¬¸ì œëŠ” ì´ë¯¸ì§€ ì—†ì´ í…ìŠ¤íŠ¸ë§Œìœ¼ë¡œ êµ¬ì„±ë©ë‹ˆë‹¤.
ì„ìƒ ì¦ë¡€ì™€ ê²€ì‚¬ ê²°ê³¼ ì„¤ëª…ì— ì§‘ì¤‘í•˜ì„¸ìš”.
"""
        
        # ì‹ ë¢°ë„ì— ë”°ë¥¸ ì¡°ê±´ë¶€ í”„ë¡¬í”„íŠ¸
        confidence_instruction = ""
        if context.confidence == "high":
            confidence_instruction = "ê²€ìƒ‰ëœ ì˜ë£Œ ì •ë³´ì˜ ì‹ ë¢°ë„ê°€ ë†’ìœ¼ë¯€ë¡œ, êµ¬ì²´ì ì´ê³  ì „ë¬¸ì ì¸ ë¬¸ì œë¥¼ ìƒì„±í•˜ì„¸ìš”."
        elif context.confidence == "medium":
            confidence_instruction = "ê²€ìƒ‰ëœ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ í•˜ë˜, ì¼ë°˜ì ì¸ ì˜í•™ ì§€ì‹ë„ í™œìš©í•˜ì—¬ ë¬¸ì œë¥¼ ë³´ì™„í•˜ì„¸ìš”."
        else:
            confidence_instruction = "ê²€ìƒ‰ ì •ë³´ê°€ ì œí•œì ì´ë¯€ë¡œ, í•´ë‹¹ ì£¼ì œì˜ ê¸°ë³¸ì ì´ê³  í•µì‹¬ì ì¸ ë‚´ìš©ìœ¼ë¡œ ë¬¸ì œë¥¼ êµ¬ì„±í•˜ì„¸ìš”."
        
        prompt = f"""ë‹¹ì‹ ì€ í•œêµ­ ì˜ì‚¬êµ­ê°€ê³ ì‹œ ë¬¸ì œ ì¶œì œ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.

# ì‚¬ìš©ì ìš”ì²­
ì‚¬ìš©ìê°€ "{context.query}"ì— ëŒ€í•œ ë¬¸ì œë¥¼ ìš”ì²­í–ˆìŠµë‹ˆë‹¤.

# ë²¡í„°DB ê²€ìƒ‰ ê²°ê³¼
ì¶”ì • ì˜ë£Œ ì£¼ì œ: {context.estimated_topic}
ê²€ìƒ‰ ì‹ ë¢°ë„: {context.confidence}

## ê´€ë ¨ ì˜í•™ ì§€ì‹
{context.text_content[:2000]}  

## ì´ë¯¸ì§€ ì •ë³´
{context.image_info}

# ìƒì„± ì§€ì¹¨

## ê¸°ë³¸ ìš”êµ¬ì‚¬í•­
1. í•œêµ­ ì˜ì‚¬êµ­ê°€ê³ ì‹œ í˜•ì‹ì˜ 5ì§€ì„ ë‹¤ ê°ê´€ì‹ ë¬¸ì œ 1ê°œ ìƒì„±
2. ì‹¤ì œ ì„ìƒ ìƒí™©ì„ ë°˜ì˜í•œ í™˜ì ì¦ë¡€ í¬í•¨
3. ìœ„ì˜ ê²€ìƒ‰ëœ ì˜ë£Œ ì§€ì‹ì„ ìµœëŒ€í•œ í™œìš©
4. í•œêµ­ ì˜ë£Œ í™˜ê²½ê³¼ ìš©ì–´ì— ë§ê²Œ ì‘ì„±

## ì¡°ê±´ë¶€ ì§€ì¹¨
{image_instruction}

{confidence_instruction}

## ì¶œë ¥ í˜•ì‹
ë‹¤ìŒ JSON í˜•ì‹ìœ¼ë¡œë§Œ ì‘ë‹µí•˜ì„¸ìš”:

{{
    "question": "ë¬¸ì œ ë³¸ë¬¸ (í™˜ì ì¦ë¡€ í¬í•¨)",
    "options": ["ë³´ê¸°1", "ë³´ê¸°2", "ë³´ê¸°3", "ë³´ê¸°4", "ë³´ê¸°5"],
    "answer": ì •ë‹µ_ì¸ë±ìŠ¤_ìˆ«ì(0-4),
    "explanation": "ì •ë‹µ ê·¼ê±° ë° í•´ì„¤",
    "topic_analysis": {{
        "estimated_topic": "LLMì´ íŒë‹¨í•œ ì •í™•í•œ ì˜ë£Œ ì£¼ì œ",
        "difficulty_level": "ì´ˆê¸‰/ì¤‘ê¸‰/ê³ ê¸‰",
        "clinical_relevance": "high/medium/low",
        "requires_image": {str(context.has_images).lower()}
    }},
    "source_utilization": "ê²€ìƒ‰ëœ ì •ë³´ë¥¼ ì–´ë–»ê²Œ í™œìš©í–ˆëŠ”ì§€ ì„¤ëª…"
}}

ê²€ìƒ‰ëœ ì˜í•™ ì§€ì‹ì„ ì¶©ì‹¤íˆ ë°˜ì˜í•˜ì—¬ ì •í™•í•˜ê³  êµìœ¡ì  ê°€ì¹˜ê°€ ë†’ì€ ë¬¸ì œë¥¼ ìƒì„±í•˜ì„¸ìš”."""

        return prompt
    
    def generate_multiple_dynamic(self, queries: List[str], questions_per_query: int = 2) -> List[Dict]:
        """ì—¬ëŸ¬ ì¿¼ë¦¬ì— ëŒ€í•´ ë™ì  ë¬¸ì œ ìƒì„±"""
        
        print(f"\nğŸ”„ ë‹¤ì¤‘ ë™ì  ìƒì„±: {len(queries)}ê°œ ì¿¼ë¦¬")
        print("="*50)
        
        all_results = []
        
        for i, query in enumerate(queries):
            print(f"\nğŸ“‹ {i+1}/{len(queries)}: '{query}'")
            
            for j in range(questions_per_query):
                print(f"   {j+1}/{questions_per_query} ë²ˆì§¸ ë¬¸ì œ...")
                
                result = self.generate_question_from_query(query)
                
                if "error" not in result:
                    result["sequence"] = len(all_results) + 1
                    result["batch_query"] = query
                    all_results.append(result)
                    
                    topic = result["generated_question"].get("topic_analysis", {}).get("estimated_topic", "Unknown")
                    print(f"   âœ… ìƒì„± ì™„ë£Œ: {topic}")
                else:
                    print(f"   âŒ ìƒì„± ì‹¤íŒ¨: {result['error']}")
        
        print(f"\nğŸ¯ ì´ {len(all_results)}ê°œ ë¬¸ì œ ë™ì  ìƒì„± ì™„ë£Œ")
        return all_results
    
    def evaluate_dynamic_quality(self, results: List[Dict]) -> Dict[str, Any]:
        """ë™ì  ìƒì„± ë¬¸ì œë“¤ì˜ í’ˆì§ˆ í‰ê°€"""
        
        if not results:
            return {"error": "í‰ê°€í•  ê²°ê³¼ê°€ ì—†ìŒ"}
        
        print(f"\nğŸ“Š ë™ì  ìƒì„± í’ˆì§ˆ í‰ê°€ ({len(results)}ê°œ ë¬¸ì œ)")
        print("="*50)
        
        # í†µê³„ ìˆ˜ì§‘
        confidence_levels = []
        has_images_count = 0
        difficulty_distribution = {"ì´ˆê¸‰": 0, "ì¤‘ê¸‰": 0, "ê³ ê¸‰": 0}
        clinical_relevance = {"high": 0, "medium": 0, "low": 0}
        
        for result in results:
            # ê²€ìƒ‰ í’ˆì§ˆ
            search_context = result.get("search_context", {})
            confidence_levels.append(search_context.get("confidence", "low"))
            
            if search_context.get("has_images", False):
                has_images_count += 1
            
            # LLM ë¶„ì„ í’ˆì§ˆ
            question_data = result.get("generated_question", {})
            topic_analysis = question_data.get("topic_analysis", {})
            
            difficulty = topic_analysis.get("difficulty_level", "ì¤‘ê¸‰")
            if difficulty in difficulty_distribution:
                difficulty_distribution[difficulty] += 1
            
            relevance = topic_analysis.get("clinical_relevance", "medium")
            if relevance in clinical_relevance:
                clinical_relevance[relevance] += 1
        
        # í‰ê°€ ê²°ê³¼
        high_quality_count = len([c for c in confidence_levels if c == "high"])
        quality_rate = (high_quality_count / len(confidence_levels)) * 100
        
        evaluation = {
            "summary": {
                "total_questions": len(results),
                "high_confidence_rate": round(quality_rate, 1),
                "image_supported_rate": round((has_images_count / len(results)) * 100, 1),
                "average_confidence": self._calculate_avg_confidence(confidence_levels)
            },
            "quality_distribution": {
                "search_confidence": dict(zip(*zip(*[(c, confidence_levels.count(c)) for c in set(confidence_levels)]))),
                "difficulty_levels": difficulty_distribution,
                "clinical_relevance": clinical_relevance
            },
            "system_performance": {
                "vector_search_success": len([r for r in results if "error" not in r]),
                "llm_generation_success": len([r for r in results if "generated_question" in r]),
                "end_to_end_success_rate": round(len(results) / len(results) * 100, 1)
            }
        }
        
        # ê²°ê³¼ ì¶œë ¥
        print(f"ğŸ“ˆ ê³ ì‹ ë¢°ë„ ë¹„ìœ¨: {quality_rate:.1f}%")
        print(f"ğŸ–¼ï¸ ì´ë¯¸ì§€ ì§€ì›: {evaluation['summary']['image_supported_rate']:.1f}%")
        print(f"ğŸ¯ í‰ê·  ê²€ìƒ‰ í’ˆì§ˆ: {evaluation['summary']['average_confidence']}")
        
        return evaluation
    
    def _calculate_avg_confidence(self, confidence_levels: List[str]) -> str:
        """í‰ê·  ì‹ ë¢°ë„ ê³„ì‚°"""
        scores = {"high": 3, "medium": 2, "low": 1}
        avg_score = sum(scores.get(c, 1) for c in confidence_levels) / len(confidence_levels)
        
        if avg_score >= 2.5:
            return "high"
        elif avg_score >= 1.5:
            return "medium"
        else:
            return "low"
    
    def save_dynamic_results(self, results: List[Dict], filename: str = None) -> str:
        """ë™ì  ìƒì„± ê²°ê³¼ ì €ì¥"""
        
        if not filename:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            filename = f"dynamic_generated_{timestamp}.json"
        
        save_dir = Path("generated_questions")
        save_dir.mkdir(exist_ok=True)
        
        filepath = save_dir / filename
        
        # ë©”íƒ€ë°ì´í„°ì™€ í•¨ê»˜ ì €ì¥
        save_data = {
            "metadata": {
                "generation_method": "dynamic_vector_search",
                "total_questions": len(results),
                "generation_date": datetime.now().isoformat(),
                "system_version": "Dynamic Generator v1.0",
                "vector_db": "Phase IV RAG System",
                "llm_model": "Gemini 1.5 Pro"
            },
            "results": results
        }
        
        with open(filepath, 'w', encoding='utf-8') as f:
            json.dump(save_data, f, ensure_ascii=False, indent=2)
        
        print(f"ğŸ’¾ ë™ì  ìƒì„± ê²°ê³¼ ì €ì¥: {filepath}")
        return str(filepath)

# í¸ì˜ í•¨ìˆ˜ë“¤
def create_dynamic_generator() -> DynamicQuestionGenerator:
    """ë™ì  ìƒì„±ê¸° ì¸ìŠ¤í„´ìŠ¤ ìƒì„±"""
    return DynamicQuestionGenerator()

def quick_dynamic_generate(query: str = "íë ´") -> Dict:
    """ë¹ ë¥¸ ë™ì  ë¬¸ì œ ìƒì„±"""
    print(f"ğŸš€ ë¹ ë¥¸ ë™ì  ìƒì„±: '{query}'")
    
    try:
        generator = create_dynamic_generator()
        result = generator.generate_question_from_query(query)
        
        if "error" not in result:
            print(f"\nâœ… ë™ì  ìƒì„± ì„±ê³µ!")
            question_data = result["generated_question"]
            topic_analysis = question_data.get("topic_analysis", {})
            
            print(f"ğŸ“‹ ì¶”ì • ì£¼ì œ: {topic_analysis.get('estimated_topic', 'Unknown')}")
            print(f"ğŸ“Š ë‚œì´ë„: {topic_analysis.get('difficulty_level', 'Unknown')}")
            print(f"ğŸ¥ ì„ìƒ ê´€ë ¨ì„±: {topic_analysis.get('clinical_relevance', 'Unknown')}")
            print(f"ğŸ–¼ï¸ ì´ë¯¸ì§€ í•„ìš”: {topic_analysis.get('requires_image', False)}")
            
            return result
        else:
            print(f"âŒ ìƒì„± ì‹¤íŒ¨: {result['error']}")
            return result
            
    except Exception as e:
        print(f"âŒ ì˜¤ë¥˜: {e}")
        return {"error": str(e)}

def demo_dynamic_generation() -> None:
    """ë™ì  ìƒì„± ì‹œìŠ¤í…œ ë°ëª¨"""
    print("ğŸ¯ ë™ì  ë¬¸ì œ ìƒì„± ë°ëª¨")
    print("="*50)
    
    # ë‹¤ì–‘í•œ ì˜ë£Œ ì£¼ì œ í…ŒìŠ¤íŠ¸
    test_queries = [
        "íë ´ ì§„ë‹¨",           # ì´ë¯¸ì§€ + í…ìŠ¤íŠ¸
        "ê²°í•µ ì¹˜ë£Œ",           # í…ìŠ¤íŠ¸ ìœ„ì£¼
        "ê¸°í‰ ì‘ê¸‰ì²˜ì¹˜",       # ì´ë¯¸ì§€ + í…ìŠ¤íŠ¸
        "ì‹¬ë¶€ì „ ê´€ë¦¬",         # í…ìŠ¤íŠ¸ ìœ„ì£¼
        "íìƒ‰ì „ì¦ ì§„ë‹¨",       # í…ìŠ¤íŠ¸ ìœ„ì£¼
        "í‰ìˆ˜ ì²œììˆ "          # ì´ë¯¸ì§€ + í…ìŠ¤íŠ¸
    ]
    
    try:
        generator = create_dynamic_generator()
        results = generator.generate_multiple_dynamic(test_queries, questions_per_query=1)
        
        if results:
            filepath = generator.save_dynamic_results(results, "demo_dynamic.json")
            evaluation = generator.evaluate_dynamic_quality(results)
            
            print(f"\nğŸ‰ ë™ì  ìƒì„± ë°ëª¨ ì™„ë£Œ!")
            print(f"   ğŸ“ ì €ì¥: {filepath}")
            print(f"   ğŸ“Š ê³ ì‹ ë¢°ë„ ë¹„ìœ¨: {evaluation['summary']['high_confidence_rate']}%")
            print(f"   ğŸ–¼ï¸ ì´ë¯¸ì§€ ì§€ì›: {evaluation['summary']['image_supported_rate']}%")
            
        else:
            print("âŒ ë¬¸ì œ ìƒì„± ì‹¤íŒ¨")
            
    except Exception as e:
        print(f"âŒ ë°ëª¨ ì‹¤í–‰ ì‹¤íŒ¨: {e}")

if __name__ == "__main__":
    import sys
    from pathlib import Path
    
    if len(sys.argv) > 1:
        command = sys.argv[1].lower()
        
        if command == "test":
            query = sys.argv[2] if len(sys.argv) > 2 else "íë ´"
            quick_dynamic_generate(query)
            
        elif command == "demo":
            demo_dynamic_generation()
            
        else:
            print("ì‚¬ìš©ë²•:")
            print("  python dynamic_question_generator.py test [ì˜ë£Œì£¼ì œ]")
            print("  python dynamic_question_generator.py demo")
    
    else:
        print("ğŸ¤– ë™ì  ì˜ë£Œ ë¬¸ì œ ìƒì„± ì‹œìŠ¤í…œ")
        print("ë²¡í„°DB ê²€ìƒ‰ â†’ LLM ììœ¨ íŒë‹¨ â†’ ì ì‘í˜• ë¬¸ì œ ìƒì„±")