import sys
sys.path.append('./search')

from search.search_engine import SearchEngine
from generation.context_builder import LLMContextBuilder
from generation.prompt_engineer import PromptEngineer

def main():
    print("ğŸš€ Phase 5: Step 2 - ì „ì²´ íŒŒì´í”„ë¼ì¸ í†µí•© í…ŒìŠ¤íŠ¸")
    
    # 1. ê²€ìƒ‰
    print("\n[1/4] ê²€ìƒ‰ ì—”ì§„ ì‹¤í–‰...")
    engine = SearchEngine()
    search_result = engine.search_text("ê¸°í‰ì´ ì˜ì‹¬ë˜ëŠ” í™˜ì")
    if "error" in search_result:
        print(f"âŒ ê²€ìƒ‰ ì‹¤íŒ¨: {search_result['error']}")
        return
    print("âœ… ê²€ìƒ‰ ì„±ê³µ!")

    # 2. ì»¨í…ìŠ¤íŠ¸ ìƒì„±
    print("\n[2/4] LLMContextBuilder ì‹¤í–‰...")
    try:
        builder = LLMContextBuilder(search_result)
        llm_context = builder.build_context_for_llm()
        primary_image_path = builder.get_primary_image_path()
        print("âœ… ì»¨í…ìŠ¤íŠ¸ ë° ì´ë¯¸ì§€ ê²½ë¡œ ìƒì„± ì„±ê³µ!")
    except ValueError as e:
        print(f"âŒ ì»¨í…ìŠ¤íŠ¸ ìƒì„± ì‹¤íŒ¨: {e}")
        return

    # 3. í”„ë¡¬í”„íŠ¸ ì—”ì§€ë‹ˆì–´ë§
    print("\n[3/4] PromptEngineer ì‹¤í–‰...")
    try:
        engineer = PromptEngineer(context=llm_context, image_path=primary_image_path)
        final_prompt = engineer.create_question_generation_prompt()
        print("âœ… ìµœì¢… í”„ë¡¬í”„íŠ¸ ìƒì„± ì„±ê³µ!")
    except ValueError as e:
        print(f"âŒ í”„ë¡¬í”„íŠ¸ ìƒì„± ì‹¤íŒ¨: {e}")
        return

    # 4. ìµœì¢… í”„ë¡¬í”„íŠ¸ í™•ì¸
    print("\n[4/4] Geminiì—ê²Œ ì „ë‹¬ë  ìµœì¢… í”„ë¡¬í”„íŠ¸:")
    print("=" * 70)
    print(final_prompt)
    print("=" * 70)
    print("\nğŸ‰ ëª¨ë“  íŒŒì´í”„ë¼ì¸ì´ ì„±ê³µì ìœ¼ë¡œ ì—°ê²°ë˜ì—ˆìŠµë‹ˆë‹¤!")

if __name__ == "__main__":
    main()