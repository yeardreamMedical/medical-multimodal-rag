# search/search_engine.py
# í†µí•©ëœ ë©€í‹°ëª¨ë‹¬ ê²€ìƒ‰ ì—”ì§„ - ëª¨ë“  ê²€ìƒ‰ ë¡œì§ì„ í•˜ë‚˜ì˜ íŒŒì¼ì— í†µí•©
from datetime import datetime
import os
import re
import torch
import numpy as np
from pathlib import Path
from PIL import Image
from typing import List, Dict, Any, Optional
from dotenv import load_dotenv
from pinecone import Pinecone
from openai import OpenAI

# BioViL-T ëª¨ë¸ import
from health_multimodal.image.model.pretrained import get_biovil_t_image_encoder
from health_multimodal.image.data.transforms import create_chest_xray_transform_for_inference

# --- ì„¤ì • ë° ìƒìˆ˜ ---
load_dotenv()

class SearchConfig:
    """ê²€ìƒ‰ ì‹œìŠ¤í…œ ì„¤ì • ë° ìƒìˆ˜"""
    
    # API ì„¤ì •
    PINECONE_API_KEY = os.getenv("PINECONE_API_KEY")
    OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
    
    # ëª¨ë¸ ì„¤ì •
    DEVICE = "cuda" if torch.cuda.is_available() else "cpu"
    TEXT_EMBEDDING_MODEL = "text-embedding-3-small"
    
    # ì¸ë±ìŠ¤ ì„¤ì •
    TEXT_INDEX_NAME = "textbook-rag"
    IMAGE_INDEX_NAME = "cxr-image-meta-v2"
    
    # ì§ˆë³‘ ì •ë³´
    DISEASE_INFO = {
        "Effusion": {"count": 51, "korean": "í‰ìˆ˜", "exam_weight": "ë†’ìŒ"},
        "Infiltrate": {"count": 44, "korean": "ì¹¨ìœ¤/ê²½í™”", "exam_weight": "ë†’ìŒ"},
        "Atelectasis": {"count": 31, "korean": "ë¬´ê¸°í", "exam_weight": "ì¤‘ê°„"},
        "Pneumonia": {"count": 23, "korean": "íë ´", "exam_weight": "ë§¤ìš°ë†’ìŒ"},
        "Mass": {"count": 22, "korean": "ì¢…ê´´", "exam_weight": "ë†’ìŒ"},
        "Pneumothorax": {"count": 12, "korean": "ê¸°í‰", "exam_weight": "ë†’ìŒ"},
        "Cardiomegaly": {"count": 11, "korean": "ì‹¬ì¥ë¹„ëŒ€", "exam_weight": "ì¤‘ê°„"},
        "Nodule": {"count": 3, "korean": "ê²°ì ˆ", "exam_weight": "ë‚®ìŒ"}
    }
    
    # ì¿¼ë¦¬ í™•ì¥ í…œí”Œë¦¿
    QUERY_EXPANSION_TEMPLATES = {
        # ì˜ì–´ ì§ˆë³‘ëª…
        "pneumonia": "pneumonia diagnosis treatment bacterial viral lung infection chest disease",
        "effusion": "pleural effusion chest fluid thoracentesis drainage respiratory",
        "pleural effusion": "pleural effusion chest fluid thoracentesis drainage blunting costophrenic",
        "pneumothorax": "pneumothorax collapsed lung tension emergency chest tube",
        "atelectasis": "atelectasis lung collapse volume loss postoperative",
        "consolidation": "consolidation pneumonia lung opacity air space disease",
        "infiltrate": "infiltrate lung opacity consolidation pneumonia infection",
        "mass": "lung mass tumor lesion CT evaluation oncology",
        "cardiomegaly": "cardiomegaly enlarged heart failure cardiothoracic ratio",
        "nodule": "lung nodule pulmonary nodule CT scan evaluation",
        
        # í•œêµ­ì–´ ì§ˆë³‘ëª…
        "íë ´": "íë ´ ì§„ë‹¨ ì¹˜ë£Œ í•­ìƒì œ ì„¸ê· ì„± ë°”ì´ëŸ¬ìŠ¤ì„± íê°ì—¼ í˜¸í¡ê¸°ì§ˆí™˜",
        "í‰ìˆ˜": "í‰ìˆ˜ ëŠ‘ë§‰ì‚¼ì¶œ ì²œììˆ  ë°°ì•¡ í˜¸í¡ê³¤ë€ í‰ë¶€ ëŠ‘ê³¨íš¡ê²©ë§‰ê°",
        "ê¸°í‰": "ê¸°í‰ í—ˆíƒˆ ê¸´ì¥ì„± ì‘ê¸‰ìƒí™© í‰ê´€ì‚½ì… ì¹˜ë£Œ ê³µê¸°ëˆ„ì¶œ",
        "ë¬´ê¸°í": "ë¬´ê¸°í í—ˆíƒˆ ë¶€í”¼ê°ì†Œ ìˆ˜ìˆ í›„ í•©ë³‘ì¦ í˜¸í¡ê¸°",
        "ì¹¨ìœ¤": "ì¹¨ìœ¤ íì¹¨ìœ¤ ê²½í™” ê°ì—¼ ìŒì˜ ì§ˆí™˜ ì‹¤ì§ˆ",
        "ê²½í™”": "ê²½í™” íê²½í™” ê³µê¸°ê³µê°„ì§ˆí™˜ ìŒì˜ ì§„ë‹¨ íë ´",
        "ì¢…ê´´": "ì¢…ê´´ íì¢…ê´´ ì¢…ì–‘ ë³‘ë³€ CTê²€ì‚¬ í‰ê°€ ê²°ì ˆ",
        "ì‹¬ì¥ë¹„ëŒ€": "ì‹¬ì¥ë¹„ëŒ€ ì‹¬ë¶€ì „ ì‹¬í‰ê³½ë¹„ ì‹¬ì´ˆìŒíŒŒ ê²€ì‚¬",
        "ê²°ì ˆ": "ê²°ì ˆ íê²°ì ˆ ì¢…ê´´ ë³‘ë³€ CTê²€ì‚¬ ì•…ì„± ì–‘ì„±"
    }
    
    # ì¿¼ë¦¬-ì§ˆë³‘ ì§ì ‘ ë§¤í•‘
    QUERY_DISEASE_MAPPING = {
        "pneumonia": "Pneumonia", "íë ´": "Pneumonia",
        "effusion": "Effusion", "í‰ìˆ˜": "Effusion", "pleural effusion": "Effusion",
        "pneumothorax": "Pneumothorax", "ê¸°í‰": "Pneumothorax", 
        "atelectasis": "Atelectasis", "ë¬´ê¸°í": "Atelectasis",
        "consolidation": "Infiltrate", "ì¹¨ìœ¤": "Infiltrate", "ê²½í™”": "Infiltrate", "infiltrate": "Infiltrate",
        "mass": "Mass", "ì¢…ê´´": "Mass",
        "cardiomegaly": "Cardiomegaly", "ì‹¬ì¥ë¹„ëŒ€": "Cardiomegaly",
        "nodule": "Nodule", "ê²°ì ˆ": "Nodule"
    }
    
    # ì§ˆë³‘ë³„ ìƒì„¸ ë§¤í•‘
    DISEASE_MAPPINGS = {
        "Pneumonia": {
            "exact_match": ["pneumonia", "íë ´"],
            "partial_match": ["bacterial pneumonia", "viral pneumonia", "lung infection"],
            "korean_match": ["íë ´", "ì„¸ê· ì„±íë ´", "ë°”ì´ëŸ¬ìŠ¤íë ´"],
            "exclude_if_found": ["pneumothorax"]
        },
        "Pneumothorax": {
            "exact_match": ["pneumothorax", "ê¸°í‰"],
            "partial_match": ["collapsed lung", "tension pneumothorax"],
            "korean_match": ["ê¸°í‰", "ê¸´ì¥ì„±ê¸°í‰"],
            "exclude_if_found": ["pneumonia"]
        },
        "Effusion": {
            "exact_match": ["effusion", "í‰ìˆ˜", "pleural effusion"],
            "partial_match": ["pleural fluid", "chest fluid"],
            "korean_match": ["í‰ìˆ˜", "ëŠ‘ë§‰ì‚¼ì¶œ", "ê°€ìŠ´ë¬¼"],
            "exclude_if_found": []
        },
        "Atelectasis": {
            "exact_match": ["atelectasis", "ë¬´ê¸°í"],
            "partial_match": ["lung collapse", "partial collapse"],
            "korean_match": ["ë¬´ê¸°í", "í—ˆíƒˆ", "íí—ˆíƒˆ"],
            "exclude_if_found": []
        },
        "Infiltrate": {
            "exact_match": ["infiltrate", "ì¹¨ìœ¤", "consolidation"],
            "partial_match": ["lung opacity", "parenchymal opacity", "ê²½í™”"],
            "korean_match": ["ì¹¨ìœ¤", "ê²½í™”", "íê²½í™”", "íì¹¨ìœ¤"],
            "exclude_if_found": []
        },
        "Mass": {
            "exact_match": ["mass", "ì¢…ê´´"],
            "partial_match": ["tumor", "lesion", "nodular opacity"],
            "korean_match": ["ì¢…ê´´", "ì¢…ì–‘", "ë©ì–´ë¦¬"],
            "exclude_if_found": []
        },
        "Cardiomegaly": {
            "exact_match": ["cardiomegaly", "ì‹¬ì¥ë¹„ëŒ€"],
            "partial_match": ["enlarged heart", "cardiac enlargement"],
            "korean_match": ["ì‹¬ì¥ë¹„ëŒ€", "ì‹¬ì¥í™•ëŒ€"],
            "exclude_if_found": []
        },
        "Nodule": {
            "exact_match": ["nodule", "ê²°ì ˆ"],
            "partial_match": ["lung nodule", "pulmonary nodule"],
            "korean_match": ["ê²°ì ˆ", "íê²°ì ˆ"],
            "exclude_if_found": []
        }
    }


class QueryProcessor:
    """ì¿¼ë¦¬ í™•ì¥ ë° ì „ì²˜ë¦¬"""
    
    def __init__(self, config: SearchConfig):
        self.config = config
        self.templates = config.QUERY_EXPANSION_TEMPLATES
        # LLM í´ë¼ì´ì–¸íŠ¸ ì¶”ê°€
        try:
            import google.generativeai as genai
            api_key = os.getenv("GEMINI_API_KEY")
            if api_key:
                genai.configure(api_key=api_key)
                self.llm_client = genai.GenerativeModel('gemini-1.5-pro')
                print("âœ… ì¿¼ë¦¬ í™•ì¥ìš© LLM í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì™„ë£Œ")
            else:
                self.llm_client = None
                print("âš ï¸ GEMINI_API_KEY ì—†ìŒ: ê¸°ë³¸ í…œí”Œë¦¿ ë°©ì‹ ì‚¬ìš©")
        except ImportError:
            self.llm_client = None
            print("âš ï¸ Gemini íŒ¨í‚¤ì§€ ì—†ìŒ: ê¸°ë³¸ í…œí”Œë¦¿ ë°©ì‹ ì‚¬ìš©")
    
    def expand_query(self, query: str) -> str:
        """LLM ê¸°ë°˜ ë™ì  ì¿¼ë¦¬ í™•ì¥ + ê¸°ì¡´ í…œí”Œë¦¿ fallback"""
        query_lower = query.lower().strip()
        
        # 1. ê¸°ì¡´ í…œí”Œë¦¿ ë°©ì‹ ì‹œë„ (ë¹ ë¥¸ ì²˜ë¦¬)
        template_expanded = self._try_template_expansion(query, query_lower)
        if template_expanded != query:
            print(f"    í…œí”Œë¦¿ í™•ì¥: '{query}' â†’ '{template_expanded[:80]}...'")
            return template_expanded
        
        # 2. LLM ë™ì  í™•ì¥ ì‹œë„
        if self.llm_client:
            llm_expanded = self._expand_with_llm(query)
            if llm_expanded and llm_expanded != query:
                print(f"    LLM ë™ì  í™•ì¥: '{query}' â†’ '{llm_expanded[:80]}...'")
                return llm_expanded
        
        # 3. ì¼ë°˜ ì˜ë£Œ í‚¤ì›Œë“œ ì¶”ê°€ (ìµœì¢… fallback)
        fallback_expanded = self._add_general_medical_keywords(query)
        print(f"    ì¼ë°˜ ì˜ë£Œ í™•ì¥: '{query}' â†’ '{fallback_expanded}'")
        return fallback_expanded
    
    def _try_template_expansion(self, query: str, query_lower: str) -> str:
        """ê¸°ì¡´ í…œí”Œë¦¿ ë°©ì‹ í™•ì¥ ì‹œë„"""
        # ì§ì ‘ ë§¤ì¹­ í™•ì¸
        for term, expansion in self.templates.items():
            if term in query_lower:
                return f"{query} {expansion}"
        
        # ë¶€ë¶„ ë§¤ì¹­ í™•ì¸
        for term, expansion in self.templates.items():
            if any(word in query_lower for word in term.split()):
                return f"{query} {expansion}"
        
        return query  # í™•ì¥ ì‹¤íŒ¨ì‹œ ì›ë³¸ ë°˜í™˜
    
    def _expand_with_llm(self, query: str) -> str:
        """LLMì„ ì‚¬ìš©í•œ ë™ì  ì¿¼ë¦¬ í™•ì¥ - ê¸¸ì´ ì œí•œ ê°•í™”"""
        try:
            prompt = f"""ë‹¹ì‹ ì€ ì˜ë£Œ ì •ë³´ ê²€ìƒ‰ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ë‹¤ìŒ ì¿¼ë¦¬ë¥¼ ì˜ë£Œ ë¬¸í—Œ ê²€ìƒ‰ì— ìµœì í™”ëœ í˜•íƒœë¡œ í™•ì¥í•˜ì„¸ìš”.

    ì›ë³¸ ì¿¼ë¦¬: "{query}"

    ì§€ì¹¨:
    1. ì›ë³¸ ì¿¼ë¦¬ + í•µì‹¬ í‚¤ì›Œë“œ 3-4ê°œë§Œ ì¶”ê°€
    2. ì´ ê¸¸ì´ëŠ” ì›ë³¸ì˜ 2ë°°ë¥¼ ë„˜ì§€ ë§ ê²ƒ
    3. ë™ì˜ì–´, ê´€ë ¨ ì¦ìƒ, ì§„ë‹¨ ë°©ë²• ì¤‘ì‹¬
    4. í•œêµ­ì–´ì™€ ì˜ì–´ë¥¼ ì ì ˆíˆ ì¡°í•©
    5. ê°„ê²°í•˜ê³  ê²€ìƒ‰ì— ìœ ìš©í•œ í‚¤ì›Œë“œë§Œ ì„ íƒ

    ì˜ˆì‹œ:
    - "ì—´ìƒ" â†’ "ì—´ìƒ ìƒì²˜ ë´‰í•© ì™¸ìƒ laceration wound suture"
    - "íë ´" â†’ "íë ´ pneumonia ë°œì—´ ê¸°ì¹¨ ê°ì—¼ respiratory"

    í™•ì¥ëœ ì¿¼ë¦¬ë§Œ ì¶œë ¥í•˜ì„¸ìš” (ì„¤ëª… ë¶ˆí•„ìš”):"""

            response = self.llm_client.generate_content(prompt)
            expanded = response.text.strip()
            
            # ìœ ì—°í•œ ê¸¸ì´ ê²€ì¦ (ì§§ì€ ì¿¼ë¦¬ ê³ ë ¤)
            if len(query) <= 5:  # ë§¤ìš° ì§§ì€ ì¿¼ë¦¬ (ì˜ˆ: "ì—´ìƒ", "íë ´")
                max_length = 80
            elif len(query) <= 15:  # ì¤‘ê°„ ê¸¸ì´ ì¿¼ë¦¬ (ì˜ˆ: "ì—´ìƒ í™˜ì ì¹˜ë£Œ")
                max_length = 120
            else:  # ê¸´ ì¿¼ë¦¬
                max_length = len(query) * 2
            
            if len(expanded) > max_length:
                print(f"    âš ï¸ LLM í™•ì¥ ê²°ê³¼ê°€ ë„ˆë¬´ ê¹€ ({len(expanded)}ì > {max_length}ì), ê¸°ë³¸ ë°©ì‹ ì‚¬ìš©")
                return query
            
            # ì˜ë¯¸ì—†ëŠ” ë°˜ë³µì´ë‚˜ ì„¤ëª… ì œê±°
            if "ì˜ˆì‹œ:" in expanded or "ì„¤ëª…:" in expanded or "ì§€ì¹¨:" in expanded:
                print(f"    âš ï¸ LLMì´ ì„¤ëª…ì„ í¬í•¨í•¨, ê¸°ë³¸ ë°©ì‹ ì‚¬ìš©")
                return query
            
            # ì›ë³¸ê³¼ ë„ˆë¬´ ìœ ì‚¬í•˜ë©´ í™•ì¥ íš¨ê³¼ ì—†ìŒ
            if expanded.lower().strip() == query.lower().strip():
                print(f"    âš ï¸ LLM í™•ì¥ íš¨ê³¼ ì—†ìŒ, ê¸°ë³¸ ë°©ì‹ ì‚¬ìš©")
                return query
            
            return expanded
            
        except Exception as e:
            print(f"    âš ï¸ LLM ì¿¼ë¦¬ í™•ì¥ ì‹¤íŒ¨: {e}")
            return query
    
    def _add_general_medical_keywords(self, query: str) -> str:
        """ì¼ë°˜ ì˜ë£Œ í‚¤ì›Œë“œ ì¶”ê°€ (ìµœì¢… fallback)"""
        # ì¿¼ë¦¬ì—ì„œ ì˜ë£Œ ë§¥ë½ ê°ì§€
        medical_indicators = [
            'í™˜ì', 'ì§„ë‹¨', 'ì¹˜ë£Œ', 'ì¦ìƒ', 'ì§ˆí™˜', 'ë³‘ì›', 'ì˜ì‚¬',
            'patient', 'diagnosis', 'treatment', 'symptom', 'disease'
        ]
        
        if any(indicator in query.lower() for indicator in medical_indicators):
            return f"{query} ì§„ë‹¨ ì¹˜ë£Œ ì¦ìƒ í™˜ì ì˜ë£Œ clinical diagnosis treatment medical"
        else:
            return f"{query} ì˜ë£Œ ì§„ë‹¨ medical diagnosis clinical"


class DiseaseExtractor:
    """ì§ˆë³‘ëª… ì¶”ì¶œ ë° ì§ì ‘ ë§¤ì¹­ ë³´ë„ˆìŠ¤"""
    
    def __init__(self, config: SearchConfig):
        self.config = config
        self.disease_mappings = config.DISEASE_MAPPINGS
        self.query_mapping = config.QUERY_DISEASE_MAPPING
        # ì œì™¸ íŒ¨í„´ ê°•í™” (ë” êµ¬ì²´ì ìœ¼ë¡œ)
        self.exclusion_patterns = {
            'pneumonia': [
                r'\b(?:not|no|without|absence of|rule out|r/o)\s+pneumonia\b',
                r'\bpneumothorax\s+(?:not|rather than|instead of)\s+pneumonia\b',
                r'\b(?:pneumothorax|effusion|mass)\s+(?:not|rather than)\s+pneumonia\b'
            ],
            'pneumothorax': [
                r'\b(?:not|no|without|absence of|rule out|r/o)\s+pneumothorax\b',
                r'\bpneumonia\s+(?:not|rather than|instead of)\s+pneumothorax\b'
            ],
            'effusion': [
                r'\b(?:not|no|without|absence of|rule out|r/o)\s+(?:pleural\s+)?effusion\b',
                r'\b(?:pneumonia|pneumothorax)\s+(?:not|rather than)\s+effusion\b'
            ]
        }
    
    def extract_diseases(self, text_results: List[Dict], query: str = "") -> List[str]:
        """í…ìŠ¤íŠ¸ ê²°ê³¼ì—ì„œ ì§ˆë³‘ì„ ì¶”ì¶œí•˜ê³  ì ìˆ˜ ê³„ì‚° - ìˆ˜ì •ëœ ë²„ì „"""
        
        # ê¸°ë³¸ ì ìˆ˜ ê³„ì‚° (ê¸°ì¡´ ë©”ì„œë“œ ì‚¬ìš©)
        disease_scores = self._calculate_basic_scores(text_results)
        
        # ì¿¼ë¦¬ ì§ì ‘ ë§¤ì¹­ ë³´ë„ˆìŠ¤ ì ìš©
        direct_match_found = self._apply_direct_matching_bonus(disease_scores, query)
        
        # ê²°ê³¼ ì •ë ¬ ë° í•„í„°ë§
        predicted_diseases = self._filter_and_sort_diseases(disease_scores, direct_match_found)
        
        return predicted_diseases
    
    def _calculate_basic_scores(self, text_results: List[Dict]) -> Dict[str, float]:
        """ê¸°ë³¸ ì§ˆë³‘ ì ìˆ˜ ê³„ì‚°"""
        disease_scores = {disease: 0 for disease in self.disease_mappings.keys()}
        
        for chunk in text_results:
            content = chunk['content']
            similarity = chunk['similarity']
            
            for disease, mapping_info in self.disease_mappings.items():
                disease_score = 0
                
                # ì œì™¸ íŒ¨í„´ í™•ì¸
                if self._has_exclusion_pattern(content, mapping_info["exclude_if_found"]):
                    continue
                
                # ì ìˆ˜ ê³„ì‚°
                disease_score += self._calculate_exact_matches(content, mapping_info["exact_match"], similarity)
                disease_score += self._calculate_partial_matches(content, mapping_info["partial_match"], similarity)
                disease_score += self._calculate_korean_matches(content, mapping_info["korean_match"], similarity)
                
                disease_scores[disease] += disease_score
        
        return disease_scores
    
    def _has_exclusion_pattern(self, content: str, exclude_terms: List[str]) -> bool:
        """ì œì™¸ íŒ¨í„´ì´ ìˆëŠ”ì§€ í™•ì¸"""
        for exclude_term in exclude_terms:
            if self._is_exact_word_match(content, exclude_term):
                print(f"    ì œì™¸ íŒ¨í„´ ë°œê²¬: '{exclude_term}' ë°œê²¬")
                return True
        return False
    
    def _calculate_exact_matches(self, content: str, exact_terms: List[str], similarity: float) -> float:
        """ì •í™•í•œ ë§¤ì¹­ ì ìˆ˜ ê³„ì‚°"""
        score = 0
        for exact_term in exact_terms:
            if self._is_exact_word_match(content, exact_term):
                count = self._count_exact_matches(content, exact_term)
                weight = 3.0
                score += similarity * weight * count
                print(f"    ì •í™•í•œ ë§¤ì¹­: '{exact_term}' (ê°€ì¤‘ì¹˜: {weight}, íšŸìˆ˜: {count})")
        return score
    
    def _calculate_partial_matches(self, content: str, partial_terms: List[str], similarity: float) -> float:
        """ë¶€ë¶„ ë§¤ì¹­ ì ìˆ˜ ê³„ì‚°"""
        score = 0
        for partial_term in partial_terms:
            if partial_term.lower() in content.lower():
                count = content.lower().count(partial_term.lower())
                weight = 1.5
                score += similarity * weight * count
        return score
    
    def _calculate_korean_matches(self, content: str, korean_terms: List[str], similarity: float) -> float:
        """í•œêµ­ì–´ ë§¤ì¹­ ì ìˆ˜ ê³„ì‚°"""
        score = 0
        for korean_term in korean_terms:
            if korean_term in content:
                count = content.count(korean_term)
                weight = 2.0
                score += similarity * weight * count
        return score
    
    def _apply_direct_matching_bonus(self, disease_scores: Dict[str, float], original_query: str) -> bool:
        """ì¿¼ë¦¬ ì§ì ‘ ë§¤ì¹­ ë³´ë„ˆìŠ¤ ì ìš©"""
        direct_match_found = False
        
        if original_query:
            query_lower = original_query.lower()
            for term, disease in self.query_mapping.items():
                if term in query_lower and disease in disease_scores:
                    original_score = disease_scores[disease]
                    disease_scores[disease] += 100.0  # ê°•ë ¥í•œ ë³´ë„ˆìŠ¤
                    print(f"    ğŸš€ ì¿¼ë¦¬ ì§ì ‘ ë§¤ì¹­ ë³´ë„ˆìŠ¤: {disease} {original_score:.3f} â†’ {disease_scores[disease]:.3f}")
                    direct_match_found = True
                    break
        
        return direct_match_found
    
    def _filter_and_sort_diseases(self, disease_scores: Dict[str, float], direct_match_found: bool) -> List[str]:
        """ì§ˆë³‘ ì ìˆ˜ ì •ë ¬ ë° í•„í„°ë§ - í…ìŠ¤íŠ¸ ì „ìš© í”Œë˜ê·¸ ì¶”ê°€"""
        sorted_diseases = sorted(disease_scores.items(), key=lambda x: x[1], reverse=True)
        
        # ì„ê³„ê°’ ì ìš©
        min_threshold = 0.05 if direct_match_found else 0.1
        predicted_diseases = [disease for disease, score in sorted_diseases if score > min_threshold]
        
        # ê²°ê³¼ ì¶œë ¥
        print(f"   ğŸ¯ ì§ˆë³‘ ì˜ˆì¸¡ ê²°ê³¼:")
        for i, (disease, score) in enumerate(sorted_diseases[:5]):
            korean = self.config.DISEASE_INFO[disease]['korean']
            status = "âœ…" if score > min_threshold else "âŒ"
            bonus_mark = "ğŸš€" if direct_match_found and score > 50 else ""
            print(f"      {i+1}. {disease} ({korean}): {score:.3f}ì  {status} {bonus_mark}")
        
        # **í•µì‹¬ ìˆ˜ì •**: ëª¨ë“  ì§ˆë³‘ì´ ë§¤ì¹­ ì‹¤íŒ¨ì‹œ í…ìŠ¤íŠ¸ ì „ìš© í‘œì‹œ
        if not predicted_diseases:
            max_score = sorted_diseases[0][1] if sorted_diseases else 0
            if max_score < 0.1:  # ë§¤ìš° ë‚®ì€ ì ìˆ˜
                print("   ğŸ“ ì§ˆë³‘ ë§¤ì¹­ ì‹¤íŒ¨ â†’ í…ìŠ¤íŠ¸ ì „ìš© ëª¨ë“œ ì„¤ì •")
                return ["TEXT_ONLY"]  # íŠ¹ë³„í•œ í”Œë˜ê·¸ ë°˜í™˜
            else:
                # ê¸°ì¡´ fallback ë¡œì§
                predicted_diseases = sorted(self.config.DISEASE_INFO.keys(), 
                                        key=lambda x: self.config.DISEASE_INFO[x]['count'], reverse=True)
                print("   âš ï¸ fallback ì ìš©: ë°ì´í„° ë³´ìœ ëŸ‰ ìˆœ")
        
        return predicted_diseases
    
    def _is_exact_word_match(self, text: str, word: str) -> bool:
        """ë‹¨ì–´ ê²½ê³„ë¥¼ ê³ ë ¤í•œ ì •í™•í•œ ë§¤ì¹­"""
        pattern = r'\b' + re.escape(word.lower()) + r'\b'
        return bool(re.search(pattern, text.lower()))
    
    def _count_exact_matches(self, text: str, word: str) -> int:
        """ì •í™•í•œ ë‹¨ì–´ ë§¤ì¹­ íšŸìˆ˜ ê³„ì‚°"""
        pattern = r'\b' + re.escape(word.lower()) + r'\b'
        return len(re.findall(pattern, text.lower()))


class ImageSearcher:
    """ì´ë¯¸ì§€ ê²€ìƒ‰ ë° ì„ë² ë”© ì²˜ë¦¬"""
    
    def __init__(self, config: SearchConfig, image_index, image_encoder, image_transform):
        self.config = config
        self.image_index = image_index
        self.image_encoder = image_encoder
        self.image_transform = image_transform
    
    def search_by_diseases(self, predicted_diseases: List[str], top_k: int = 3) -> List[Dict]:
        """ì˜ˆì¸¡ëœ ì§ˆë³‘ë“¤ë¡œ ì´ë¯¸ì§€ DBì—ì„œ ì •í™•í•œ ë¼ë²¨ ë§¤ì¹­ ê²€ìƒ‰"""
        all_images = []
        dummy_vector = [0.0] * 512  # í•„í„°ë§ì—ì„œëŠ” ë²¡í„° ë¬´ê´€
        
        print(f"ğŸ–¼ï¸ ì´ë¯¸ì§€ ê²€ìƒ‰: ì˜ˆì¸¡ëœ ì§ˆë³‘ë³„ ì •í™•í•œ ë§¤ì¹­")
        
        for disease in predicted_diseases[:3]:  # ìƒìœ„ 3ê°œ ì§ˆë³‘
            try:
                filter_condition = {"primary_label": {"$eq": disease}}
                available_count = self.config.DISEASE_INFO.get(disease, {}).get('count', 0)
                search_count = min(top_k, available_count)
                
                if search_count > 0:
                    results = self.image_index.query(
                        vector=dummy_vector,
                        filter=filter_condition,
                        top_k=search_count,
                        include_metadata=True
                    )
                    
                    for match in results['matches']:
                        metadata = match['metadata']
                        all_images.append({
                            'image_id': match['id'],
                            'disease': disease,
                            'labels': metadata.get('labels', []),
                            'description': metadata.get('all_descriptions', ''),
                            'primary_label': metadata.get('primary_label', ''),
                            'image_path': metadata.get('image_path', ''),
                            'bbox_info': metadata.get('bboxes', []),
                            'relevance_score': 1.0
                        })
                    
                    korean_name = self.config.DISEASE_INFO[disease]['korean']
                    print(f"   âœ… {disease} ({korean_name}): {len(results['matches'])}ê°œ ì´ë¯¸ì§€ ë§¤ì¹­")
                else:
                    print(f"   âš ï¸ {disease}: ì´ë¯¸ì§€ ì—†ìŒ")
                    
            except Exception as e:
                print(f"   âŒ {disease} ì´ë¯¸ì§€ ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
        
        return all_images
    
    def search_by_image(self, image_path: str, top_k: int = 3) -> Dict:
        """ì´ë¯¸ì§€ ê¸°ë°˜ ê²€ìƒ‰"""
        # ì´ë¯¸ì§€ ì„ë² ë”© ìƒì„±
        image_embedding = self._get_image_embedding(image_path)
        
        if not image_embedding:
            return {"error": "ì´ë¯¸ì§€ ì²˜ë¦¬ ì‹¤íŒ¨", "image_path": image_path}
        
        try:
            # ì´ë¯¸ì§€ DBì—ì„œ ìœ ì‚¬ë„ ê²€ìƒ‰
            results = self.image_index.query(
                vector=image_embedding,
                top_k=top_k,
                include_metadata=True
            )
            
            # ê²°ê³¼ ì²˜ë¦¬
            matched_images = []
            for match in results['matches']:
                metadata = match['metadata']
                matched_images.append({
                    'image_id': match['id'],
                    'similarity': match['score'],
                    'disease': metadata.get('primary_label', ''),
                    'labels': metadata.get('labels', []),
                    'description': metadata.get('all_descriptions', ''),
                    'image_path': metadata.get('image_path', '')
                })
            
            # ìµœê³  ìœ ì‚¬ë„ ê²°ê³¼ ê¸°ì¤€ìœ¼ë¡œ ì»¨í…ìŠ¤íŠ¸ ìƒì„±
            if matched_images:
                best_match = matched_images[0]
                primary_disease = best_match['disease']
                korean_name = self.config.DISEASE_INFO.get(primary_disease, {}).get('korean', primary_disease)
                
                return {
                    "query": f"ì´ë¯¸ì§€ ê²€ìƒ‰: {Path(image_path).name}",
                    "diagnosis": primary_disease,
                    "korean_diagnosis": korean_name,
                    "confidence": "high" if best_match['similarity'] > 0.95 else "medium",
                    "search_info": {
                        "strategy": "image_similarity_search",
                        "similarity_score": best_match['similarity'],
                        "matched_images": len(matched_images)
                    },
                    "images": matched_images
                }
            else:
                return {"error": "ìœ ì‚¬í•œ ì´ë¯¸ì§€ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤", "image_path": image_path}
                
        except Exception as e:
            return {"error": f"ì´ë¯¸ì§€ ê²€ìƒ‰ ì‹¤íŒ¨: {e}", "image_path": image_path}
    
    def _get_image_embedding(self, image_path: str) -> Optional[List[float]]:
        """ì‹¤ì œ ì´ë¯¸ì§€ íŒŒì¼ì— ëŒ€í•œ ì„ë² ë”© ìƒì„±"""
        image_path_obj = Path(image_path)
        if not image_path_obj.exists():
            print(f"ê²½ê³ : ì´ë¯¸ì§€ íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {image_path}")
            return None
        
        try:
            # ì´ë¯¸ì§€ ì²˜ë¦¬
            pil_image = Image.open(image_path_obj).convert('L')
            image_tensor = self.image_transform(pil_image)
            batch_tensor = image_tensor.unsqueeze(0).to(self.config.DEVICE)
            
            with torch.no_grad():
                model_output = self.image_encoder(batch_tensor)
                embedding_tensor = model_output.img_embedding
                return embedding_tensor.cpu().detach().numpy().squeeze().tolist()
                
        except Exception as e:
            print(f"ì˜¤ë¥˜: ì´ë¯¸ì§€ ì²˜ë¦¬ ì‹¤íŒ¨ {image_path}: {e}")
            return None


class ContextBuilder:
    """ê²€ìƒ‰ ê²°ê³¼ë¥¼ í†µí•©í•˜ì—¬ ì»¨í…ìŠ¤íŠ¸ ìƒì„±"""
    
    def __init__(self):
        self.max_text_length = 2000
        self.max_images = 3
    
    def create_context(
        self, 
        query: str, 
        text_results: List[Dict], 
        image_results: List[Dict], 
        predicted_diseases: List[str]
    ) -> Dict[str, Any]:
        """í†µí•© ì»¨í…ìŠ¤íŠ¸ ìƒì„± - TEXT_ONLY í”Œë˜ê·¸ ì²˜ë¦¬ ì¶”ê°€"""
        
        # í…ìŠ¤íŠ¸ ë‚´ìš© í†µí•© (ê¸¸ì´ ì œí•œ)
        text_content = self._combine_text_results(text_results)
        
        # **í•µì‹¬ ìˆ˜ì •**: TEXT_ONLY í”Œë˜ê·¸ í™•ì¸
        is_text_only = len(predicted_diseases) == 1 and predicted_diseases[0] == "TEXT_ONLY"
        
        if is_text_only:
            # í…ìŠ¤íŠ¸ ì „ìš© ëª¨ë“œ
            primary_diagnosis = "Unknown"
            korean_diagnosis = "í…ìŠ¤íŠ¸ ì „ìš© (í‰ë¶€ ê´€ë ¨ì„± ë‚®ìŒ)"
            image_info = "ì´ë¯¸ì§€ ê²€ìƒ‰ ìƒëµ (í‰ë¶€ ë¬´ê´€ ì£¼ì œ)"
            confidence_level = "medium"  # í…ìŠ¤íŠ¸ ê¸°ë°˜ì´ë¯€ë¡œ ì¤‘ê°„ ì‹ ë¢°ë„
            print(f"   ğŸ“ í…ìŠ¤íŠ¸ ì „ìš© ì»¨í…ìŠ¤íŠ¸ ìƒì„±: í‰ë¶€ ë¬´ê´€ ì£¼ì œë¡œ íŒë‹¨")
        else:
            # ê¸°ì¡´ ë¡œì§
            image_info = self._process_image_results(image_results)
            primary_diagnosis = predicted_diseases[0] if predicted_diseases else "Unknown"
            korean_diagnosis = self._get_korean_diagnosis(primary_diagnosis)
            confidence_level = self._calculate_confidence_level(text_results, image_results, predicted_diseases)
        
        context = {
            "query": query,
            "diagnosis": primary_diagnosis,
            "primary_diagnosis": primary_diagnosis,
            "korean_diagnosis": korean_diagnosis,
            "all_diseases": predicted_diseases,
            "text_content": text_content,
            "image_info": image_info,
            "images": [] if is_text_only else image_results,  # í…ìŠ¤íŠ¸ ì „ìš©ì‹œ ë¹ˆ ë¦¬ìŠ¤íŠ¸
            "confidence": confidence_level,
            "text_count": len(text_results),
            "image_count": 0 if is_text_only else len(image_results),
            "is_text_only_mode": is_text_only,  # ìƒˆë¡œìš´ í”Œë˜ê·¸ ì¶”ê°€
            "created_at": datetime.now().isoformat()
        }
        
        print(f"   âœ… ì»¨í…ìŠ¤íŠ¸ ìƒì„± ì™„ë£Œ: {korean_diagnosis}, ì‹ ë¢°ë„: {confidence_level}")
        return context
    
    def _combine_text_results(self, text_results: List[Dict]) -> str:
        """í…ìŠ¤íŠ¸ ê²°ê³¼ë“¤ì„ ê²°í•©"""
        if not text_results:
            return "ê´€ë ¨ í…ìŠ¤íŠ¸ ì •ë³´ ì—†ìŒ"
        
        combined_text = ""
        for result in text_results:
            content = result.get('content', '') or result.get('text', '')
            combined_text += content + " "
        
        # ê¸¸ì´ ì œí•œ
        if len(combined_text) > self.max_text_length:
            combined_text = combined_text[:self.max_text_length] + "..."
        
        return combined_text.strip()
    
    def _process_image_results(self, image_results: List[Dict]) -> str:
        """ì´ë¯¸ì§€ ê²°ê³¼ë“¤ì„ ì²˜ë¦¬"""
        if not image_results:
            return "ê´€ë ¨ ì´ë¯¸ì§€ ì •ë³´ ì—†ìŒ"
        
        processed_info = f"{len(image_results)}ê°œ ê´€ë ¨ ì´ë¯¸ì§€ ë°œê²¬"
        
        # ì£¼ìš” ì´ë¯¸ì§€ ì •ë³´ ì¶”ê°€
        if image_results:
            first_image = image_results[0]
            disease = first_image.get('disease', first_image.get('primary_label', 'Unknown'))
            description = first_image.get('description', '')
            if description:
                processed_info += f" - {description[:100]}"
        
        return processed_info
    
    def _get_korean_diagnosis(self, primary_diagnosis: str) -> str:
        """ì˜ì–´ ì§„ë‹¨ëª…ì„ í•œêµ­ì–´ë¡œ ë³€í™˜"""
        # ì§ì ‘ DISEASE_INFO ì‚¬ìš©
        DISEASE_INFO = {
            "Effusion": {"korean": "í‰ìˆ˜"},
            "Infiltrate": {"korean": "ì¹¨ìœ¤/ê²½í™”"},
            "Atelectasis": {"korean": "ë¬´ê¸°í"},
            "Pneumonia": {"korean": "íë ´"},
            "Mass": {"korean": "ì¢…ê´´"},
            "Pneumothorax": {"korean": "ê¸°í‰"},
            "Cardiomegaly": {"korean": "ì‹¬ì¥ë¹„ëŒ€"},
            "Nodule": {"korean": "ê²°ì ˆ"}
        }
        
        disease_info = DISEASE_INFO.get(primary_diagnosis, {})
        korean_name = disease_info.get('korean', primary_diagnosis)
        
        return f"{korean_name} ({primary_diagnosis})"
    
    def _calculate_confidence_level(self, text_results: List[Dict], image_results: List[Dict], predicted_diseases: List[str]) -> str:
        """ì‹ ë¢°ë„ ë ˆë²¨ ê³„ì‚°"""
        
        confidence_score = 0
        
        # 1. í…ìŠ¤íŠ¸ ê²°ê³¼ ì ìˆ˜ (ìµœëŒ€ 40ì )
        text_score = min(len(text_results) * 10, 40)
        confidence_score += text_score
        
        # 2. ì´ë¯¸ì§€ ê²°ê³¼ ì ìˆ˜ (ìµœëŒ€ 30ì )  
        image_score = min(len(image_results) * 15, 30)
        confidence_score += image_score
        
        # 3. ì§ˆë³‘ ì˜ˆì¸¡ ì ìˆ˜ (ìµœëŒ€ 30ì )
        disease_score = min(len(predicted_diseases) * 10, 30)
        confidence_score += disease_score
        
        # 4. í…ìŠ¤íŠ¸ í’ˆì§ˆ ë³´ë„ˆìŠ¤ (ìµœëŒ€ 10ì )
        if text_results:
            total_text_length = sum(
                len(result.get('content', '') + result.get('text', '')) 
                for result in text_results
            )
            if total_text_length > 500:
                confidence_score += 10
        
        # 5. ì´ë¯¸ì§€ í’ˆì§ˆ ë³´ë„ˆìŠ¤ (ìµœëŒ€ 10ì ) 
        if image_results:
            high_confidence_images = 0
            for img in image_results:
                metadata = img.get('metadata', {})
                if metadata.get('image_confidence', 0) > 0.8:
                    high_confidence_images += 1
            if high_confidence_images > 0:
                confidence_score += 10
        
        # ì‹ ë¢°ë„ ë ˆë²¨ ê²°ì • (ì´ 120ì  ë§Œì )
        if confidence_score >= 80:
            return "high"
        elif confidence_score >= 50:
            return "medium"  
        else:
            return "low"
        
class SearchEngine:
    """í†µí•© ë©€í‹°ëª¨ë‹¬ ê²€ìƒ‰ ì—”ì§„"""
    
    def __init__(self):
        """ê²€ìƒ‰ ì—”ì§„ ì´ˆê¸°í™”"""
        print("ğŸ¥ ë©€í‹°ëª¨ë‹¬ ê²€ìƒ‰ ì—”ì§„ ì´ˆê¸°í™” ì¤‘...")
        
        # ì„¤ì • ë¡œë“œ
        self.config = SearchConfig()
        
        # ì™¸ë¶€ ì„œë¹„ìŠ¤ ì—°ê²°
        self.pc = Pinecone(api_key=self.config.PINECONE_API_KEY)
        self.openai_client = OpenAI(api_key=self.config.OPENAI_API_KEY)
        
        # ì¸ë±ìŠ¤ ì—°ê²°
        self.text_index = self.pc.Index(self.config.TEXT_INDEX_NAME)
        self.image_index = self.pc.Index(self.config.IMAGE_INDEX_NAME)
        
        # BioViL-T ëª¨ë¸ ì´ˆê¸°í™”
        self.image_encoder = get_biovil_t_image_encoder()
        self.image_transform = create_chest_xray_transform_for_inference(resize=512, center_crop_size=480)
        self.image_encoder.to(self.config.DEVICE)
        self.image_encoder.eval()
        
        # ì»´í¬ë„ŒíŠ¸ ì´ˆê¸°í™”
        self.query_processor = QueryProcessor(self.config)
        self.disease_extractor = DiseaseExtractor(self.config)
        self.image_searcher = ImageSearcher(self.config, self.image_index, self.image_encoder, self.image_transform)
        self.context_builder = ContextBuilder()
        
        print("âœ… ê²€ìƒ‰ ì—”ì§„ ì´ˆê¸°í™” ì™„ë£Œ")
    
    def search_text(self, query: str, top_k: int = 5) -> Dict[str, Any]:
        """
        í…ìŠ¤íŠ¸ ê¸°ë°˜ ë©€í‹°ëª¨ë‹¬ ê²€ìƒ‰
        
        Args:
            query: ê²€ìƒ‰ ì¿¼ë¦¬
            top_k: ë°˜í™˜í•  ê²°ê³¼ ìˆ˜
            
        Returns:
            ê²€ìƒ‰ ê²°ê³¼ ë”•ì…”ë„ˆë¦¬
        """
        print(f"\n{'='*60}")
        print(f"ğŸ” í…ìŠ¤íŠ¸ ê¸°ë°˜ ë©€í‹°ëª¨ë‹¬ ê²€ìƒ‰: '{query}'")
        print(f"{'='*60}")
        
        try:
            # 1. ì¿¼ë¦¬ í™•ì¥
            expanded_query = self.query_processor.expand_query(query)
            
            # 2. í…ìŠ¤íŠ¸ ê²€ìƒ‰
            text_results = self._search_text_knowledge(expanded_query, top_k)
            if not text_results:
                return {"error": "ê´€ë ¨ ì˜í•™ ì§€ì‹ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤", "query": query}
            
            # 3. ì§ˆë³‘ ì¶”ì¶œ (ì§ì ‘ ë§¤ì¹­ ë³´ë„ˆìŠ¤ í¬í•¨)
            predicted_diseases = self.disease_extractor.extract_diseases(text_results, query)
            
            # 4. ì´ë¯¸ì§€ ê²€ìƒ‰
            image_results = self.image_searcher.search_by_diseases(predicted_diseases, top_k)
            
            # 5. ì»¨í…ìŠ¤íŠ¸ ìƒì„±
            context = self.context_builder.create_context(query, text_results, image_results, predicted_diseases)
            
            return context
            
        except Exception as e:
            print(f"âŒ ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
            return {"error": f"ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}", "query": query}
    
    def search_image(self, image_path: str, top_k: int = 5) -> Dict[str, Any]:
        """
        ì´ë¯¸ì§€ ê¸°ë°˜ ê²€ìƒ‰
        
        Args:
            image_path: ì´ë¯¸ì§€ íŒŒì¼ ê²½ë¡œ
            top_k: ë°˜í™˜í•  ê²°ê³¼ ìˆ˜
            
        Returns:
            ê²€ìƒ‰ ê²°ê³¼ ë”•ì…”ë„ˆë¦¬
        """
        print(f"\n{'='*60}")
        print(f"ğŸ–¼ï¸ ì´ë¯¸ì§€ ê¸°ë°˜ ê²€ìƒ‰: {image_path}")
        print(f"{'='*60}")
        
        try:
            result = self.image_searcher.search_by_image(image_path, top_k)
            return result
            
        except Exception as e:
            print(f"âŒ ì´ë¯¸ì§€ ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
            return {"error": f"ì´ë¯¸ì§€ ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}", "image_path": image_path}
    
    def _search_text_knowledge(self, query: str, top_k: int = 5) -> List[Dict]:
        """í…ìŠ¤íŠ¸ DBì—ì„œ ì˜í•™ ì§€ì‹ ê²€ìƒ‰"""
        try:
            print(f"ğŸ“š í…ìŠ¤íŠ¸ ì§€ì‹ ê²€ìƒ‰: '{query[:50]}...'")
            
            # OpenAI ì„ë² ë”© ìƒì„±
            resp = self.openai_client.embeddings.create(
                input=[query], 
                model=self.config.TEXT_EMBEDDING_MODEL
            )
            embedding = resp.data[0].embedding
            
            # Pinecone ê²€ìƒ‰
            results = self.text_index.query(
                vector=embedding,
                top_k=top_k,
                include_metadata=True
            )
            
            # ê²°ê³¼ ì²˜ë¦¬
            text_chunks = []
            for match in results['matches']:
                metadata = match['metadata']
                content = metadata.get('text', metadata.get('content', ''))
                text_chunks.append({
                    'content': content,
                    'similarity': match['score'],
                    'source': metadata.get('source', 'unknown'),
                    'id': match['id']
                })
            
            print(f"   âœ… {len(text_chunks)}ê°œ ì§€ì‹ ì²­í¬ ê²€ìƒ‰ ì™„ë£Œ")
            
            # ë””ë²„ê¹… ì •ë³´
            if text_chunks:
                print(f"   ğŸ” ê²€ìƒ‰ëœ ë‚´ìš© ìƒ˜í”Œ:")
                for i, chunk in enumerate(text_chunks[:2]):
                    preview = chunk['content'][:80] + "..." if len(chunk['content']) > 80 else chunk['content']
                    print(f"      {i+1}. (ìœ ì‚¬ë„: {chunk['similarity']:.3f}) {preview}")
            
            return text_chunks
            
        except Exception as e:
            print(f"   âŒ í…ìŠ¤íŠ¸ ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
            return []
    
    def get_system_info(self) -> Dict[str, Any]:
        """ì‹œìŠ¤í…œ ì •ë³´ ë°˜í™˜"""
        try:
            # ì¸ë±ìŠ¤ í†µê³„
            text_stats = self.text_index.describe_index_stats()
            image_stats = self.image_index.describe_index_stats()
            
            return {
                "system_status": "online",
                "device": self.config.DEVICE,
                "text_index": {
                    "name": self.config.TEXT_INDEX_NAME,
                    "total_vectors": text_stats.get('total_vector_count', 0),
                    "dimension": text_stats.get('dimension', 0)
                },
                "image_index": {
                    "name": self.config.IMAGE_INDEX_NAME,
                    "total_vectors": image_stats.get('total_vector_count', 0),
                    "dimension": image_stats.get('dimension', 0)
                },
                "supported_diseases": list(self.config.DISEASE_INFO.keys()),
                "total_diseases": len(self.config.DISEASE_INFO)
            }
        except Exception as e:
            return {"system_status": "error", "error": str(e)}


# --- í…ŒìŠ¤íŠ¸ ë° í‰ê°€ í´ë˜ìŠ¤ ---

class SearchTester:
    """ê²€ìƒ‰ ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸ ë° í‰ê°€"""
    
    def __init__(self, search_engine: SearchEngine):
        self.search_engine = search_engine
    
    def test_accuracy(self) -> float:
        """ì§ˆë³‘ ë§¤ì¹­ ì •í™•ë„ í…ŒìŠ¤íŠ¸"""
        test_cases = [
            {"query": "pneumonia", "expected": "Pneumonia"},
            {"query": "pleural effusion", "expected": "Effusion"},
            {"query": "íë ´", "expected": "Pneumonia"},
            {"query": "í‰ìˆ˜", "expected": "Effusion"},
            {"query": "ê¸°í‰", "expected": "Pneumothorax"},
            {"query": "pneumothorax", "expected": "Pneumothorax"},
            {"query": "consolidation", "expected": "Infiltrate"},
            {"query": "ì‹¬ì¥ë¹„ëŒ€", "expected": "Cardiomegaly"}
        ]
        
        print("\nğŸ¯ ì§ˆë³‘ ë§¤ì¹­ ì •í™•ë„ í…ŒìŠ¤íŠ¸")
        print("="*50)
        
        correct = 0
        total = len(test_cases)
        
        for case in test_cases:
            try:
                result = self.search_engine.search_text(case["query"], top_k=3)
                
                if "error" not in result:
                    predicted = result["diagnosis"]
                    expected = case["expected"]
                    
                    if predicted == expected:
                        correct += 1
                        print(f"âœ… '{case['query']}' â†’ {predicted} - ì •í™•!")
                    else:
                        print(f"âŒ '{case['query']}' â†’ {predicted} (ì˜ˆìƒ: {expected})")
                else:
                    print(f"âŒ '{case['query']}' â†’ ê²€ìƒ‰ ì‹¤íŒ¨: {result['error']}")
                    
            except Exception as e:
                print(f"âŒ '{case['query']}' â†’ ì˜¤ë¥˜: {e}")
        
        accuracy = correct / total * 100
        print(f"\nğŸ“ˆ ì •í™•ë„: {correct}/{total} ({accuracy:.1f}%)")
        
        return accuracy
    
    def test_performance(self) -> Dict[str, float]:
        """ì„±ëŠ¥ í…ŒìŠ¤íŠ¸"""
        import time
        
        print("\nâ±ï¸ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸")
        print("="*30)
        
        test_queries = ["pneumonia", "pleural effusion", "íë ´"]
        times = []
        
        for query in test_queries:
            start_time = time.time()
            try:
                result = self.search_engine.search_text(query, top_k=3)
                end_time = time.time()
                
                duration = end_time - start_time
                times.append(duration)
                
                status = "âœ…" if "error" not in result else "âŒ"
                print(f"{status} '{query}': {duration:.2f}ì´ˆ")
                
            except Exception as e:
                end_time = time.time()
                duration = end_time - start_time
                times.append(duration)
                print(f"âŒ '{query}': {duration:.2f}ì´ˆ (ì˜¤ë¥˜)")
        
        avg_time = sum(times) / len(times) if times else 0
        print(f"\nğŸ“Š í‰ê·  ì‘ë‹µ ì‹œê°„: {avg_time:.2f}ì´ˆ")
        
        return {
            "average_time": avg_time,
            "individual_times": times,
            "total_queries": len(test_queries)
        }
    
    def run_comprehensive_test(self) -> Dict[str, Any]:
        """í¬ê´„ì  í…ŒìŠ¤íŠ¸ ì‹¤í–‰"""
        print("\nğŸ§ª í¬ê´„ì  í…ŒìŠ¤íŠ¸ ì‹¤í–‰")
        print("="*50)
        
        # 1. ì •í™•ë„ í…ŒìŠ¤íŠ¸
        accuracy = self.test_accuracy()
        
        # 2. ì„±ëŠ¥ í…ŒìŠ¤íŠ¸
        performance = self.test_performance()
        
        # 3. ì‹œìŠ¤í…œ ì •ë³´
        system_info = self.search_engine.get_system_info()
        
        # ìµœì¢… ê²°ê³¼
        print(f"\n{'='*50}")
        print(f"ğŸ† ì¢…í•© í…ŒìŠ¤íŠ¸ ê²°ê³¼")
        print(f"{'='*50}")
        print(f"ğŸ¯ ì§ˆë³‘ ë§¤ì¹­ ì •í™•ë„: {accuracy:.1f}%")
        print(f"â±ï¸ í‰ê·  ì‘ë‹µ ì‹œê°„: {performance['average_time']:.2f}ì´ˆ")
        print(f"ğŸ¥ ì§€ì› ì§ˆë³‘ ìˆ˜: {system_info.get('total_diseases', 0)}ê°œ")
        print(f"ğŸ“Š í…ìŠ¤íŠ¸ ë²¡í„° ìˆ˜: {system_info.get('text_index', {}).get('total_vectors', 0):,}ê°œ")
        print(f"ğŸ–¼ï¸ ì´ë¯¸ì§€ ë²¡í„° ìˆ˜: {system_info.get('image_index', {}).get('total_vectors', 0):,}ê°œ")
        
        if accuracy >= 75:
            print("ğŸ‰ ëª©í‘œ ë‹¬ì„±! (75% ì´ìƒ)")
        elif accuracy >= 50:
            print("ğŸŸ¡ ë¶€ë¶„ ê°œì„  (50% ì´ìƒ)")
        else:
            print("ğŸ”´ ì¶”ê°€ ê°œì„  í•„ìš”")
        
        return {
            "accuracy": accuracy,
            "performance": performance,
            "system_info": system_info,
            "status": "excellent" if accuracy >= 75 else "good" if accuracy >= 50 else "needs_improvement"
        }


# --- í¸ì˜ í•¨ìˆ˜ë“¤ ---

def create_search_engine() -> SearchEngine:
    """ê²€ìƒ‰ ì—”ì§„ ì¸ìŠ¤í„´ìŠ¤ ìƒì„±"""
    return SearchEngine()

def quick_test(query: str = "íë ´ ì§„ë‹¨") -> None:
    """ë¹ ë¥¸ í…ŒìŠ¤íŠ¸ ì‹¤í–‰"""
    print(f"ğŸš€ ë¹ ë¥¸ í…ŒìŠ¤íŠ¸: '{query}'")
    
    try:
        engine = create_search_engine()
        result = engine.search_text(query)
        
        if "error" not in result:
            print(f"âœ… ê²°ê³¼: {result['korean_diagnosis']} ({result['diagnosis']})")
            print(f"   ì‹ ë¢°ë„: {result['confidence']}")
            print(f"   ê´€ë ¨ ì´ë¯¸ì§€: {len(result.get('images', []))}ê°œ")
        else:
            print(f"âŒ ì‹¤íŒ¨: {result['error']}")
            
    except Exception as e:
        print(f"âŒ ì˜¤ë¥˜: {e}")

def run_full_evaluation() -> None:
    """ì „ì²´ í‰ê°€ ì‹¤í–‰"""
    try:
        engine = create_search_engine()
        tester = SearchTester(engine)
        results = tester.run_comprehensive_test()
        
        return results
    except Exception as e:
        print(f"âŒ í‰ê°€ ì‹¤í–‰ ì‹¤íŒ¨: {e}")
        return None


# --- ë©”ì¸ ì‹¤í–‰ë¶€ ---

if __name__ == "__main__":
    print("ğŸ¥ Medical Multimodal Search Engine")
    print("=" * 60)
    
    import sys
    
    if len(sys.argv) > 1:
        command = sys.argv[1].lower()
        
        if command == "test":
            # ë¹ ë¥¸ í…ŒìŠ¤íŠ¸
            query = sys.argv[2] if len(sys.argv) > 2 else "íë ´ ì§„ë‹¨"
            quick_test(query)
            
        elif command == "eval":
            # ì „ì²´ í‰ê°€
            run_full_evaluation()
            
        elif command == "info":
            # ì‹œìŠ¤í…œ ì •ë³´
            try:
                engine = create_search_engine()
                info = engine.get_system_info()
                print("ğŸ” ì‹œìŠ¤í…œ ì •ë³´:")
                for key, value in info.items():
                    print(f"  {key}: {value}")
            except Exception as e:
                print(f"âŒ ì‹œìŠ¤í…œ ì •ë³´ ì¡°íšŒ ì‹¤íŒ¨: {e}")
                
        else:
            print("ì‚¬ìš©ë²•:")
            print("  python search_engine.py test [ì¿¼ë¦¬]     # ë¹ ë¥¸ í…ŒìŠ¤íŠ¸")
            print("  python search_engine.py eval           # ì „ì²´ í‰ê°€")
            print("  python search_engine.py info           # ì‹œìŠ¤í…œ ì •ë³´")
    
    else:
        # ê¸°ë³¸ ì‹¤í–‰: ì¸í„°ë™í‹°ë¸Œ ëª¨ë“œ
        try:
            engine = create_search_engine()
            print("\nğŸ¯ ì¸í„°ë™í‹°ë¸Œ ëª¨ë“œ (ì¢…ë£Œ: 'quit')")
            
            while True:
                query = input("\nê²€ìƒ‰ì–´ ì…ë ¥: ").strip()
                
                if query.lower() in ['quit', 'exit', 'ì¢…ë£Œ']:
                    print("ğŸ‘‹ ê²€ìƒ‰ ì—”ì§„ì„ ì¢…ë£Œí•©ë‹ˆë‹¤.")
                    break
                
                if query:
                    result = engine.search_text(query)
                    
                    if "error" not in result:
                        print(f"\nğŸ“Š ê²€ìƒ‰ ê²°ê³¼:")
                        print(f"  ğŸ¯ ì§„ë‹¨: {result['korean_diagnosis']} ({result['diagnosis']})")
                        print(f"  ğŸ“ˆ ì‹ ë¢°ë„: {result['confidence']}")
                        print(f"  ğŸ–¼ï¸ ê´€ë ¨ ì´ë¯¸ì§€: {len(result.get('images', []))}ê°œ")
                        print(f"  ğŸ“ ê´€ë ¨ í…ìŠ¤íŠ¸: {len(result.get('text_chunks', []))}ê°œ")
                        
                        # ì£¼ìš” ì†Œê²¬ ì¶œë ¥
                        if 'key_finding' in result:
                            print(f"\nğŸ“‹ ì£¼ìš” ì†Œê²¬:")
                            for line in result['key_finding'].split('\n'):
                                if line.strip():
                                    print(f"    {line}")
                    else:
                        print(f"âŒ ê²€ìƒ‰ ì‹¤íŒ¨: {result['error']}")
                
        except KeyboardInterrupt:
            print("\nğŸ‘‹ ê²€ìƒ‰ ì—”ì§„ì„ ì¢…ë£Œí•©ë‹ˆë‹¤.")
        except Exception as e:
            print(f"âŒ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")