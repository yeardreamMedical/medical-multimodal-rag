# search/search_engine.py
# í†µí•©ëœ ë©€í‹°ëª¨ë‹¬ ê²€ìƒ‰ ì—”ì§„ - ëª¨ë“  ê²€ìƒ‰ ë¡œì§ì„ í•˜ë‚˜ì˜ íŒŒì¼ì— í†µí•©

# --- ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸ ---
from datetime import datetime
import os
import re # ì •ê·œ í‘œí˜„ì‹(Regular Expression) ë¼ì´ë¸ŒëŸ¬ë¦¬. ë³µì¡í•œ ë¬¸ìì—´ íŒ¨í„´ì„ ê²€ìƒ‰í•˜ê³  ì¡°ì‘í•˜ëŠ” ë° ì‚¬ìš©ë©ë‹ˆë‹¤.
import torch # PyTorch ë¼ì´ë¸ŒëŸ¬ë¦¬. ë”¥ëŸ¬ë‹ ëª¨ë¸(ì—¬ê¸°ì„œëŠ” BioViL-T)ì„ ì‚¬ìš©í•˜ê¸° ìœ„í•´ í•„ìš”í•©ë‹ˆë‹¤.
import numpy as np # ìˆ˜ì¹˜ ê³„ì‚°ì„ ìœ„í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬. ë²¡í„° ì—°ì‚° ë“±ì— ì‚¬ìš©ë©ë‹ˆë‹¤.
from pathlib import Path
from PIL import Image
from typing import List, Dict, Any, Optional # íƒ€ì… íŒíŒ…ì„ ìœ„í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬. ì½”ë“œì˜ ê°€ë…ì„±ê³¼ ì•ˆì •ì„±ì„ ë†’ì—¬ì¤ë‹ˆë‹¤.
from dotenv import load_dotenv # .env íŒŒì¼ì—ì„œ í™˜ê²½ ë³€ìˆ˜ë¥¼ ë¶ˆëŸ¬ì˜¤ê¸° ìœ„í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ì…ë‹ˆë‹¤.
from pinecone import Pinecone # Pinecone ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ ì„œë¹„ìŠ¤ë¥¼ ì‚¬ìš©í•˜ê¸° ìœ„í•œ í´ë¼ì´ì–¸íŠ¸ ë¼ì´ë¸ŒëŸ¬ë¦¬ì…ë‹ˆë‹¤.
from openai import OpenAI # OpenAIì˜ ëª¨ë¸(í…ìŠ¤íŠ¸ ì„ë² ë”©)ì„ ì‚¬ìš©í•˜ê¸° ìœ„í•œ í´ë¼ì´ì–¸íŠ¸ ë¼ì´ë¸ŒëŸ¬ë¦¬ì…ë‹ˆë‹¤.

# BioViL-T ëª¨ë¸ import
# health_multimodalì€ ì˜ë£Œ ë¶„ì•¼ì— íŠ¹í™”ëœ ë©€í‹°ëª¨ë‹¬(í…ìŠ¤íŠ¸, ì´ë¯¸ì§€ ë“±) AI ëª¨ë¸ì„ ì œê³µí•˜ëŠ” ë¼ì´ë¸ŒëŸ¬ë¦¬ì…ë‹ˆë‹¤.
from health_multimodal.image.model.pretrained import get_biovil_t_image_encoder # ë¯¸ë¦¬ í•™ìŠµëœ í‰ë¶€ X-ray ì´ë¯¸ì§€ ì¸ì½”ë”ë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤.
from health_multimodal.image.data.transforms import create_chest_xray_transform_for_inference # ì¶”ë¡ (ì˜ˆì¸¡)ì„ ìœ„í•œ ì´ë¯¸ì§€ ë³€í™˜ í•¨ìˆ˜ë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤.

# --- ì„¤ì • ë° ìƒìˆ˜ ---
# .env íŒŒì¼ì— ì €ì¥ëœ API í‚¤ì™€ ê°™ì€ ë¯¼ê°í•œ ì •ë³´ë¥¼ ë¡œë“œí•©ë‹ˆë‹¤.
load_dotenv()

class SearchConfig:
    """
    ê²€ìƒ‰ ì‹œìŠ¤í…œ ì „ì²´ì—ì„œ ì‚¬ìš©ë  ì„¤ì • ê°’ë“¤ì„ ëª¨ì•„ë‘” í´ë˜ìŠ¤ì…ë‹ˆë‹¤.
    ì´ë ‡ê²Œ í•œ ê³³ì— ì„¤ì •ì„ ëª¨ì•„ë‘ë©´ ë‚˜ì¤‘ì— ë³€ê²½í•˜ê±°ë‚˜ ê´€ë¦¬í•˜ê¸°ê°€ ë§¤ìš° í¸ë¦¬í•©ë‹ˆë‹¤.
    'í•˜ë“œì½”ë”©'ì„ í”¼í•˜ê³  ì„¤ì • ê°’ì„ ì¤‘ì•™ì—ì„œ ê´€ë¦¬í•˜ëŠ” ê²ƒì€ ì¢‹ì€ í”„ë¡œê·¸ë˜ë° ìŠµê´€ì…ë‹ˆë‹¤.
    """
    
    # API ë° í™˜ê²½ ë³€ìˆ˜ ì„¤ì •
    PINECONE_API_KEY = os.getenv("PINECONE_API_KEY")
    OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
    
    # ëª¨ë¸ ê´€ë ¨ ì„¤ì •
    # torch.cuda.is_available()ëŠ” NVIDIA GPUê°€ ì‚¬ìš© ê°€ëŠ¥í•œì§€ í™•ì¸í•©ë‹ˆë‹¤.
    # GPUë¥¼ ì‚¬ìš©í•˜ë©´ ë”¥ëŸ¬ë‹ ì—°ì‚° ì†ë„ê°€ ë§¤ìš° ë¹¨ë¼ì§‘ë‹ˆë‹¤. ì‚¬ìš©ì´ ë¶ˆê°€ëŠ¥í•˜ë©´ CPUë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.
    DEVICE = "cuda" if torch.cuda.is_available() else "cpu"
    # OpenAIì˜ í…ìŠ¤íŠ¸ ì„ë² ë”© ëª¨ë¸ ì´ë¦„ì„ ì§€ì •í•©ë‹ˆë‹¤.
    # ë¹„ìš©ê³¼ ì„±ëŠ¥ ì‚¬ì´ì˜ ê· í˜•ì´ ì¢‹ì€ ëª¨ë¸ì…ë‹ˆë‹¤.
    TEXT_EMBEDDING_MODEL = "text-embedding-3-small"
    
    # Pinecone ì¸ë±ìŠ¤ ì„¤ì •
    # ì¸ë±ìŠ¤ëŠ” ë°ì´í„°ë² ì´ìŠ¤ì˜ 'í…Œì´ë¸”'ê³¼ ìœ ì‚¬í•œ ê°œë…ì…ë‹ˆë‹¤.
    TEXT_INDEX_NAME = "textbook-rag" # ì˜ë£Œ êµê³¼ì„œ í…ìŠ¤íŠ¸ ë°ì´í„°ê°€ ì €ì¥ëœ ì¸ë±ìŠ¤
    IMAGE_INDEX_NAME = "cxr-image-meta-v2" # í‰ë¶€ X-ray ì´ë¯¸ì§€ ë°ì´í„°ê°€ ì €ì¥ëœ ì¸ë±ìŠ¤
    
    # í‰ë¶€ X-ray ë°ì´í„°ì…‹ì— í¬í•¨ëœ ì£¼ìš” ì§ˆë³‘ ì •ë³´ì…ë‹ˆë‹¤.
    # ê° ì§ˆë³‘ë³„ë¡œ ë³´ìœ í•œ ì´ë¯¸ì§€ ìˆ˜(count), í•œê¸€ëª…(korean), ì‹œí—˜ ì¶œì œ ë¹„ì¤‘(exam_weight)ì„ ì •ì˜í•©ë‹ˆë‹¤.
    DISEASE_INFO = {
        "Effusion": {"count": 51, "korean": "í‰ìˆ˜", "exam_weight": "ë†’ìŒ"},
        "Infiltrate": {"count": 44, "korean": "ì¹¨ìœ¤/ê²½í™”", "exam_weight": "ë†’ìŒ"},
        "Atelectasis": {"count": 31, "korean": "ë¬´ê¸°í", "exam_weight": "ì¤‘ê°„"},
        "Pneumonia": {"count": 23, "korean": "íë ´", "exam_weight": "ë§¤ìš°ë†’ìŒ"},
        "Mass": {"count": 22, "korean": "ì¢…ê´´", "exam_weight": "ë†’ìŒ"},
        "Pneumothorax": {"count": 12, "korean": "ê¸°í‰", "exam_weight": "ë†’ìŒ"},
        "Cardiomegaly": {"count": 11, "korean": "ì‹¬ì¥ë¹„ëŒ€", "exam_weight": "ì¤‘ê°„"},
        "Nodule": {"count": 3, "korean": "ê²°ì ˆ", "exam_weight": "ë‚®ìŒ"}
    }
    
    # ì¿¼ë¦¬ í™•ì¥ í…œí”Œë¦¿: ì‚¬ìš©ìì˜ ì§§ì€ ì¿¼ë¦¬ë¥¼ ë” í’ë¶€í•œ ê²€ìƒ‰ì–´ë¡œ ë§Œë“¤ì–´ì£¼ëŠ” ë° ì‚¬ìš©ë©ë‹ˆë‹¤.
    # ì˜ˆë¥¼ ë“¤ì–´, ì‚¬ìš©ìê°€ 'íë ´'ì´ë¼ê³  ê²€ìƒ‰í•˜ë©´, 'íë ´ ì§„ë‹¨ ì¹˜ë£Œ...' ë“±ì˜ ê´€ë ¨ í‚¤ì›Œë“œë¥¼ ì¶”ê°€í•˜ì—¬
    # ë²¡í„° ê²€ìƒ‰ ì‹œ ë” ì •í™•í•˜ê³  í’ë¶€í•œ ê²°ê³¼ë¥¼ ì–»ì„ ìˆ˜ ìˆë„ë¡ ë„ì™€ì¤ë‹ˆë‹¤.
    QUERY_EXPANSION_TEMPLATES = {
        # ì˜ì–´ ì§ˆë³‘ëª…
        "pneumonia": "pneumonia diagnosis treatment bacterial viral lung infection chest disease",
        "effusion": "pleural effusion chest fluid thoracentesis drainage respiratory",
        "pleural effusion": "pleural effusion chest fluid thoracentesis drainage blunting costophrenic",
        "pneumothorax": "pneumothorax collapsed lung tension emergency chest tube",
        "atelectasis": "atelectasis lung collapse volume loss postoperative",
        "consolidation": "consolidation pneumonia lung opacity air space disease",
        "infiltrate": "infiltrate lung opacity consolidation pneumonia infection",
        "mass": "lung mass tumor lesion CT evaluation oncology",
        "cardiomegaly": "cardiomegaly enlarged heart failure cardiothoracic ratio",
        "nodule": "lung nodule pulmonary nodule CT scan evaluation",
        
        # í•œêµ­ì–´ ì§ˆë³‘ëª…
        "íë ´": "íë ´ ì§„ë‹¨ ì¹˜ë£Œ í•­ìƒì œ ì„¸ê· ì„± ë°”ì´ëŸ¬ìŠ¤ì„± íê°ì—¼ í˜¸í¡ê¸°ì§ˆí™˜",
        "í‰ìˆ˜": "í‰ìˆ˜ ëŠ‘ë§‰ì‚¼ì¶œ ì²œììˆ  ë°°ì•¡ í˜¸í¡ê³¤ë€ í‰ë¶€ ëŠ‘ê³¨íš¡ê²©ë§‰ê°",
        "ê¸°í‰": "ê¸°í‰ í—ˆíƒˆ ê¸´ì¥ì„± ì‘ê¸‰ìƒí™© í‰ê´€ì‚½ì… ì¹˜ë£Œ ê³µê¸°ëˆ„ì¶œ",
        "ë¬´ê¸°í": "ë¬´ê¸°í í—ˆíƒˆ ë¶€í”¼ê°ì†Œ ìˆ˜ìˆ í›„ í•©ë³‘ì¦ í˜¸í¡ê¸°",
        "ì¹¨ìœ¤": "ì¹¨ìœ¤ íì¹¨ìœ¤ ê²½í™” ê°ì—¼ ìŒì˜ ì§ˆí™˜ ì‹¤ì§ˆ",
        "ê²½í™”": "ê²½í™” íê²½í™” ê³µê¸°ê³µê°„ì§ˆí™˜ ìŒì˜ ì§„ë‹¨ íë ´",
        "ì¢…ê´´": "ì¢…ê´´ íì¢…ê´´ ì¢…ì–‘ ë³‘ë³€ CTê²€ì‚¬ í‰ê°€ ê²°ì ˆ",
        "ì‹¬ì¥ë¹„ëŒ€": "ì‹¬ì¥ë¹„ëŒ€ ì‹¬ë¶€ì „ ì‹¬í‰ê³½ë¹„ ì‹¬ì´ˆìŒíŒŒ ê²€ì‚¬",
        "ê²°ì ˆ": "ê²°ì ˆ íê²°ì ˆ ì¢…ê´´ ë³‘ë³€ CTê²€ì‚¬ ì•…ì„± ì–‘ì„±"
    }
    
    # ì¿¼ë¦¬-ì§ˆë³‘ ì§ì ‘ ë§¤í•‘: ì‚¬ìš©ìì˜ ì¿¼ë¦¬ì— íŠ¹ì • ë‹¨ì–´ê°€ ë°œê²¬ë˜ë©´ ì–´ë–¤ ì§ˆë³‘ì— í•´ë‹¹í•˜ëŠ”ì§€ ì§ì ‘ ì•Œë ¤ì£¼ëŠ” ê·œì¹™ì…ë‹ˆë‹¤.
    # ì˜ˆë¥¼ ë“¤ì–´ 'íë ´' ë˜ëŠ” 'pneumonia'ê°€ ì¿¼ë¦¬ì— ìˆìœ¼ë©´ 'Pneumonia' ì§ˆë³‘ìœ¼ë¡œ ë°”ë¡œ ì—°ê²°í•˜ì—¬ ì •í™•ë„ë¥¼ ë†’ì…ë‹ˆë‹¤.
    QUERY_DISEASE_MAPPING = {
        "pneumonia": "Pneumonia", "íë ´": "Pneumonia",
        "effusion": "Effusion", "í‰ìˆ˜": "Effusion", "pleural effusion": "Effusion",
        "pneumothorax": "Pneumothorax", "ê¸°í‰": "Pneumothorax", 
        "atelectasis": "Atelectasis", "ë¬´ê¸°í": "Atelectasis",
        "consolidation": "Infiltrate", "ì¹¨ìœ¤": "Infiltrate", "ê²½í™”": "Infiltrate", "infiltrate": "Infiltrate",
        "mass": "Mass", "ì¢…ê´´": "Mass",
        "cardiomegaly": "Cardiomegaly", "ì‹¬ì¥ë¹„ëŒ€": "Cardiomegaly",
        "nodule": "Nodule", "ê²°ì ˆ": "Nodule"
    }
    
    # ì§ˆë³‘ë³„ ìƒì„¸ ë§¤í•‘: í…ìŠ¤íŠ¸ì—ì„œ ì§ˆë³‘ì„ ì¶”ì¶œí•  ë•Œ ì‚¬ìš©í•  ìƒì„¸ ê·œì¹™ì…ë‹ˆë‹¤.
    # ê° ì§ˆë³‘ì— ëŒ€í•´, ì •í™•íˆ ì¼ì¹˜í•˜ëŠ” ë‹¨ì–´, ë¶€ë¶„ì ìœ¼ë¡œ ì¼ì¹˜í•˜ëŠ” ë‹¨ì–´, í•œêµ­ì–´ ë‹¨ì–´ ë“±ì„ ì •ì˜í•˜ì—¬
    # ì§ˆë³‘ ì ìˆ˜ë¥¼ ë” ì •êµí•˜ê²Œ ê³„ì‚°í•˜ëŠ” ë° ì‚¬ìš©ë©ë‹ˆë‹¤. `exclude_if_found`ëŠ” ì˜¤íƒì§€ë¥¼ ì¤„ì´ëŠ” ì—­í• ì„ í•©ë‹ˆë‹¤.
    DISEASE_MAPPINGS = {
        "Pneumonia": {
            "exact_match": ["pneumonia", "íë ´"],
            "partial_match": ["bacterial pneumonia", "viral pneumonia", "lung infection"],
            "korean_match": ["íë ´", "ì„¸ê· ì„±íë ´", "ë°”ì´ëŸ¬ìŠ¤íë ´"],
            "exclude_if_found": ["pneumothorax"]
        },
        "Pneumothorax": {
            "exact_match": ["pneumothorax", "ê¸°í‰"],
            "partial_match": ["collapsed lung", "tension pneumothorax"],
            "korean_match": ["ê¸°í‰", "ê¸´ì¥ì„±ê¸°í‰"],
            "exclude_if_found": ["pneumonia"]
        },
        "Effusion": {
            "exact_match": ["effusion", "í‰ìˆ˜", "pleural effusion"],
            "partial_match": ["pleural fluid", "chest fluid"],
            "korean_match": ["í‰ìˆ˜", "ëŠ‘ë§‰ì‚¼ì¶œ", "ê°€ìŠ´ë¬¼"],
            "exclude_if_found": []
        },
        "Atelectasis": {
            "exact_match": ["atelectasis", "ë¬´ê¸°í"],
            "partial_match": ["lung collapse", "partial collapse"],
            "korean_match": ["ë¬´ê¸°í", "í—ˆíƒˆ", "íí—ˆíƒˆ"],
            "exclude_if_found": []
        },
        "Infiltrate": {
            "exact_match": ["infiltrate", "ì¹¨ìœ¤", "consolidation"],
            "partial_match": ["lung opacity", "parenchymal opacity", "ê²½í™”"],
            "korean_match": ["ì¹¨ìœ¤", "ê²½í™”", "íê²½í™”", "íì¹¨ìœ¤"],
            "exclude_if_found": []
        },
        "Mass": {
            "exact_match": ["mass", "ì¢…ê´´"],
            "partial_match": ["tumor", "lesion", "nodular opacity"],
            "korean_match": ["ì¢…ê´´", "ì¢…ì–‘", "ë©ì–´ë¦¬"],
            "exclude_if_found": []
        },
        "Cardiomegaly": {
            "exact_match": ["cardiomegaly", "ì‹¬ì¥ë¹„ëŒ€"],
            "partial_match": ["enlarged heart", "cardiac enlargement"],
            "korean_match": ["ì‹¬ì¥ë¹„ëŒ€", "ì‹¬ì¥í™•ëŒ€"],
            "exclude_if_found": []
        },
        "Nodule": {
            "exact_match": ["nodule", "ê²°ì ˆ"],
            "partial_match": ["lung nodule", "pulmonary nodule"],
            "korean_match": ["ê²°ì ˆ", "íê²°ì ˆ"],
            "exclude_if_found": []
        }
    }


class QueryProcessor:
    """
    ì‚¬ìš©ìì˜ ì¿¼ë¦¬ë¥¼ ë°›ì•„ì„œ ê²€ìƒ‰ì— ë” ì í•©í•œ í˜•íƒœë¡œ ê°€ê³µ(ì „ì²˜ë¦¬)í•˜ëŠ” ì—­í• ì„ ë‹´ë‹¹í•˜ëŠ” í´ë˜ìŠ¤ì…ë‹ˆë‹¤.
    ì£¼ìš” ê¸°ëŠ¥ì€ 'ì¿¼ë¦¬ í™•ì¥(Query Expansion)'ìœ¼ë¡œ, ì´ëŠ” RAG(ê²€ìƒ‰ ì¦ê°• ìƒì„±) ì‹œìŠ¤í…œì˜ ì„±ëŠ¥ì— ë§¤ìš° ì¤‘ìš”í•©ë‹ˆë‹¤.
    ì¢‹ì€ ê²€ìƒ‰ ê²°ê³¼ë¥¼ ì–»ìœ¼ë ¤ë©´ ì¢‹ì€ ì¿¼ë¦¬ê°€ í•„ìˆ˜ì ì´ê¸° ë•Œë¬¸ì…ë‹ˆë‹¤.
    """
    
    def __init__(self, config: SearchConfig):
        """QueryProcessor í´ë˜ìŠ¤ì˜ ì¸ìŠ¤í„´ìŠ¤ë¥¼ ìƒì„±í•  ë•Œ í˜¸ì¶œë©ë‹ˆë‹¤."""
        self.config = config
        self.templates = config.QUERY_EXPANSION_TEMPLATES
        # Gemini(LLM) í´ë¼ì´ì–¸íŠ¸ë¥¼ ì´ˆê¸°í™”í•©ë‹ˆë‹¤.
        # try-except êµ¬ë¬¸ì„ ì‚¬ìš©í•˜ì—¬ Gemini ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ì—†ê±°ë‚˜ API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì€ ê²½ìš°ì—ë„
        # í”„ë¡œê·¸ë¨ì´ ì¤‘ë‹¨ë˜ì§€ ì•Šê³ , LLMì„ ì‚¬ìš©í•˜ì§€ ì•ŠëŠ” ëŒ€ì²´ ë°©ì‹ìœ¼ë¡œ ë™ì‘í•˜ë„ë¡ í•©ë‹ˆë‹¤.
        try:
            import google.generativeai as genai
            api_key = os.getenv("GEMINI_API_KEY")
            if api_key:
                genai.configure(api_key=api_key)
                self.llm_client = genai.GenerativeModel('gemini-1.5-pro')
                print("âœ… ì¿¼ë¦¬ í™•ì¥ìš© LLM í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì™„ë£Œ")
            else:
                self.llm_client = None
                print("âš ï¸ GEMINI_API_KEY ì—†ìŒ: LLM ì¿¼ë¦¬ í™•ì¥ì„ ë¹„í™œì„±í™”í•˜ê³  ê¸°ë³¸ í…œí”Œë¦¿ ë°©ì‹ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.")
        except ImportError:
            self.llm_client = None
            print("âš ï¸ Gemini íŒ¨í‚¤ì§€ ì—†ìŒ: LLM ì¿¼ë¦¬ í™•ì¥ì„ ë¹„í™œì„±í™”í•˜ê³  ê¸°ë³¸ í…œí”Œë¦¿ ë°©ì‹ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.")
    
    def expand_query(self, query: str) -> str:
        """
        ì‚¬ìš©ì ì¿¼ë¦¬ë¥¼ í™•ì¥í•˜ì—¬ ê²€ìƒ‰ ì„±ëŠ¥ì„ í–¥ìƒì‹œí‚µë‹ˆë‹¤.
        í™•ì¥ ë¡œì§ì€ ë‹¤ìŒê³¼ ê°™ì€ ìš°ì„ ìˆœìœ„ë¥¼ ê°€ì§‘ë‹ˆë‹¤:
        1. í…œí”Œë¦¿ ê·œì¹™ ê¸°ë°˜ í™•ì¥: ê°€ì¥ ë¹ ë¥´ê³  ë¹„ìš©ì´ ë“¤ì§€ ì•ŠëŠ” ë°©ì‹ì…ë‹ˆë‹¤. ë¯¸ë¦¬ ì •ì˜ëœ ê·œì¹™ì— ë§ëŠ” ê²½ìš°, ë°”ë¡œ í™•ì¥ëœ ì¿¼ë¦¬ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.
        2. LLM ë™ì  í™•ì¥: í…œí”Œë¦¿ì— ì—†ëŠ” ìƒˆë¡œìš´ ì¿¼ë¦¬ì˜ ê²½ìš°, LLMì„ ì‚¬ìš©í•˜ì—¬ ë¬¸ë§¥ì— ë§ëŠ” í‚¤ì›Œë“œë¥¼ ë™ì ìœ¼ë¡œ ìƒì„±í•©ë‹ˆë‹¤. ê°€ì¥ ìœ ì—°í•˜ì§€ë§Œ ë¹„ìš©ê³¼ ì‹œê°„ì´ ì†Œìš”ë©ë‹ˆë‹¤.
        3. ì¼ë°˜ í‚¤ì›Œë“œ ì¶”ê°€ (Fallback): ìœ„ ë‘ ë°©ë²•ì´ ëª¨ë‘ ì‹¤íŒ¨í•˜ë©´, ì¼ë°˜ì ì¸ ì˜ë£Œ í‚¤ì›Œë“œë¥¼ ì¶”ê°€í•©ë‹ˆë‹¤.
        """
        query_lower = query.lower().strip()
        
        # 1. ë¯¸ë¦¬ ì •ì˜ëœ í…œí”Œë¦¿ìœ¼ë¡œ ë¹ ë¥´ê²Œ í™•ì¥ ì‹œë„
        template_expanded = self._try_template_expansion(query, query_lower)
        if template_expanded != query:
            print("    (ì¿¼ë¦¬ í™•ì¥) í…œí”Œë¦¿ ê¸°ë°˜ í™•ì¥ ì ìš©")
            return template_expanded
        
        # 2. í…œí”Œë¦¿ì— ì—†ëŠ” ê²½ìš°, LLMì„ ì‚¬ìš©í•˜ì—¬ ë™ì ìœ¼ë¡œ í™•ì¥ ì‹œë„
        if self.llm_client:
            llm_expanded = self._expand_with_llm(query)
            if llm_expanded and llm_expanded.lower().strip() != query_lower:
                print("    (ì¿¼ë¦¬ í™•ì¥) LLM ë™ì  í™•ì¥ ì ìš©")
                return llm_expanded
        
        # 3. ìœ„ ë°©ë²•ë“¤ì´ ëª¨ë‘ ì‹¤íŒ¨í•˜ë©´, ì¼ë°˜ì ì¸ ì˜ë£Œ í‚¤ì›Œë“œë¥¼ ì¶”ê°€ (ìµœí›„ì˜ ìˆ˜ë‹¨)
        fallback_expanded = self._add_general_medical_keywords(query)
        print("    (ì¿¼ë¦¬ í™•ì¥) ì¼ë°˜ ì˜ë£Œ í‚¤ì›Œë“œ ì¶”ê°€ (Fallback)")
        return fallback_expanded
    
    def _try_template_expansion(self, query: str, query_lower: str) -> str:
        """ë¯¸ë¦¬ ì •ì˜ëœ í…œí”Œë¦¿(ê·œì¹™)ì„ ì‚¬ìš©í•˜ì—¬ ì¿¼ë¦¬ë¥¼ í™•ì¥í•©ë‹ˆë‹¤. ë‚´ë¶€ì—ì„œë§Œ ì‚¬ìš©ë©ë‹ˆë‹¤."""
        # ì§ì ‘ ë§¤ì¹­ í™•ì¸
        for term, expansion in self.templates.items():
            if term in query_lower:
                return f"{query} {expansion}"
        
        # ë¶€ë¶„ ë§¤ì¹­ í™•ì¸
        for term, expansion in self.templates.items():
            if any(word in query_lower for word in term.split()):
                return f"{query} {expansion}"
        
        return query  # í™•ì¥ ì‹¤íŒ¨ì‹œ ì›ë³¸ ë°˜í™˜
    
    def _expand_with_llm(self, query: str) -> Optional[str]:
        """LLM(Gemini)ì„ ì‚¬ìš©í•˜ì—¬ ë™ì ìœ¼ë¡œ ì¿¼ë¦¬ë¥¼ í™•ì¥í•©ë‹ˆë‹¤. ì´ ê³¼ì •ì€ 'í”„ë¡¬í”„íŠ¸ ì—”ì§€ë‹ˆì–´ë§'ì´ ì¤‘ìš”í•©ë‹ˆë‹¤."""
        try:
            # LLMì—ê²Œ ì—­í• ì„ ë¶€ì—¬í•˜ê³ , ëª…í™•í•œ ì§€ì¹¨ê³¼ ì˜ˆì‹œë¥¼ ì œê³µí•˜ì—¬ ì›í•˜ëŠ” ê²°ê³¼ë¬¼ì„ ì–»ë„ë¡ ìœ ë„í•˜ëŠ” í”„ë¡¬í”„íŠ¸ì…ë‹ˆë‹¤.
            prompt = f"""ë‹¹ì‹ ì€ ì˜ë£Œ ì •ë³´ ê²€ìƒ‰ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ë‹¤ìŒ ì¿¼ë¦¬ë¥¼ ì˜ë£Œ ë¬¸í—Œ ê²€ìƒ‰ì— ìµœì í™”ëœ í˜•íƒœë¡œ í™•ì¥í•˜ì„¸ìš”.

    ì›ë³¸ ì¿¼ë¦¬: "{query}"

    ì§€ì¹¨:
    1. ì›ë³¸ ì¿¼ë¦¬ + í•µì‹¬ í‚¤ì›Œë“œ 3-4ê°œë§Œ ì¶”ê°€
    2. ì´ ê¸¸ì´ëŠ” ì›ë³¸ì˜ 2ë°°ë¥¼ ë„˜ì§€ ë§ ê²ƒ
    3. ë™ì˜ì–´, ê´€ë ¨ ì¦ìƒ, ì§„ë‹¨ ë°©ë²• ì¤‘ì‹¬
    4. í•œêµ­ì–´ì™€ ì˜ì–´ë¥¼ ì ì ˆíˆ ì¡°í•©
    5. ê°„ê²°í•˜ê³  ê²€ìƒ‰ì— ìœ ìš©í•œ í‚¤ì›Œë“œë§Œ ì„ íƒ

    ì˜ˆì‹œ:
    - "ì—´ìƒ" â†’ "ì—´ìƒ ìƒì²˜ ë´‰í•© ì™¸ìƒ laceration wound suture"
    - "íë ´" â†’ "íë ´ pneumonia ë°œì—´ ê¸°ì¹¨ ê°ì—¼ respiratory"

    í™•ì¥ëœ ì¿¼ë¦¬ë§Œ ì¶œë ¥í•˜ì„¸ìš” (ì„¤ëª… ë¶ˆí•„ìš”):"""

            response = self.llm_client.generate_content(prompt)
            expanded = response.text.strip()
            
            # ìœ ì—°í•œ ê¸¸ì´ ê²€ì¦ (ì§§ì€ ì¿¼ë¦¬ ê³ ë ¤)
            if len(query) <= 5:  # ë§¤ìš° ì§§ì€ ì¿¼ë¦¬ (ì˜ˆ: "ì—´ìƒ", "íë ´")
                max_length = 80
            elif len(query) <= 15:  # ì¤‘ê°„ ê¸¸ì´ ì¿¼ë¦¬ (ì˜ˆ: "ì—´ìƒ í™˜ì ì¹˜ë£Œ")
                max_length = 120
            else:  # ê¸´ ì¿¼ë¦¬
                max_length = len(query) * 2
            
            if len(expanded) > max_length:
                print(f"    âš ï¸ LLM í™•ì¥ ê²°ê³¼ê°€ ë„ˆë¬´ ê¹€ ({len(expanded)}ì > {max_length}ì), ê¸°ë³¸ ë°©ì‹ ì‚¬ìš©")
                return query
            
            # ì˜ë¯¸ì—†ëŠ” ë°˜ë³µì´ë‚˜ ì„¤ëª… ì œê±°
            if "ì˜ˆì‹œ:" in expanded or "ì„¤ëª…:" in expanded or "ì§€ì¹¨:" in expanded:
                print(f"    âš ï¸ LLMì´ ì„¤ëª…ì„ í¬í•¨í•¨, ê¸°ë³¸ ë°©ì‹ ì‚¬ìš©")
                return query
            
            return expanded
            
        except Exception as e:
            print(f"âŒ LLM ì¿¼ë¦¬ í™•ì¥ ì‹¤íŒ¨: {e}")
            return query
    
    def _add_general_medical_keywords(self, query: str) -> str:
        """ì¿¼ë¦¬ì— ì¼ë°˜ì ì¸ ì˜ë£Œ ê´€ë ¨ í‚¤ì›Œë“œë¥¼ ì¶”ê°€í•©ë‹ˆë‹¤. ì´ëŠ” ìµœí›„ì˜ ë³´ë£¨(fallback) ì—­í• ì„ í•©ë‹ˆë‹¤."""
        return f"{query} ì˜ë£Œ ì§„ë‹¨ medical diagnosis clinical"


class DiseaseExtractor:
    """
    í…ìŠ¤íŠ¸ ê²€ìƒ‰ ê²°ê³¼ë¥¼ ë¶„ì„í•˜ì—¬ ì–´ë–¤ ì§ˆë³‘ì— ëŒ€í•œ ë‚´ìš©ì¸ì§€ ì¶”ë¡ í•˜ëŠ” í´ë˜ìŠ¤ì…ë‹ˆë‹¤.
    ë‹¨ìˆœíˆ í‚¤ì›Œë“œë¥¼ ì°¾ëŠ” ê²ƒì„ ë„˜ì–´, ë¬¸ë§¥ì„ ê³ ë ¤í•˜ì—¬ ì ìˆ˜ë¥¼ ë§¤ê¹ë‹ˆë‹¤.
    """
    
    def __init__(self, config: SearchConfig):
        self.config = config
        self.disease_mappings = config.DISEASE_MAPPINGS
        self.query_mapping = config.QUERY_DISEASE_MAPPING
        # ì œì™¸ íŒ¨í„´ ê°•í™” (ë” êµ¬ì²´ì ìœ¼ë¡œ)
        self.exclusion_patterns = {
            'pneumonia': [
                r'\b(?:not|no|without|absence of|rule out|r/o)\s+pneumonia\b',
                r'\bpneumothorax\s+(?:not|rather than|instead of)\s+pneumonia\b',
                r'\b(?:pneumothorax|effusion|mass)\s+(?:not|rather than)\s+pneumonia\b'
            ],
            'pneumothorax': [
                r'\b(?:not|no|without|absence of|rule out|r/o)\s+pneumothorax\b',
                r'\bpneumonia\s+(?:not|rather than|instead of)\s+pneumothorax\b'
            ],
            'effusion': [
                r'\b(?:not|no|without|absence of|rule out|r/o)\s+(?:pleural\s+)?effusion\b',
                r'\b(?:pneumonia|pneumothorax)\s+(?:not|rather than)\s+effusion\b'
            ]
        }
    
    def extract_diseases(self, text_results: List[Dict], query: str = "") -> List[str]:
        """
        í…ìŠ¤íŠ¸ ë©ì–´ë¦¬(chunk)ë“¤ë¡œë¶€í„° ê°€ì¥ ê°€ëŠ¥ì„± ë†’ì€ ì§ˆë³‘ ëª©ë¡ì„ ì¶”ì¶œí•©ë‹ˆë‹¤.
        """
        # 1. í…ìŠ¤íŠ¸ ë‚´ìš©ë§Œì„ ë°”íƒ•ìœ¼ë¡œ ê° ì§ˆë³‘ì˜ ê¸°ë³¸ ì ìˆ˜ë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤.
        disease_scores = self._calculate_basic_scores(text_results)
        
        # 2. ì‚¬ìš©ìì˜ ì›ë³¸ ì¿¼ë¦¬ì— ì§ˆë³‘ëª…ì´ ì§ì ‘ ì–¸ê¸‰ë˜ì—ˆë‹¤ë©´, í•´ë‹¹ ì§ˆë³‘ì— í° ë³´ë„ˆìŠ¤ ì ìˆ˜ë¥¼ ì¤ë‹ˆë‹¤.
        direct_match_found = self._apply_direct_matching_bonus(disease_scores, query)
        
        # 3. ìµœì¢… ì ìˆ˜ë¥¼ ê¸°ì¤€ìœ¼ë¡œ ì§ˆë³‘ ëª©ë¡ì„ ì •ë ¬í•˜ê³ , ì‹ ë¢°ë„ê°€ ë‚®ì€ ì§ˆë³‘ì€ íƒˆë½ì‹œí‚µë‹ˆë‹¤.
        predicted_diseases = self._filter_and_sort_diseases(disease_scores, direct_match_found)
        
        return predicted_diseases
    
    def _calculate_basic_scores(self, text_results: List[Dict]) -> Dict[str, float]:
        """ì§ˆë³‘ë³„ ê¸°ë³¸ ì ìˆ˜ë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤. (ë‚´ë¶€ í—¬í¼ í•¨ìˆ˜)"""
        disease_scores = {disease: 0 for disease in self.disease_mappings.keys()}
        
        for chunk in text_results:
            content = chunk.get('content', '').lower()
            similarity = chunk.get('similarity', 0.5)
            
            for disease, mapping_info in self.disease_mappings.items():
                disease_score = 0
                
                if self._has_exclusion_pattern(content, mapping_info["exclude_if_found"]):
                    continue
                
                disease_score += self._calculate_exact_matches(content, mapping_info["exact_match"], similarity)
                disease_score += self._calculate_partial_matches(content, mapping_info["partial_match"], similarity)
                disease_score += self._calculate_korean_matches(content, mapping_info["korean_match"], similarity)
                
                disease_scores[disease] += disease_score
        
        return disease_scores
    
    def _has_exclusion_pattern(self, content: str, exclude_terms: List[str]) -> bool:
        """ì œì™¸ íŒ¨í„´ì´ ìˆëŠ”ì§€ í™•ì¸í•©ë‹ˆë‹¤."""
        for exclude_term in exclude_terms:
            if self._is_exact_word_match(content, exclude_term):
                return True
        return False
    
    def _calculate_exact_matches(self, content: str, exact_terms: List[str], similarity: float) -> float:
        """ì •í™•íˆ ì¼ì¹˜í•˜ëŠ” ë‹¨ì–´ì— ëŒ€í•œ ì ìˆ˜ë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤. ê°€ì¥ ë†’ì€ ê°€ì¤‘ì¹˜(3.0)ë¥¼ ë¶€ì—¬í•©ë‹ˆë‹¤."""
        score = 0
        for exact_term in exact_terms:
            if self._is_exact_word_match(content, exact_term):
                count = self._count_exact_matches(content, exact_term)
                weight = 3.0
                score += similarity * weight * count
        return score
    
    def _calculate_partial_matches(self, content: str, partial_terms: List[str], similarity: float) -> float:
        """ë¶€ë¶„ì ìœ¼ë¡œ í¬í•¨ë˜ëŠ” ë‹¨ì–´ì— ëŒ€í•œ ì ìˆ˜ë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤. ë‚®ì€ ê°€ì¤‘ì¹˜(1.5)ë¥¼ ë¶€ì—¬í•©ë‹ˆë‹¤."""
        score = 0
        for partial_term in partial_terms:
            if partial_term.lower() in content.lower():
                count = content.lower().count(partial_term.lower())
                weight = 1.5
                score += similarity * weight * count
        return score
    
    def _calculate_korean_matches(self, content: str, korean_terms: List[str], similarity: float) -> float:
        """í•œêµ­ì–´ ë‹¨ì–´ì— ëŒ€í•œ ì ìˆ˜ë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤. ë¹„êµì  ë†’ì€ ê°€ì¤‘ì¹˜(2.0)ë¥¼ ë¶€ì—¬í•©ë‹ˆë‹¤."""
        score = 0
        for korean_term in korean_terms:
            if korean_term in content:
                count = content.count(korean_term)
                weight = 2.0
                score += similarity * weight * count
        return score
    
    def _apply_direct_matching_bonus(self, disease_scores: Dict[str, float], original_query: str) -> bool:
        """ì‚¬ìš©ì ì¿¼ë¦¬ì— ì§ˆë³‘ëª…ì´ ì§ì ‘ í¬í•¨ëœ ê²½ìš°, í•´ë‹¹ ì§ˆë³‘ì— ì••ë„ì ì¸ ë³´ë„ˆìŠ¤ ì ìˆ˜ë¥¼ ë¶€ì—¬í•©ë‹ˆë‹¤."""
        direct_match_found = False
        
        if original_query:
            query_lower = original_query.lower()
            for term, disease in self.query_mapping.items():
                if term in query_lower and disease in disease_scores:
                    original_score = disease_scores[disease]
                    disease_scores[disease] += 100.0
                    print(f"    ğŸš€ ì¿¼ë¦¬ ì§ì ‘ ë§¤ì¹­ ë³´ë„ˆìŠ¤: {disease} {original_score:.3f} â†’ {disease_scores[disease]:.3f}")
                    direct_match_found = True
                    break
        
        return direct_match_found
    
    def _filter_and_sort_diseases(self, disease_scores: Dict[str, float], direct_match_found: bool) -> List[str]:
        """ê³„ì‚°ëœ ì ìˆ˜ë¥¼ ë°”íƒ•ìœ¼ë¡œ ìµœì¢… ì§ˆë³‘ ëª©ë¡ì„ ê²°ì •í•©ë‹ˆë‹¤."""
        sorted_diseases = sorted(disease_scores.items(), key=lambda x: x[1], reverse=True)
        
        min_threshold = 0.05 if direct_match_found else 0.1
        predicted_diseases = [disease for disease, score in sorted_diseases if score > min_threshold]
        
        print(f"   ğŸ¯ ì§ˆë³‘ ì˜ˆì¸¡ ê²°ê³¼:")
        for i, (disease, score) in enumerate(sorted_diseases[:5]):
            korean = self.config.DISEASE_INFO[disease]['korean']
            status = "âœ…" if score > min_threshold else "âŒ"
            print(f"      {i+1}. {disease} ({korean}): {score:.3f}ì  {status}")
        
        if not predicted_diseases:
            max_score = sorted_diseases[0][1] if sorted_diseases else 0
            if max_score < 0.1:
                print("   ğŸ“ ì§ˆë³‘ ë§¤ì¹­ ì‹¤íŒ¨ â†’ í…ìŠ¤íŠ¸ ì „ìš© ëª¨ë“œ ì„¤ì •")
                return ["TEXT_ONLY"]
            else:
                predicted_diseases = sorted(self.config.DISEASE_INFO.keys(), 
                                        key=lambda x: self.config.DISEASE_INFO[x]['count'], reverse=True)
                print("   âš ï¸ fallback ì ìš©: ë°ì´í„° ë³´ìœ ëŸ‰ ìˆœ")
        
        return predicted_diseases
    
    def _is_exact_word_match(self, text: str, word: str) -> bool:
        """ë‹¨ì–´ ê²½ê³„ë¥¼ ê³ ë ¤í•œ ì •í™•í•œ ë§¤ì¹­ì„ í™•ì¸í•©ë‹ˆë‹¤."""
        pattern = r'\b' + re.escape(word.lower()) + r'\b'
        return bool(re.search(pattern, text.lower()))
    
    def _count_exact_matches(self, text: str, word: str) -> int:
        """ì •í™•íˆ ì¼ì¹˜í•˜ëŠ” ë‹¨ì–´ì˜ ê°œìˆ˜ë¥¼ ì…‰ë‹ˆë‹¤."""
        pattern = r'\b' + re.escape(word.lower()) + r'\b'
        return len(re.findall(pattern, text.lower()))


class ImageSearcher:
    """
    ì´ë¯¸ì§€ ê²€ìƒ‰ê³¼ ê´€ë ¨ëœ ëª¨ë“  ê¸°ëŠ¥ì„ ë‹´ë‹¹í•˜ëŠ” í´ë˜ìŠ¤ì…ë‹ˆë‹¤.
    - ì§ˆë³‘ëª… ëª©ë¡ì„ ë°›ì•„ ê´€ë ¨ ì´ë¯¸ì§€ë¥¼ ê²€ìƒ‰ (ë©”íƒ€ë°ì´í„° í•„í„°ë§ ë°©ì‹)
    - íŠ¹ì • ì´ë¯¸ì§€ íŒŒì¼ê³¼ ìœ ì‚¬í•œ ë‹¤ë¥¸ ì´ë¯¸ì§€ë¥¼ ê²€ìƒ‰ (ë²¡í„° ìœ ì‚¬ë„ ë°©ì‹)
    """
    
    def __init__(self, config: SearchConfig, image_index, image_encoder, image_transform):
        self.config = config
        self.image_index = image_index # Pinecone ì´ë¯¸ì§€ ì¸ë±ìŠ¤
        self.image_encoder = image_encoder # BioViL-T ì´ë¯¸ì§€ ì¸ì½”ë” ëª¨ë¸
        self.image_transform = image_transform # ì´ë¯¸ì§€ ì „ì²˜ë¦¬ í•¨ìˆ˜
    
    def search_by_diseases(self, predicted_diseases: List[str], top_k: int = 3) -> List[Dict]:
        """ì¶”ë¡ ëœ ì§ˆë³‘ëª… ëª©ë¡ì„ ë°›ì•„, ê° ì§ˆë³‘ì— í•´ë‹¹í•˜ëŠ” ì´ë¯¸ì§€ë¥¼ Pineconeì—ì„œ ê²€ìƒ‰í•©ë‹ˆë‹¤."""
        all_images = []
        dummy_vector = [0.0] * 512 
        
        print(f"ğŸ–¼ï¸  (ì´ë¯¸ì§€ ê²€ìƒ‰) ì˜ˆì¸¡ëœ ì§ˆë³‘ëª…ìœ¼ë¡œ ì´ë¯¸ì§€ DB ê²€ìƒ‰ ì‹œì‘...")
        
        for disease in predicted_diseases[:3]:
            if disease == "TEXT_ONLY":
                print(f"   -> í…ìŠ¤íŠ¸ ì „ìš© ëª¨ë“œì´ë¯€ë¡œ ì´ë¯¸ì§€ ê²€ìƒ‰ì„ ê±´ë„ˆëœë‹ˆë‹¤.")
                break
            
            try:
                filter_condition = {"primary_label": {"$eq": disease}}
                available_count = self.config.DISEASE_INFO.get(disease, {}).get('count', 0)
                search_count = min(top_k, available_count)
                
                if search_count > 0:
                    results = self.image_index.query(
                        vector=dummy_vector,
                        filter=filter_condition,
                        top_k=search_count,
                        include_metadata=True
                    )
                    
                    for match in results['matches']:
                        metadata = match['metadata']
                        all_images.append({
                            'image_id': match['id'],
                            'disease': disease,
                            'labels': metadata.get('labels', []),
                            'description': metadata.get('all_descriptions', ''),
                            'primary_label': metadata.get('primary_label', ''),
                            'image_path': metadata.get('image_path', ''),
                            'bbox_info': metadata.get('bboxes', []),
                            'relevance_score': 1.0
                        })
                    
                    korean_name = self.config.DISEASE_INFO[disease]['korean']
                    print(f"   âœ… {disease} ({korean_name}): {len(results['matches'])}ê°œ ì´ë¯¸ì§€ ë§¤ì¹­")
                else:
                    print(f"   âš ï¸ {disease}: ì´ë¯¸ì§€ ì—†ìŒ")
                    
            except Exception as e:
                print(f"   âŒ '{disease}' ì´ë¯¸ì§€ ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
        
        return all_images
    
    def search_by_image(self, image_path: str, top_k: int = 3) -> Dict:
        """ì´ë¯¸ì§€ íŒŒì¼ì„ ì§ì ‘ ì…ë ¥ë°›ì•„, ê·¸ ì´ë¯¸ì§€ì™€ ì‹œê°ì ìœ¼ë¡œ ìœ ì‚¬í•œ ì´ë¯¸ì§€ë“¤ì„ DBì—ì„œ ê²€ìƒ‰í•©ë‹ˆë‹¤."""
        image_embedding = self._get_image_embedding(image_path)
        
        if not image_embedding:
            return {"error": "ì´ë¯¸ì§€ ì²˜ë¦¬ ì‹¤íŒ¨", "image_path": image_path}
        
        try:
            results = self.image_index.query(
                vector=image_embedding,
                top_k=top_k,
                include_metadata=True
            )
            
            matched_images = []
            for match in results['matches']:
                metadata = match['metadata']
                matched_images.append({
                    'image_id': match['id'],
                    'similarity': match['score'],
                    'disease': metadata.get('primary_label', ''),
                    'labels': metadata.get('labels', []),
                    'description': metadata.get('all_descriptions', ''),
                    'image_path': metadata.get('image_path', '')
                })
            
            if matched_images:
                best_match = matched_images[0]
                primary_disease = best_match['disease']
                korean_name = self.config.DISEASE_INFO[primary_disease]['korean']
                
                return {
                    "query": f"ì´ë¯¸ì§€ ê²€ìƒ‰: {Path(image_path).name}",
                    "diagnosis": primary_disease,
                    "korean_diagnosis": korean_name,
                    "confidence": "high" if best_match['similarity'] > 0.95 else "medium",
                    "search_info": {
                        "strategy": "image_similarity_search",
                        "similarity_score": best_match['similarity'],
                        "matched_images": len(matched_images)
                    },
                    "images": matched_images
                }
            else:
                return {"error": "ìœ ì‚¬í•œ ì´ë¯¸ì§€ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤", "image_path": image_path}
                
        except Exception as e:
            return {"error": f"ì´ë¯¸ì§€ ê²€ìƒ‰ ì‹¤íŒ¨: {e}", "image_path": image_path}
    
    def _get_image_embedding(self, image_path: str) -> Optional[List[float]]:
        """ì‹¤ì œ ì´ë¯¸ì§€ íŒŒì¼ì— ëŒ€í•œ ì„ë² ë”© ìƒì„±"""
        image_path_obj = Path(image_path)
        if not image_path_obj.exists():
            print(f"ê²½ê³ : ì´ë¯¸ì§€ íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {image_path}")
            return None
        
        try:
            pil_image = Image.open(image_path_obj).convert('L')
            image_tensor = self.image_transform(pil_image)
            batch_tensor = image_tensor.unsqueeze(0).to(self.config.DEVICE)
            
            with torch.no_grad():
                model_output = self.image_encoder(batch_tensor)
                embedding_tensor = model_output.img_embedding
                return embedding_tensor.cpu().detach().numpy().squeeze().tolist()
                
        except Exception as e:
            print(f"ì˜¤ë¥˜: ì´ë¯¸ì§€ íŒŒì¼ì„ ì„ë² ë”©ìœ¼ë¡œ ë³€í™˜í•˜ëŠ” ë° ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤ ({image_path}): {e}")
            return None


class ContextBuilder:
    """ê²€ìƒ‰ ê²°ê³¼ë¥¼ í†µí•©í•˜ì—¬ ì»¨í…ìŠ¤íŠ¸ ìƒì„±"""
    
    def __init__(self):
        self.max_text_length = 2000 # LLMì— ì „ë‹¬í•  ìµœëŒ€ í…ìŠ¤íŠ¸ ê¸¸ì´
        self.max_images = 3 # LLMì— ì „ë‹¬í•  ìµœëŒ€ ì´ë¯¸ì§€ ê°œìˆ˜
    
    def create_context(
        self, 
        query: str, 
        text_results: List[Dict], 
        image_results: List[Dict], 
        predicted_diseases: List[str]
    ) -> Dict[str, Any]:
        """ëª¨ë“  ê²€ìƒ‰ ê²°ê³¼ë¥¼ ì¢…í•©í•˜ì—¬ ìµœì¢… ì»¨í…ìŠ¤íŠ¸ ë”•ì…”ë„ˆë¦¬ë¥¼ ìƒì„±í•©ë‹ˆë‹¤."""
        
        text_content = self._combine_text_results(text_results)
        
        is_text_only = len(predicted_diseases) == 1 and predicted_diseases[0] == "TEXT_ONLY"
        
        if is_text_only:
            primary_diagnosis = "Unknown"
            korean_diagnosis = "í…ìŠ¤íŠ¸ ì „ìš© (í‰ë¶€ ê´€ë ¨ì„± ë‚®ìŒ)"
            image_info = "ì´ë¯¸ì§€ ê²€ìƒ‰ ìƒëµ (í‰ë¶€ ë¬´ê´€ ì£¼ì œ)"
            confidence_level = "medium"
            print(f"   ğŸ“ í…ìŠ¤íŠ¸ ì „ìš© ì»¨í…ìŠ¤íŠ¸ ìƒì„±: í‰ë¶€ ë¬´ê´€ ì£¼ì œë¡œ íŒë‹¨")
        else:
            image_info = self._process_image_results(image_results)
            primary_diagnosis = predicted_diseases[0] if predicted_diseases else "Unknown"
            korean_diagnosis = self._get_korean_diagnosis(primary_diagnosis)
            confidence_level = self._calculate_confidence_level(text_results, image_results, predicted_diseases)
        
        context = {
            "query": query,
            "diagnosis": primary_diagnosis,
            "primary_diagnosis": primary_diagnosis,
            "korean_diagnosis": korean_diagnosis,
            "all_diseases": predicted_diseases,
            "text_content": text_content,
            "image_info": image_info,
            "images": [] if is_text_only else image_results,
            "confidence": confidence_level,
            "text_count": len(text_results),
            "image_count": 0 if is_text_only else len(image_results),
            "is_text_only_mode": is_text_only,
            "created_at": datetime.now().isoformat()
        }
        
        print(f"   âœ… ì»¨í…ìŠ¤íŠ¸ ìƒì„± ì™„ë£Œ: {korean_diagnosis}, ì‹ ë¢°ë„: {confidence_level}")
        return context
    
    def _combine_text_results(self, text_results: List[Dict]) -> str:
        """ì—¬ëŸ¬ ê°œì˜ í…ìŠ¤íŠ¸ ì¡°ê°ë“¤ì„ ê²°í•©"""
        if not text_results:
            return "ê´€ë ¨ í…ìŠ¤íŠ¸ ì •ë³´ ì—†ìŒ"
        
        combined_text = ""
        for result in text_results:
            content = result.get('content', '') or result.get('text', '')
            combined_text += content + " "
        
        if len(combined_text) > self.max_text_length:
            combined_text = combined_text[:self.max_text_length] + "..."
        
        return combined_text.strip()
    
    def _process_image_results(self, image_results: List[Dict]) -> str:
        """ì´ë¯¸ì§€ ê²°ê³¼ë“¤ì„ ì²˜ë¦¬"""
        if not image_results:
            return "ê´€ë ¨ ì´ë¯¸ì§€ ì •ë³´ ì—†ìŒ"
        
        processed_info = f"{len(image_results)}ê°œ ê´€ë ¨ ì´ë¯¸ì§€ ë°œê²¬"
        
        if image_results:
            first_image = image_results[0]
            disease = first_image.get('disease', first_image.get('primary_label', 'Unknown'))
            description = first_image.get('description', '')
            if description:
                processed_info += f" - {description[:100]}"
        
        return processed_info
    
    def _get_korean_diagnosis(self, primary_diagnosis: str) -> str:
        """ì˜ì–´ ì§„ë‹¨ëª…ì„ í•œêµ­ì–´ë¡œ ë³€í™˜í•©ë‹ˆë‹¤."""
        DISEASE_INFO = {
            "Effusion": {"korean": "í‰ìˆ˜"},
            "Infiltrate": {"korean": "ì¹¨ìœ¤/ê²½í™”"},
            "Atelectasis": {"korean": "ë¬´ê¸°í"},
            "Pneumonia": {"korean": "íë ´"},
            "Mass": {"korean": "ì¢…ê´´"},
            "Pneumothorax": {"korean": "ê¸°í‰"},
            "Cardiomegaly": {"korean": "ì‹¬ì¥ë¹„ëŒ€"},
            "Nodule": {"korean": "ê²°ì ˆ"}
        }
        
        disease_info = DISEASE_INFO.get(primary_diagnosis, {})
        korean_name = disease_info.get('korean', primary_diagnosis)
        
        return f"{korean_name} ({primary_diagnosis})"
    
    def _calculate_confidence_level(self, text_results: List[Dict], image_results: List[Dict], predicted_diseases: List[str]) -> str:
        """ì‹ ë¢°ë„ ë ˆë²¨ ê³„ì‚°"""
        
        confidence_score = 0
        
        confidence_score += min(len(text_results) * 10, 40)
        
        confidence_score += min(len(image_results) * 15, 30)
        
        confidence_score += min(len(predicted_diseases) * 10, 30)
        
        if text_results:
            total_text_length = sum(len(result.get('content', '') + result.get('text', '')) for result in text_results)
            if total_text_length > 500:
                confidence_score += 10
        
        if image_results:
            high_confidence_images = 0
            for img in image_results:
                metadata = img.get('metadata', {})
                if metadata.get('image_confidence', 0) > 0.8:
                    high_confidence_images += 1
            if high_confidence_images > 0:
                confidence_score += 10
        
        if confidence_score >= 80:
            return "high"
        elif confidence_score >= 50:
            return "medium"  
        else:
            return "low"
        
class SearchEngine:
    """í†µí•© ë©€í‹°ëª¨ë‹¬ ê²€ìƒ‰ ì—”ì§„ì˜ ë©”ì¸ í´ë˜ìŠ¤ì…ë‹ˆë‹¤."""
    
    def __init__(self):
        """ê²€ìƒ‰ ì—”ì§„ ì´ˆê¸°í™”: ëª¨ë“  ì™¸ë¶€ ì„œë¹„ìŠ¤ ì—°ê²° ë° í—¬í¼ í´ë˜ìŠ¤ ì¸ìŠ¤í„´ìŠ¤ ìƒì„±"""
        print("ğŸ¥ Medical Multimodal Search Engine")
        print("=" * 60)
        
        self.config = SearchConfig()
        
        self.pc = Pinecone(api_key=self.config.PINECONE_API_KEY)
        self.openai_client = OpenAI(api_key=self.config.OPENAI_API_KEY)
        
        self.text_index = self.pc.Index(self.config.TEXT_INDEX_NAME)
        self.image_index = self.pc.Index(self.config.IMAGE_INDEX_NAME)
        
        self.image_encoder = get_biovil_t_image_encoder()
        self.image_transform = create_chest_xray_transform_for_inference(resize=512, center_crop_size=480)
        self.image_encoder.to(self.config.DEVICE)
        self.image_encoder.eval()
        
        self.query_processor = QueryProcessor(self.config)
        self.disease_extractor = DiseaseExtractor(self.config)
        self.image_searcher = ImageSearcher(self.config, self.image_index, self.image_encoder, self.image_transform)
        self.context_builder = ContextBuilder()
        
        print("âœ… ê²€ìƒ‰ ì—”ì§„ ì´ˆê¸°í™” ì™„ë£Œ")
    
    def search_text(self, query: str, top_k: int = 5) -> Dict[str, Any]:
        """
        í…ìŠ¤íŠ¸ ê¸°ë°˜ ë©€í‹°ëª¨ë‹¬ ê²€ìƒ‰
        
        Args:
            query: ê²€ìƒ‰ ì¿¼ë¦¬
            top_k: ë°˜í™˜í•  ê²°ê³¼ ìˆ˜
            
        Returns:
            ê²€ìƒ‰ ê²°ê³¼ ë”•ì…”ë„ˆë¦¬
        """
        print(f"\n{'='*60}")
        print(f"ğŸ” í…ìŠ¤íŠ¸ ê¸°ë°˜ ë©€í‹°ëª¨ë‹¬ ê²€ìƒ‰: '{query}'")
        print(f"{'='*60}")
        
        try:
            expanded_query = self.query_processor.expand_query(query)
            
            text_results = self._search_text_knowledge(expanded_query, top_k)
            if not text_results:
                return {"error": "ê´€ë ¨ ì˜í•™ ì§€ì‹ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤", "query": query}
            
            predicted_diseases = self.disease_extractor.extract_diseases(text_results, query)
            
            image_results = self.image_searcher.search_by_diseases(predicted_diseases, top_k)
            
            context = self.context_builder.create_context(query, text_results, image_results, predicted_diseases)
            
            return context
            
        except Exception as e:
            print(f"âŒ ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
            return {"error": f"ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}", "query": query}
    
    def search_image(self, image_path: str, top_k: int = 5) -> Dict[str, Any]:
        """
        ì´ë¯¸ì§€ ê¸°ë°˜ ê²€ìƒ‰
        
        Args:
            image_path: ì´ë¯¸ì§€ íŒŒì¼ ê²½ë¡œ
            top_k: ë°˜í™˜í•  ê²°ê³¼ ìˆ˜
            
        Returns:
            ê²€ìƒ‰ ê²°ê³¼ ë”•ì…”ë„ˆë¦¬
        """
        print(f"\n{'='*60}")
        print(f"ğŸ–¼ï¸ ì´ë¯¸ì§€ ê¸°ë°˜ ê²€ìƒ‰: {image_path}")
        print(f"{'='*60}")
        
        try:
            result = self.image_searcher.search_by_image(image_path, top_k)
            return result
            
        except Exception as e:
            print(f"âŒ ì´ë¯¸ì§€ ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
            return {"error": f"ì´ë¯¸ì§€ ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}", "image_path": image_path}
    
    def search_images_by_disease(self, disease_name: str, top_k: int = 5) -> List[Dict]:
        """
        [ì¶”ê°€ëœ ë©”ì„œë“œ]
        íŠ¹ì • ì§ˆë³‘ëª…ìœ¼ë¡œ ì´ë¯¸ì§€ë¥¼ ê²€ìƒ‰í•©ë‹ˆë‹¤.
        ImageSearcherì˜ ê¸°ëŠ¥ì„ SearchEngineì„ í†µí•´ ë…¸ì¶œì‹œí‚µë‹ˆë‹¤.
        """
        print(f"ğŸ–¼ï¸ ì§ˆë³‘ëª… ê¸°ë°˜ ì´ë¯¸ì§€ ê²€ìƒ‰: '{disease_name}' (ìƒìœ„ {top_k}ê°œ)")
        if not self.image_searcher:
            print("   âš ï¸ ì´ë¯¸ì§€ ê²€ìƒ‰ê¸°(ImageSearcher)ê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            return []
            
        try:
            results = self.image_searcher.search_by_diseases(
                predicted_diseases=[disease_name], 
                top_k=top_k
            )
            return results
        except Exception as e:
            print(f"âŒ ì§ˆë³‘ëª… '{disease_name}' ì´ë¯¸ì§€ ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
            return []

    def _search_text_knowledge(self, query: str, top_k: int = 5) -> List[Dict]:
        """OpenAI APIë¡œ ì¿¼ë¦¬ë¥¼ ì„ë² ë”©í•˜ê³ , Pineconeì—ì„œ í…ìŠ¤íŠ¸ ì§€ì‹ì„ ê²€ìƒ‰í•˜ëŠ” ë‚´ë¶€ ë©”ì„œë“œ."""
        
        if not self.text_index:
            print("âŒ í…ìŠ¤íŠ¸ ì¸ë±ìŠ¤ê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            return []
        
        try:
            print(f"ğŸ“š í…ìŠ¤íŠ¸ ì§€ì‹ ê²€ìƒ‰: '{query[:50]}...'")
            
            resp = self.openai_client.embeddings.create(
                input=[query], 
                model=self.config.TEXT_EMBEDDING_MODEL
            )
            embedding = resp.data[0].embedding
            
            results = self.text_index.query(
                vector=embedding,
                top_k=top_k,
                include_metadata=True
            )
            
            text_chunks = []
            for match in results['matches']:
                metadata = match['metadata']
                content = metadata.get('text', metadata.get('content', ''))
                text_chunks.append({
                    'content': content,
                    'similarity': match['score'],
                    'source': metadata.get('source', 'unknown'),
                    'id': match['id']
                })
            
            print(f"   âœ… {len(text_chunks)}ê°œ ì§€ì‹ ì²­í¬ ê²€ìƒ‰ ì™„ë£Œ")
            
            return text_chunks
            
        except Exception as e:
            print(f"âŒ í…ìŠ¤íŠ¸ ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
            return {"error": f"í…ìŠ¤íŠ¸ ê²€ìƒ‰ ì‹¤íŒ¨: {e}"}
    
    def get_system_info(self) -> Dict[str, Any]:
        """ì‹œìŠ¤í…œì˜ í˜„ì¬ ìƒíƒœì™€ ì •ë³´ë¥¼ ë°˜í™˜í•˜ëŠ” ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ì…ë‹ˆë‹¤."""
        try:
            text_stats = self.text_index.describe_index_stats()
            image_stats = self.image_index.describe_index_stats()
            
            return {
                "system_status": "online",
                "device": self.config.DEVICE,
                "text_index": {
                    "name": self.config.TEXT_INDEX_NAME,
                    "total_vectors": text_stats.get('total_vector_count', 0),
                    "dimension": text_stats.get('dimension', 0)
                },
                "image_index": {
                    "name": self.config.IMAGE_INDEX_NAME,
                    "total_vectors": image_stats.get('total_vector_count', 0),
                    "dimension": image_stats.get('dimension', 0)
                },
                "supported_diseases": list(self.config.DISEASE_INFO.keys()),
                "total_diseases": len(self.config.DISEASE_INFO)
            }
        except Exception as e:
            return {"system_status": "error", "error": str(e)}


# --- í…ŒìŠ¤íŠ¸ ë° í‰ê°€ í´ë˜ìŠ¤ ---

class SearchTester:
    """ê²€ìƒ‰ ì‹œìŠ¤í…œì˜ ì„±ëŠ¥ê³¼ ì •í™•ë„ë¥¼ í…ŒìŠ¤íŠ¸í•˜ê¸° ìœ„í•œ í´ë˜ìŠ¤ì…ë‹ˆë‹¤."""
    
    def __init__(self, search_engine: SearchEngine):
        self.search_engine = search_engine
    
    def test_accuracy(self) -> float:
        """ì§ˆë³‘ ë§¤ì¹­ ì •í™•ë„ í…ŒìŠ¤íŠ¸: ë¯¸ë¦¬ ì •í•´ì§„ ì¿¼ë¦¬ì™€ ì •ë‹µì„ ë¹„êµí•˜ì—¬ ì‹œìŠ¤í…œì˜ ì •í™•ë„ë¥¼ ì¸¡ì •í•©ë‹ˆë‹¤."""
        test_cases = [
            {"query": "pneumonia", "expected": "Pneumonia"},
            {"query": "pleural effusion", "expected": "Effusion"},
            {"query": "íë ´", "expected": "Pneumonia"},
            {"query": "í‰ìˆ˜", "expected": "Effusion"},
            {"query": "ê¸°í‰", "expected": "Pneumothorax"},
            {"query": "pneumothorax", "expected": "Pneumothorax"},
            {"query": "consolidation", "expected": "Infiltrate"},
            {"query": "ì‹¬ì¥ë¹„ëŒ€", "expected": "Cardiomegaly"}
        ]
        
        print("\nğŸ¯ ì§ˆë³‘ ë§¤ì¹­ ì •í™•ë„ í…ŒìŠ¤íŠ¸")
        print("="*50)
        
        correct = 0
        total = len(test_cases)
        
        for case in test_cases:
            try:
                result = self.search_engine.search_text(case["query"], top_k=3)
                
                if "error" not in result:
                    predicted = result["diagnosis"]
                    expected = case["expected"]
                    
                    if predicted == expected:
                        correct += 1
                        print(f"âœ… '{case['query']}' â†’ {predicted} - ì •í™•!")
                    else:
                        print(f"âŒ '{case['query']}' â†’ {predicted} (ì˜ˆìƒ: {expected})")
                else:
                    print(f"âŒ '{case['query']}' â†’ ê²€ìƒ‰ ì‹¤íŒ¨: {result['error']}")
                    
            except Exception as e:
                print(f"âŒ '{case['query']}' â†’ ì˜¤ë¥˜: {e}")
        
        accuracy = correct / total * 100
        print(f"\nğŸ“ˆ ì •í™•ë„: {correct}/{total} ({accuracy:.1f}%)")
        
        return accuracy
    
    def test_performance(self) -> Dict[str, float]:
        """ì„±ëŠ¥ í…ŒìŠ¤íŠ¸: íŠ¹ì • ì¿¼ë¦¬ì— ëŒ€í•œ ì‹œìŠ¤í…œì˜ ì‘ë‹µ ì‹œê°„ì„ ì¸¡ì •í•©ë‹ˆë‹¤."""
        import time
        
        print("\nâ±ï¸ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸")
        print("="*30)
        
        test_queries = ["pneumonia", "pleural effusion", "íë ´"]
        times = []
        
        for query in test_queries:
            start_time = time.time()
            try:
                result = self.search_engine.search_text(query, top_k=3)
                end_time = time.time()
                
                duration = end_time - start_time
                times.append(duration)
                
                status = "âœ…" if "error" not in result else "âŒ"
                print(f"{status} '{query}': {duration:.2f}ì´ˆ")
                
            except Exception as e:
                end_time = time.time()
                duration = end_time - start_time
                times.append(duration)
                print(f"âŒ '{query}': {duration:.2f}ì´ˆ (ì˜¤ë¥˜)")
        
        avg_time = sum(times) / len(times) if times else 0
        print(f"\nğŸ“Š í‰ê·  ì‘ë‹µ ì‹œê°„: {avg_time:.2f}ì´ˆ")
        
        return {
            "average_time": avg_time,
            "individual_times": times,
            "total_queries": len(test_queries)
        }
    
    def run_comprehensive_test(self) -> Dict[str, Any]:
        """í¬ê´„ì  í…ŒìŠ¤íŠ¸ ì‹¤í–‰: ì •í™•ë„, ì„±ëŠ¥ ë“± ì—¬ëŸ¬ í…ŒìŠ¤íŠ¸ë¥¼ í•œ ë²ˆì— ì‹¤í–‰í•˜ê³  ì¢…í•© ê²°ê³¼ë¥¼ ë³´ê³ í•©ë‹ˆë‹¤."""
        print("\nğŸ§ª í¬ê´„ì  í…ŒìŠ¤íŠ¸ ì‹¤í–‰")
        print("="*50)
        
        # 1. ì •í™•ë„ í…ŒìŠ¤íŠ¸
        accuracy = self.test_accuracy()
        
        # 2. ì„±ëŠ¥ í…ŒìŠ¤íŠ¸
        performance = self.test_performance()
        
        # 3. ì‹œìŠ¤í…œ ì •ë³´
        system_info = self.search_engine.get_system_info()
        
        # ìµœì¢… ê²°ê³¼ ìš”ì•½ ì¶œë ¥
        print(f"\n{'='*50}")
        print(f"ğŸ† ì¢…í•© í…ŒìŠ¤íŠ¸ ê²°ê³¼")
        print(f"{'='*50}")
        print(f"ğŸ¯ ì§ˆë³‘ ë§¤ì¹­ ì •í™•ë„: {accuracy:.1f}%")
        print(f"â±ï¸ í‰ê·  ì‘ë‹µ ì‹œê°„: {performance['average_time']:.2f}ì´ˆ")
        print(f"ğŸ¥ ì§€ì› ì§ˆë³‘ ìˆ˜: {system_info.get('total_diseases', 0)}ê°œ")
        print(f"ğŸ“Š í…ìŠ¤íŠ¸ ë²¡í„° ìˆ˜: {system_info.get('text_index', {}).get('total_vectors', 0):,}ê°œ")
        print(f"ğŸ–¼ï¸ ì´ë¯¸ì§€ ë²¡í„° ìˆ˜: {system_info.get('image_index', {}).get('total_vectors', 0):,}ê°œ")
        
        if accuracy >= 75:
            print("ğŸ‰ ëª©í‘œ ë‹¬ì„±! (75% ì´ìƒ)")
        elif accuracy >= 50:
            print("ğŸŸ¡ ë¶€ë¶„ ê°œì„  (50% ì´ìƒ)")
        else:
            print("ğŸ”´ ì¶”ê°€ ê°œì„  í•„ìš”")
        
        return {
            "accuracy": accuracy,
            "performance": performance,
            "system_info": system_info,
            "status": "excellent" if accuracy >= 75 else "good" if accuracy >= 50 else "needs_improvement"
        }


# --- í¸ì˜ í•¨ìˆ˜ë“¤ ---

def create_search_engine() -> SearchEngine:
    """ê²€ìƒ‰ ì—”ì§„ ì¸ìŠ¤í„´ìŠ¤ ìƒì„±"""
    return SearchEngine()

def quick_test(query: str = "íë ´ ì§„ë‹¨") -> None:
    """ë¹ ë¥¸ í…ŒìŠ¤íŠ¸ ì‹¤í–‰"""
    print(f"ğŸš€ ë¹ ë¥¸ í…ŒìŠ¤íŠ¸: '{query}'")
    
    try:
        engine = create_search_engine()
        result = engine.search_text(query)
        
        if "error" not in result:
            print(f"âœ… ê²°ê³¼: {result['korean_diagnosis']} ({result['diagnosis']})")
            print(f"   ì‹ ë¢°ë„: {result['confidence']}")
            print(f"   ê´€ë ¨ ì´ë¯¸ì§€: {len(result.get('images', []))}ê°œ")
        else:
            print(f"âŒ ì‹¤íŒ¨: {result['error']}")
            
    except Exception as e:
        print(f"âŒ ì˜¤ë¥˜: {e}")

def run_full_evaluation() -> None:
    """ì „ì²´ í‰ê°€ ì‹¤í–‰"""
    try:
        engine = create_search_engine()
        tester = SearchTester(engine)
        results = tester.run_comprehensive_test()
        
        return results
    except Exception as e:
        print(f"âŒ í‰ê°€ ì‹¤í–‰ ì‹¤íŒ¨: {e}")
        return None


# --- ë©”ì¸ ì‹¤í–‰ë¶€ ---

if __name__ == "__main__":
    print("ğŸ¥ Medical Multimodal Search Engine")
    print("=" * 60)
    
    import sys
    
    if len(sys.argv) > 1:
        command = sys.argv[1].lower()
        
        if command == "test":
            # ë¹ ë¥¸ í…ŒìŠ¤íŠ¸
            query = sys.argv[2] if len(sys.argv) > 2 else "íë ´ ì§„ë‹¨"
            quick_test(query)
            
        elif command == "eval":
            # ì „ì²´ í‰ê°€
            run_full_evaluation()
            
        elif command == "info":
            # ì‹œìŠ¤í…œ ì •ë³´
            try:
                engine = create_search_engine()
                info = engine.get_system_info()
                print("ğŸ” ì‹œìŠ¤í…œ ì •ë³´:")
                for key, value in info.items():
                    print(f"  {key}: {value}")
            except Exception as e:
                print(f"âŒ ì‹œìŠ¤í…œ ì •ë³´ ì¡°íšŒ ì‹¤íŒ¨: {e}")
                
        else:
            print("ì‚¬ìš©ë²•:")
            print("  python search_engine.py test [ì¿¼ë¦¬]     # ë¹ ë¥¸ í…ŒìŠ¤íŠ¸")
            print("  python search_engine.py eval           # ì „ì²´ í‰ê°€")
            print("  python search_engine.py info           # ì‹œìŠ¤í…œ ì •ë³´")
    
    else:
        # ê¸°ë³¸ ì‹¤í–‰: ì¸í„°ë™í‹°ë¸Œ ëª¨ë“œ
        try:
            engine = create_search_engine()
            print("\nğŸ¯ ì¸í„°ë™í‹°ë¸Œ ëª¨ë“œ (ì¢…ë£Œ: 'quit')")
            
            while True:
                query = input("\nê²€ìƒ‰ì–´ ì…ë ¥: ").strip()
                
                if query.lower() in ['quit', 'exit', 'ì¢…ë£Œ']:
                    print("ğŸ‘‹ ê²€ìƒ‰ ì—”ì§„ì„ ì¢…ë£Œí•©ë‹ˆë‹¤.")
                    break
                
                if query:
                    result = engine.search_text(query)
                    
                    if "error" not in result:
                        print(f"\nğŸ“Š ê²€ìƒ‰ ê²°ê³¼:")
                        print(f"  ğŸ¯ ì§„ë‹¨: {result['korean_diagnosis']} ({result['diagnosis']})")
                        print(f"  ğŸ“ˆ ì‹ ë¢°ë„: {result['confidence']}")
                        print(f"  ğŸ–¼ï¸ ê´€ë ¨ ì´ë¯¸ì§€: {len(result.get('images', []))}ê°œ")
                    else:
                        print(f"âŒ ê²€ìƒ‰ ì‹¤íŒ¨: {result['error']}")
                
        except KeyboardInterrupt:
            print("\nğŸ‘‹ ê²€ìƒ‰ ì—”ì§„ì„ ì¢…ë£Œí•©ë‹ˆë‹¤.")
        except Exception as e:
            print(f"âŒ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")